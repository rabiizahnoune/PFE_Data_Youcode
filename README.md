# ğŸ† Documentation du Projet Gold Price Analytics

<div align="center">
  
  ![Gold Analytics](https://img.shields.io/badge/Gold-Analytics-FFD700?style=for-the-badge&logo=bitcoin&logoColor=black)
  ![Status](https://img.shields.io/badge/Status-Production_Ready-success?style=for-the-badge)
  ![Version](https://img.shields.io/badge/Version-1.0.0-blue?style=for-the-badge)
  ![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

</div>

---

## ğŸŒŸ Introduction

> **Gold Price Analytics** est une plateforme complÃ¨te conÃ§ue pour analyser les donnÃ©es du marchÃ© de l'or, en intÃ©grant des donnÃ©es financiÃ¨res, des actualitÃ©s et des analyses prÃ©dictives.

Cette solution utilise une **architecture moderne** basÃ©e sur des technologies Big Data et d'intelligence artificielle pour fournir des insights techniques, fondamentaux et interactifs via une interface utilisateur intuitive. Le projet est structurÃ© pour gÃ©rer l'ingestion, le traitement, l'analyse et la visualisation des donnÃ©es, avec un dÃ©ploiement orchestrÃ© via Docker.

---

## ğŸ“š Table des MatiÃ¨res

<details>
<summary>ğŸ” Cliquez pour voir la table des matiÃ¨res dÃ©taillÃ©e</summary>

1. [ğŸ¯ Objectifs du Projet](#-objectifs-du-projet)
2. [ğŸ—ï¸ Architecture du Projet](#ï¸-architecture-du-projet)
3. [ğŸ“ Structure des Dossiers et Fichiers](#-structure-des-dossiers-et-fichiers)
4. [ğŸ› ï¸ Technologies UtilisÃ©es](#ï¸-technologies-utilisÃ©es)
5. [âš™ï¸ Configuration et DÃ©ploiement](#ï¸-configuration-et-dÃ©ploiement)
6. [ğŸ”„ Pipeline de DonnÃ©es](#-pipeline-de-donnÃ©es)
7. [ğŸ¤– ModÃ¨les d'Analyse](#-modÃ¨les-danalyse)
8. [ğŸ“Š Tableau de Bord Streamlit](#-tableau-de-bord-streamlit)
9. [ğŸ‘ï¸ Surveillance et Logging](#ï¸-surveillance-et-logging)
10. [ğŸ“¥ Instructions d'Installation](#-instructions-dinstallation)
11. [ğŸš€ Utilisation](#-utilisation)
12. [ğŸ¤ Contributions et Maintenance](#-contributions-et-maintenance)

</details>

---

## ğŸ¯ Objectifs du Projet

<div align="center">
  
| ğŸ¯ **Objectif** | ğŸ“‹ **Description** |
|:---|:---|
| **ğŸ“ˆ Analyser les donnÃ©es du marchÃ© de l'or** | Collecter et traiter les donnÃ©es historiques et en temps rÃ©el sur les prix de l'or, les indices S&P 500, les taux d'intÃ©rÃªt fÃ©dÃ©raux et les actualitÃ©s pertinentes |
| **ğŸ” Fournir des insights techniques et fondamentaux** | Offrir des analyses basÃ©es sur des indicateurs techniques (moyennes mobiles, variations de prix) et des analyses fondamentales via l'intÃ©gration d'actualitÃ©s |
| **ğŸ”® PrÃ©dire les tendances** | Utiliser des modÃ¨les d'apprentissage automatique pour anticiper les mouvements des prix de l'or |
| **ğŸ’¬ Interagir avec les utilisateurs** | Proposer une interface utilisateur interactive via Streamlit et un module de chat AI basÃ© sur Gemini pour rÃ©pondre aux questions des utilisateurs |

</div>

---

## ğŸ—ï¸ Architecture du Projet

```mermaid
graph TB
    subgraph "ğŸ“Š Data Sources"
        A[yfinance & FRED] 
        B[NewsAPI]
    end
    
    subgraph "ğŸ”„ Ingestion Layer"
        C[Apache Kafka]
        D[Apache Airflow]
    end
    
    subgraph "ğŸ’¾ Storage Layer"
        E[HDFS]
        F[Snowflake]
        G[Cassandra]
    end
    
    subgraph "âš¡ Processing Layer"
        H[Apache Spark]
        I[MLflow]
    end
    
    subgraph "ğŸ“± Presentation Layer"
        J[Streamlit Dashboard]
    end
    
    A --> C
    B --> C
    C --> D
    D --> E
    E --> F
    E --> G
    H --> E
    I --> H
    F --> J
    G --> J
```

L'architecture est **modulaire** et basÃ©e sur des conteneurs Docker, orchestrÃ©s par `docker-compose.yml`. Elle comprend :

### ğŸ”½ **1. Ingestion des DonnÃ©es**
- **ğŸ“Š Sources** : DonnÃ©es financiÃ¨res via yfinance et FRED, actualitÃ©s via NewsAPI
- **ğŸ› ï¸ Outils** : Apache Kafka pour le streaming, Airflow pour l'orchestration des tÃ¢ches

### ğŸ’¾ **2. Stockage**
- **ğŸ—ƒï¸ HDFS** : Stockage des donnÃ©es brutes et traitÃ©es au format CSV et Parquet
- **â„ï¸ Snowflake** : Base de donnÃ©es analytique pour les tables dimensionnelles et factuelles
- **ğŸ”— Cassandra** : Stockage des actualitÃ©s et des analyses d'impact

### âš¡ **3. Traitement**
- **âœ¨ Spark** : Traitement des flux de donnÃ©es et analyse des actualitÃ©s
- **ğŸ¤– MLflow** : Gestion des modÃ¨les d'apprentissage automatique

### ğŸ“Š **4. Visualisation**
- **ğŸ¨ Streamlit** : Tableau de bord interactif pour l'analyse technique, fondamentale et le chat AI

### ğŸ‘ï¸ **5. Surveillance**
- Airflow pour le monitoring des pipelines
- Discord pour les alertes en cas d'erreurs dans les logs Spark

---

## ğŸ“ Structure des Dossiers et Fichiers

<details>
<summary>ğŸŒ³ Arborescence complÃ¨te du projet</summary>

```
ğŸ“¦ C:\Users\Youcode\Documents\gold_price_project
â”œâ”€â”€ ğŸ“„ .gitignore
â”œâ”€â”€ ğŸ“„ data.sql.txt
â”œâ”€â”€ ğŸ³ docker-compose.yml
â”œâ”€â”€ ğŸ test.py
â”œâ”€â”€ ğŸ x.py
â”œâ”€â”€ ğŸ“‚ airflow/
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt
â”‚   â””â”€â”€ ğŸ“‚ dags/
â”‚       â”œâ”€â”€ ğŸ extract_gold.py
â”‚       â”œâ”€â”€ ğŸ load.py
â”‚       â”œâ”€â”€ ğŸ monitor_spark.py
â”‚       â”œâ”€â”€ ğŸ news_batch.py
â”‚       â”œâ”€â”€ ğŸ stream.py
â”‚       â”œâ”€â”€ ğŸ while.py
â”‚       â””â”€â”€ ğŸ gold_trading_dashboard.py
â”œâ”€â”€ ğŸ“‚ docker/
â”‚   â”œâ”€â”€ ğŸ³ agent.dockerfile
â”‚   â”œâ”€â”€ ğŸ³ ai_trainer.dockerfile
â”‚   â”œâ”€â”€ ğŸ³ apache.dockerfile
â”‚   â”œâ”€â”€ ğŸ³ hadoop.dockerfile
â”‚   â””â”€â”€ ğŸ“„ requirements.txt
â”œâ”€â”€ ğŸ” keys/
â”œâ”€â”€ ğŸ“‚ ML/
â”‚   â”œâ”€â”€ ğŸ“„ commande.sh
â”‚   â”œâ”€â”€ ğŸ³ Dockerfile
â”‚   â”œâ”€â”€ ğŸ fine_tune_model.py
â”‚   â”œâ”€â”€ ğŸ“„ mlflow.db
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt
â”‚   â””â”€â”€ ğŸ train_model.py
â”œâ”€â”€ ğŸ“‚ ollama_llm/
â”‚   â”œâ”€â”€ ğŸ³ Dockerfile
â”‚   â””â”€â”€ ğŸ“„ entrypoint.sh
â”œâ”€â”€ ğŸ“‚ postgres/
â”‚   â””â”€â”€ ğŸ“„ init.sql
â”œâ”€â”€ ğŸ“‚ scripts/
â”‚   â”œâ”€â”€ ğŸ“‚ batch/
â”‚   â””â”€â”€ ğŸ“‚ mapreduce/
â””â”€â”€ ğŸ“‚ stream/
    â”œâ”€â”€ ğŸ“‚ cassandra/
    â”‚   â”œâ”€â”€ ğŸ“„ cassandra-rackdc.properties
    â”‚   â”œâ”€â”€ ğŸ“„ cassandra-setup.cql
    â”‚   â”œâ”€â”€ ğŸ“„ cassandra.yaml
    â”‚   â””â”€â”€ ğŸ³ Dockerfile
    â”œâ”€â”€ ğŸ“‚ kafka/
    â”‚   â”œâ”€â”€ ğŸ³ Dockerfile
    â”‚   â”œâ”€â”€ ğŸ“„ kafka-setup-k8s.sh
    â”‚   â”œâ”€â”€ ğŸ“„ kafka.properties
    â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt
    â”‚   â””â”€â”€ ğŸ“‚ scripts/
    â”‚       â”œâ”€â”€ ğŸ gold_price.py
    â”‚       â”œâ”€â”€ ğŸ news_producer.py
    â”‚       â””â”€â”€ ğŸ“‚ logs/
    â”‚           â””â”€â”€ ğŸ“„ kafka.log
    â””â”€â”€ ğŸ“‚ spark/
        â”œâ”€â”€ ğŸ analyze_news.py
        â”œâ”€â”€ ğŸ“„ commande.sh
        â”œâ”€â”€ ğŸ³ Dockerfile
        â”œâ”€â”€ ğŸ gold_price_streaming.py
        â”œâ”€â”€ ğŸ“„ requirements.txt
        â”œâ”€â”€ ğŸ spark_consume_test.py
        â”œâ”€â”€ ğŸ store_news_to_hdfs.py
        â””â”€â”€ ğŸ“‚ logs/
            â””â”€â”€ ğŸ“„ spark.log
```

</details>

### ğŸ” Description des Fichiers Principaux

<div align="center">

| ğŸ“„ **Fichier** | ğŸ“‹ **Description** |
|:---|:---|
| **ğŸ“„ .gitignore** | Ignore les environnements virtuels (`myenv`) et les artifacts MLflow (`ML/mlruns`) |
| **ğŸ“„ data.sql.txt** | DÃ©finit le schÃ©ma Snowflake pour les tables `Dim_Date`, `Dim_Marche`, et `Fait_Prix_Or` |
| **ğŸ³ docker-compose.yml** | Configure les services Docker (Airflow, HDFS, Kafka, Spark, MLflow, Cassandra, Streamlit, etc.) |
| **ğŸ test.py** | Script pour tÃ©lÃ©charger et lire les fichiers CSV/Parquet depuis HDFS, avec prÃ©visualisation des donnÃ©es |
| **ğŸ x.py** | Script utilitaire pour gÃ©nÃ©rer la structure du projet et gÃ©rer les interactions avec HDFS |

</div>

#### ğŸ”„ **airflow/dags/** - Orchestration des tÃ¢ches

| ğŸ **Script** | ğŸ¯ **Fonction** |
|:---|:---|
| **extract_gold.py** | Extrait les donnÃ©es de l'or, S&P 500, et taux fÃ©dÃ©raux via yfinance et FRED |
| **load.py** | Charge les donnÃ©es traitÃ©es dans Snowflake avec des opÃ©rations MERGE pour Ã©viter les doublons |
| **monitor_spark.py** | Surveille les logs Spark pour dÃ©tecter les erreurs et envoie des alertes via Discord |
| **news_batch.py** | IngÃ¨re les actualitÃ©s via NewsAPI et les stocke dans HDFS |
| **gold_trading_dashboard.py** | Tableau de bord Streamlit pour l'analyse technique, fondamentale et le chat AI |

#### ğŸ¤– **ML/** - Machine Learning

| ğŸ **Script** | ğŸ¯ **Fonction** |
|:---|:---|
| **train_model.py** | EntraÃ®ne un modÃ¨le de rÃ©gression linÃ©aire pour prÃ©dire les prix de l'or |
| **fine_tune_model.py** | Fine-tune un modÃ¨le existant avec de nouvelles donnÃ©es mensuelles |

#### ğŸ”„ **stream/** - Traitement en temps rÃ©el

| ğŸ“‚ **Module** | ğŸ¯ **Fonction** |
|:---|:---|
| **kafka/** | Configure Kafka pour le streaming des donnÃ©es de prix et d'actualitÃ©s |
| **spark/** | Traite les flux de donnÃ©es et analyse les actualitÃ©s avec Spark |
| **cassandra/** | Stocke les actualitÃ©s et leurs analyses d'impact |

#### ğŸ¤– **ollama_llm/** - IA Conversationnelle
Configuration pour le modÃ¨le Mistral (commentÃ© dans `docker-compose.yml`)

---

## ğŸ› ï¸ Technologies UtilisÃ©es

<div align="center">

### ğŸ”„ **Ingestion et Orchestration**
![Airflow](https://img.shields.io/badge/Apache_Airflow-2.7.1-017CEE?style=for-the-badge&logo=apache-airflow&logoColor=white)
![Kafka](https://img.shields.io/badge/Apache_Kafka-7.4.0-231F20?style=for-the-badge&logo=apache-kafka&logoColor=white)

### ğŸ’¾ **Stockage**
![Hadoop](https://img.shields.io/badge/Hadoop_HDFS-3.2.1-66CCFF?style=for-the-badge&logo=apache&logoColor=black)
![Snowflake](https://img.shields.io/badge/Snowflake-29B5E8?style=for-the-badge&logo=snowflake&logoColor=white)
![Cassandra](https://img.shields.io/badge/Cassandra-4.1-1287B1?style=for-the-badge&logo=apache-cassandra&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-13-336791?style=for-the-badge&logo=postgresql&logoColor=white)

### âš¡ **Traitement**
![Spark](https://img.shields.io/badge/Apache_Spark-3.5.1-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)
![MLflow](https://img.shields.io/badge/MLflow-2.17.2-0194E2?style=for-the-badge&logo=mlflow&logoColor=white)

### ğŸ“Š **Visualisation**
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)

### ğŸ¤– **IA et Analyse**
![Gemini](https://img.shields.io/badge/Gemini_AI-4285F4?style=for-the-badge&logo=google&logoColor=white)
![Scikit Learn](https://img.shields.io/badge/scikit_learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)

### ğŸ³ **Conteneurisation**
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Docker Compose](https://img.shields.io/badge/Docker_Compose-2496ED?style=for-the-badge&logo=docker&logoColor=white)

</div>

---

## âš™ï¸ Configuration et DÃ©ploiement

### ğŸ“‹ PrÃ©-requis

<div align="center">

| âœ… **Requis** | ğŸ“‹ **Description** |
|:---|:---|
| ğŸ³ **Docker & Docker Compose** | InstallÃ©s et configurÃ©s |
| â„ï¸ **Compte Snowflake** | Identifiants configurÃ©s dans `load.py` et `gold_trading_dashboard.py` |
| ğŸ“° **ClÃ© API NewsAPI** | Pour `news_batch.py` et `news_producer.py` |
| ğŸ¤– **ClÃ© API Gemini** | Pour `gold_trading_dashboard.py` et `analyze_news.py` |
| ğŸ¦ **ClÃ© FRED** | Pour `extract_gold.py` |

</div>

### ğŸ”§ Configuration

#### ğŸ”‘ **1. ClÃ©s API**
Configurez les clÃ©s API dans les fichiers respectifs :

```python
# ğŸ“Š Dans extract_gold.py
ALPHA_VANTAGE_KEY = "votre_clÃ©_alpha_vantage"
FRED_KEY = "votre_clÃ©_fred"

# ğŸ“° Dans news_batch.py et news_producer.py
API_KEY = "votre_clÃ©_news_api"

# ğŸ¤– Dans gold_trading_dashboard.py et analyze_news.py
GEMINI_API_KEY = "votre_clÃ©_gemini"
```

> âš ï¸ **Important** : Assurez-vous que les identifiants Snowflake sont corrects dans `load.py` et `gold_trading_dashboard.py`.

#### ğŸ—ƒï¸ **2. HDFS et Permissions**
Le script (`test.py`) dÃ©finit des permissions 777 sur les rÃ©pertoires HDFS pour garantir l'accÃ¨s.

#### ğŸ³ **3. Docker Compose**
Le fichier `docker-compose.yml` dÃ©finit les services suivants :

<details>
<summary>ğŸ” Voir tous les services Docker</summary>

| ğŸ³ **Service** | ğŸ¯ **Description** |
|:---|:---|
| **postgres** | Base de donnÃ©es pour Airflow |
| **airflow-init**, **airflow-webserver**, **airflow-scheduler** | Composants Airflow |
| **namenode**, **datanode1** | HDFS pour le stockage distribuÃ© |
| **zookeeper**, **kafka**, **kafka-init** | Gestion du streaming |
| **spark** | Traitement des donnÃ©es |
| **mlflow-container** | Suivi des modÃ¨les |
| **cassandra** | Stockage des actualitÃ©s |
| **streamlit** | Interface utilisateur |
| **ollama** (commentÃ©) | Pour le modÃ¨le Mistral |

</details>

---

## ğŸ”„ Pipeline de DonnÃ©es

### ğŸ”½ **1. Ingestion**

<div align="center">

| ğŸ **Script** | ğŸ¯ **Fonction** | ğŸ“Š **Source** | ğŸ’¾ **Destination** |
|:---|:---|:---|:---|
| **extract_gold.py** | Extrait les donnÃ©es financiÃ¨res | yfinance, FRED | HDFS `/gold_datalake/raw` |
| **news_batch.py** | IngÃ¨re les actualitÃ©s | NewsAPI | HDFS (JSON) |
| **gold_price.py** | DonnÃ©es simulÃ©es | Simulation | Kafka `gold-price` |
| **news_producer.py** | Flux d'actualitÃ©s | NewsAPI | Kafka `gold-news` |

</div>

### âš¡ **2. Traitement**

<div align="center">

| ğŸ **Script** | ğŸ¯ **Fonction** | ğŸ“¥ **Source** | ğŸ’¾ **Destination** |
|:---|:---|:---|:---|
| **gold_price_streaming.py** | Traite les flux Kafka | `gold-price` | HDFS Parquet (partitionnÃ©) |
| **store_news_to_hdfs.py** | Convertit JSON â†’ Parquet | JSON | HDFS Parquet |
| **analyze_news.py** | Analyse avec Gemini AI | ActualitÃ©s | Cassandra |

</div>

### ğŸ“¤ **3. Chargement**

**load.py** : Lit les fichiers Parquet depuis HDFS, les charge dans Snowflake avec des opÃ©rations MERGE pour Ã©viter les doublons, et met Ã  jour les tables `Dim_Date`, `Dim_Marche`, et `Fait_Prix_Or`.

### ğŸ“Š **4. Visualisation**

**gold_trading_dashboard.py** : Fournit une interface Streamlit avec trois modes :
- **ğŸ“ˆ Analyse Technique** : Graphiques en chandeliers, moyennes mobiles, corrÃ©lations
- **ğŸ“° Analyse Fondamentale** : Tableau des actualitÃ©s avec impact, statistiques par source
- **ğŸ’¬ Chat AI** : Interaction avec Gemini AI pour rÃ©pondre aux questions

---

## ğŸ¤– ModÃ¨les d'Analyse

### ğŸ¯ **EntraÃ®nement Initial**

**train_model.py** :
- Utilise un modÃ¨le de **rÃ©gression linÃ©aire** pour prÃ©dire les prix de l'or Ã  t+30 minutes
- BasÃ© sur les 30 minutes prÃ©cÃ©dentes
- DonnÃ©es lues depuis `/app/gold_price_historical.csv`
- ModÃ¨le loggÃ© dans **MLflow** avec la mÃ©trique RMSE

### ğŸ”„ **Fine-Tuning**

**fine_tune_model.py** :
- Fine-tune un modÃ¨le existant avec les donnÃ©es d'un mois spÃ©cifique
- DonnÃ©es lues depuis **HDFS**
- Ajoute des features de dÃ©calage (lags)
- Enregistre le modÃ¨le mis Ã  jour dans **MLflow**

---

## ğŸ“Š Tableau de Bord Streamlit

<div align="center">

![Dashboard](https://img.shields.io/badge/Streamlit-Dashboard-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)

</div>

Le tableau de bord (`gold_trading_dashboard.py`) offre :

### ğŸ“ˆ **Analyse Technique**
- ğŸ•¯ï¸ Graphiques en chandeliers pour les prix de l'or
- ğŸ“Š Moyennes mobiles (7 et 30 jours)
- ğŸ”— CorrÃ©lations entre prix de l'or, S&P 500, et taux fÃ©dÃ©raux
- ğŸ“ˆ Statistiques descriptives

### ğŸ“° **Analyse Fondamentale**
- ğŸ“‹ Tableau des actualitÃ©s avec liens cliquables et impacts (Ã©valuÃ©s via Gemini AI)
- ğŸ“Š Statistiques sur les sources d'actualitÃ©s

### ğŸ’¬ **Chat AI**
- ğŸ¤– Interface interactive pour poser des questions sur le marchÃ© de l'or
- âš¡ AlimentÃ©e par Gemini AI

---

## ğŸ‘ï¸ Surveillance et Logging

### ğŸš¨ **Monitoring AutomatisÃ©**

**monitor_spark.py** : Un DAG Airflow vÃ©rifie les logs Spark (`spark.log`) pour dÃ©tecter les erreurs et envoie des alertes via un webhook Discord.

### ğŸ“ **SystÃ¨me de Logging**

Les scripts Python utilisent le module `logging` pour journaliser les opÃ©rations :

<div align="center">

| ğŸ“Š **Niveau** | ğŸ¯ **Utilisation** |
|:---|:---|
| ğŸ’š **INFO** | OpÃ©rations normales |
| âš ï¸ **WARNING** | Avertissements |
| ğŸ”´ **ERROR** | Erreurs critiques |

</div>

---

## ğŸ“¥ Instructions d'Installation

### 1ï¸âƒ£ **Cloner le RÃ©pertoire**
```bash
git clone https://github.com/rabiizahnoune/PFE_Data_Youcode
cd gold_price_project
```

### 2ï¸âƒ£ **Lancer Docker Compose**
```bash
docker-compose up -d
```

### 3ï¸âƒ£ **AccÃ©der aux Services**

<div align="center">

| ğŸŒ **Service** | ğŸ”— **URL** | ğŸ”‘ **Identifiants** |
|:---|:---|:---|
| **ğŸ”„ Airflow** | http://localhost:8080 | admin/admin |
| **ğŸ—ƒï¸ HDFS NameNode** | http://localhost:9870 | - |
| **ğŸ¤– MLflow** | http://localhost:5000 | - |
| **ğŸ“Š Streamlit** | http://localhost:8050 | - |

</div>

### 4ï¸âƒ£ **ExÃ©cuter les DAGs Airflow**
Activez les DAGs dans l'interface Airflow pour lancer les pipelines.

---

## ğŸš€ Utilisation

### ğŸ“Š **1. Extraction des DonnÃ©es**
- â–¶ï¸ ExÃ©cutez le DAG `extract_gold` pour collecter les donnÃ©es financiÃ¨res
- â–¶ï¸ ExÃ©cutez le DAG `news_batch` pour ingÃ©rer les actualitÃ©s

### âš¡ **2. Traitement et Chargement**
- ğŸ”„ Le DAG `load` charge les donnÃ©es dans Snowflake
- âš¡ Les scripts Spark (`gold_price_streaming.py`, `store_news_to_hdfs.py`, `analyze_news.py`) traitent les flux de donnÃ©es

### ğŸ“Š **3. Visualisation**
- ğŸŒ AccÃ©dez au tableau de bord Streamlit Ã  http://localhost:8050
- ğŸ“… SÃ©lectionnez l'annÃ©e, la pÃ©riode, et le type d'analyse (Technique, Fondamentale, Chat AI)

### ğŸ‘ï¸ **4. Surveillance**
- ğŸ“‹ VÃ©rifiez les logs dans Airflow et les alertes Discord pour les erreurs

---

## ğŸ¤ Contributions et Maintenance

### ğŸ‘¥ **Contributeurs**
Ajoutez des fonctionnalitÃ©s via des pull requests.

### ğŸ”§ **Maintenance**

<div align="center">

| ğŸ”§ **TÃ¢che** | ğŸ“… **FrÃ©quence** |
|:---|:---|
| ğŸ”‘ Mise Ã  jour des clÃ©s API | Si expiration |
| ğŸ“‹ VÃ©rification des logs Spark et Airflow | RÃ©guliÃ¨re |
| ğŸ¤– Fine-tuning des modÃ¨les | PÃ©riodique avec `fine_tune_model.py` |

</div>

---

<div align="center">

---

**Â© 2024 Gold Analytics Pro** 

*ğŸ† Plateforme Professionnelle d'Analyse de MarchÃ©*

![Footer](https://img.shields.io/badge/Made_with-â¤ï¸_and_â˜•-red?style=for-the-badge)

---

</div>
