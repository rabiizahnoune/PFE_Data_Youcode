[2025-05-09T10:09:35.714+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: gold_pipeline.transform_gold_data manual__2025-05-09T10:08:46.980175+00:00 [queued]>
[2025-05-09T10:09:35.726+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: gold_pipeline.transform_gold_data manual__2025-05-09T10:08:46.980175+00:00 [queued]>
[2025-05-09T10:09:35.727+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 1
[2025-05-09T10:09:35.746+0000] {taskinstance.py:1380} INFO - Executing <Task(PythonOperator): transform_gold_data> on 2025-05-09 10:08:46.980175+00:00
[2025-05-09T10:09:35.755+0000] {standard_task_runner.py:57} INFO - Started process 826 to run task
[2025-05-09T10:09:35.760+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'gold_pipeline', 'transform_gold_data', 'manual__2025-05-09T10:08:46.980175+00:00', '--job-id', '50', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpjunswxqr']
[2025-05-09T10:09:35.763+0000] {standard_task_runner.py:85} INFO - Job 50: Subtask transform_gold_data
[2025-05-09T10:09:35.815+0000] {task_command.py:415} INFO - Running <TaskInstance: gold_pipeline.transform_gold_data manual__2025-05-09T10:08:46.980175+00:00 [running]> on host 749db00b1372
[2025-05-09T10:09:35.906+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='gold_pipeline' AIRFLOW_CTX_TASK_ID='transform_gold_data' AIRFLOW_CTX_EXECUTION_DATE='2025-05-09T10:08:46.980175+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-09T10:08:46.980175+00:00'
[2025-05-09T10:09:35.909+0000] {client.py:724} INFO - Reading file '/gold_datalake/raw/gold_prices/2025-05-09.csv'.
[2025-05-09T10:09:36.073+0000] {client.py:724} INFO - Reading file '/gold_datalake/raw/fed_rates/2025-05-09.csv'.
[2025-05-09T10:09:36.105+0000] {client.py:724} INFO - Reading file '/gold_datalake/raw/sp500/2025-05-09.csv'.
[2025-05-09T10:09:36.139+0000] {logging_mixin.py:151} INFO - Dates uniques dans gold_df: <DatetimeArray>
['2025-04-09 00:00:00', '2025-04-09 04:00:00', '2025-04-09 08:00:00',
 '2025-04-09 12:00:00', '2025-04-09 16:00:00']
Length: 5, dtype: datetime64[ns]
[2025-05-09T10:09:36.140+0000] {logging_mixin.py:151} INFO - Dates uniques dans sp500_df: <DatetimeArray>
['2025-04-09 09:30:00', '2025-04-09 10:30:00', '2025-04-09 11:30:00',
 '2025-04-09 12:30:00', '2025-04-09 13:30:00']
Length: 5, dtype: datetime64[ns]
[2025-05-09T10:09:36.150+0000] {logging_mixin.py:151} INFO - Dates uniques dans sp500_4h: <DatetimeArray>
['2025-04-09 08:00:00', '2025-04-09 12:00:00', '2025-04-10 08:00:00',
 '2025-04-10 12:00:00', '2025-04-11 08:00:00']
Length: 5, dtype: datetime64[ns]
[2025-05-09T10:09:36.151+0000] {logging_mixin.py:151} INFO - Dates uniques dans calendar_df: <DatetimeArray>
['2025-04-09 00:00:00', '2025-04-09 04:00:00', '2025-04-09 08:00:00',
 '2025-04-09 12:00:00', '2025-04-09 16:00:00']
Length: 5, dtype: datetime64[ns]
[2025-05-09T10:09:36.169+0000] {logging_mixin.py:151} INFO - Colonnes dans merged_df: ['date', 'source_name', 'ticker_symbol', 'open_price', 'prix_or', 'volume_or', 'ingestion_timestamp', 'prix_sp500', 'volume_sp500', 'taux_fed']
[2025-05-09T10:09:36.169+0000] {logging_mixin.py:151} INFO - Taille de merged_df: (186, 10)
[2025-05-09T10:09:36.175+0000] {logging_mixin.py:151} INFO - Échantillon de merged_df:
                 date source_name ticker_symbol   open_price      prix_or  volume_or         ingestion_timestamp   prix_sp500  volume_sp500  taux_fed
0 2025-04-09 00:00:00    yfinance          GC=F  3018.600098  3059.000000    40530.0  2025-05-09T10:09:10.894292          NaN           NaN      4.33
1 2025-04-09 04:00:00    yfinance          GC=F  3059.100098  3084.500000    43556.0  2025-05-09T10:09:10.894372          NaN           NaN      4.33
2 2025-04-09 08:00:00    yfinance          GC=F  3084.800049  3102.100098    77740.0  2025-05-09T10:09:10.894424  5005.896647  1.013395e+09      4.33
3 2025-04-09 12:00:00    yfinance          GC=F  3102.300049  3110.600098    75408.0  2025-05-09T10:09:10.894472  5383.929932  3.852815e+09      4.33
4 2025-04-09 16:00:00    yfinance          GC=F  3110.600098  3101.199951     6456.0  2025-05-09T10:09:10.894518          NaN           NaN      4.33
[2025-05-09T10:09:36.181+0000] {logging_mixin.py:151} INFO - Taille de merged_df après dropna: (186, 10)
[2025-05-09T10:09:36.198+0000] {client.py:496} INFO - Writing to '/gold_datalake/processed/gold_prices_2025-05-09.parquet'.
[2025-05-09T10:09:36.240+0000] {logging_mixin.py:151} INFO - Fichier écrit avec succès dans HDFS: /gold_datalake/processed/gold_prices_2025-05-09.parquet
[2025-05-09T10:09:36.244+0000] {client.py:496} INFO - Writing to '/gold_datalake/processed/dim_date_2025-05-09.parquet'.
[2025-05-09T10:09:36.288+0000] {logging_mixin.py:151} INFO - Fichier écrit avec succès dans HDFS: /gold_datalake/processed/dim_date_2025-05-09.parquet
[2025-05-09T10:09:36.291+0000] {client.py:496} INFO - Writing to '/gold_datalake/processed/dim_marche_2025-05-09.parquet'.
[2025-05-09T10:09:36.338+0000] {logging_mixin.py:151} INFO - Fichier écrit avec succès dans HDFS: /gold_datalake/processed/dim_marche_2025-05-09.parquet
[2025-05-09T10:09:36.339+0000] {python.py:194} INFO - Done. Returned value was: (                date_id      prix_or  ...  variation_or_pct  variation_or_abs
0   2025-04-09 00:00:00  3059.000000  ...          0.000000          0.000000
1   2025-04-09 04:00:00  3084.500000  ...          0.833606         25.500000
2   2025-04-09 08:00:00  3102.100098  ...          1.408960         43.100098
3   2025-04-09 12:00:00  3110.600098  ...          1.686829         51.600098
4   2025-04-09 16:00:00  3101.199951  ...          1.379534         42.199951
..                  ...          ...  ...               ...               ...
181 2025-05-09 04:00:00  3312.399902  ...          8.283750        253.399902
182 2025-05-09 08:00:00  3312.399902  ...          8.283750        253.399902
183 2025-05-09 12:00:00  3312.399902  ...          8.283750        253.399902
184 2025-05-09 16:00:00  3312.399902  ...          8.283750        253.399902
185 2025-05-09 20:00:00  3312.399902  ...          8.283750        253.399902

[186 rows x 7 columns],                 date_id  jour  mois  annee  heure trimestre
0   2025-04-09 00:00:00     9     4   2025      0    2025Q2
1   2025-04-09 04:00:00     9     4   2025      4    2025Q2
2   2025-04-09 08:00:00     9     4   2025      8    2025Q2
3   2025-04-09 12:00:00     9     4   2025     12    2025Q2
4   2025-04-09 16:00:00     9     4   2025     16    2025Q2
..                  ...   ...   ...    ...    ...       ...
181 2025-05-09 04:00:00     9     5   2025      4    2025Q2
182 2025-05-09 08:00:00     9     5   2025      8    2025Q2
183 2025-05-09 12:00:00     9     5   2025     12    2025Q2
184 2025-05-09 16:00:00     9     5   2025     16    2025Q2
185 2025-05-09 20:00:00     9     5   2025     20    2025Q2

[186 rows x 6 columns],                 date_id  volume_sp500  marche_id
0   2025-04-09 00:00:00           NaN          1
1   2025-04-09 04:00:00           NaN          2
2   2025-04-09 08:00:00  1.013395e+09          3
3   2025-04-09 12:00:00  3.852815e+09          4
4   2025-04-09 16:00:00  3.293914e+09          5
..                  ...           ...        ...
181 2025-05-09 04:00:00  1.259868e+09        182
182 2025-05-09 08:00:00  1.259868e+09        183
183 2025-05-09 12:00:00  1.259868e+09        184
184 2025-05-09 16:00:00  1.259868e+09        185
185 2025-05-09 20:00:00  1.259868e+09        186

[186 rows x 3 columns])
[2025-05-09T10:09:36.403+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=gold_pipeline, task_id=transform_gold_data, execution_date=20250509T100846, start_date=20250509T100935, end_date=20250509T100936
[2025-05-09T10:09:36.455+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-05-09T10:09:36.484+0000] {taskinstance.py:2776} INFO - 1 downstream tasks scheduled from follow-on schedule check
