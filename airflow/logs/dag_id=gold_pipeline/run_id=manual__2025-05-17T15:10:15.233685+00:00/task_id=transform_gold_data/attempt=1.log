[2025-05-17T15:11:25.375+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: gold_pipeline.transform_gold_data manual__2025-05-17T15:10:15.233685+00:00 [queued]>
[2025-05-17T15:11:25.386+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: gold_pipeline.transform_gold_data manual__2025-05-17T15:10:15.233685+00:00 [queued]>
[2025-05-17T15:11:25.387+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 1
[2025-05-17T15:11:25.404+0000] {taskinstance.py:1380} INFO - Executing <Task(PythonOperator): transform_gold_data> on 2025-05-17 15:10:15.233685+00:00
[2025-05-17T15:11:25.413+0000] {standard_task_runner.py:57} INFO - Started process 772 to run task
[2025-05-17T15:11:25.417+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'gold_pipeline', 'transform_gold_data', 'manual__2025-05-17T15:10:15.233685+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmpi6m7rgl_']
[2025-05-17T15:11:25.421+0000] {standard_task_runner.py:85} INFO - Job 3: Subtask transform_gold_data
[2025-05-17T15:11:25.495+0000] {task_command.py:415} INFO - Running <TaskInstance: gold_pipeline.transform_gold_data manual__2025-05-17T15:10:15.233685+00:00 [running]> on host 75a565b94570
[2025-05-17T15:11:25.627+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='gold_pipeline' AIRFLOW_CTX_TASK_ID='transform_gold_data' AIRFLOW_CTX_EXECUTION_DATE='2025-05-17T15:10:15.233685+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-17T15:10:15.233685+00:00'
[2025-05-17T15:11:25.630+0000] {client.py:724} INFO - Reading file '/gold_datalake/raw/gold_prices/2025-05-17.csv'.
[2025-05-17T15:11:25.819+0000] {client.py:724} INFO - Reading file '/gold_datalake/raw/fed_rates/2025-05-17.csv'.
[2025-05-17T15:11:25.841+0000] {client.py:724} INFO - Reading file '/gold_datalake/raw/sp500/2025-05-17.csv'.
[2025-05-17T15:11:25.885+0000] {logging_mixin.py:151} INFO - Dates uniques dans gold_df: <DatetimeArray>
['2025-04-17 00:00:00', '2025-04-17 04:00:00', '2025-04-17 08:00:00',
 '2025-04-17 12:00:00', '2025-04-17 16:00:00']
Length: 5, dtype: datetime64[ns]
[2025-05-17T15:11:25.886+0000] {logging_mixin.py:151} INFO - Dates uniques dans sp500_df: <DatetimeArray>
['2025-04-17 09:30:00', '2025-04-17 10:30:00', '2025-04-17 11:30:00',
 '2025-04-17 12:30:00', '2025-04-17 13:30:00']
Length: 5, dtype: datetime64[ns]
[2025-05-17T15:11:25.896+0000] {logging_mixin.py:151} INFO - Dates uniques dans sp500_4h: <DatetimeArray>
['2025-04-17 08:00:00', '2025-04-17 12:00:00', '2025-04-21 08:00:00',
 '2025-04-21 12:00:00', '2025-04-22 08:00:00']
Length: 5, dtype: datetime64[ns]
[2025-05-17T15:11:25.899+0000] {logging_mixin.py:151} INFO - Dates uniques dans calendar_df: <DatetimeArray>
['2025-04-17 00:00:00', '2025-04-17 04:00:00', '2025-04-17 08:00:00',
 '2025-04-17 12:00:00', '2025-04-17 16:00:00']
Length: 5, dtype: datetime64[ns]
[2025-05-17T15:11:25.917+0000] {logging_mixin.py:151} INFO - Colonnes dans merged_df: ['date', 'source_name', 'ticker_symbol', 'open_price', 'prix_or', 'volume_or', 'ingestion_timestamp', 'prix_sp500', 'volume_sp500', 'taux_fed']
[2025-05-17T15:11:25.918+0000] {logging_mixin.py:151} INFO - Taille de merged_df: (186, 10)
[2025-05-17T15:11:25.929+0000] {logging_mixin.py:151} INFO - Échantillon de merged_df:
                 date source_name ticker_symbol   open_price      prix_or  volume_or         ingestion_timestamp   prix_sp500  volume_sp500  taux_fed
0 2025-04-17 00:00:00    yfinance          GC=F  3357.000000  3336.500000    26571.0  2025-05-17T15:10:49.704953          NaN           NaN      4.33
1 2025-04-17 04:00:00    yfinance          GC=F  3336.500000  3341.199951    26764.0  2025-05-17T15:10:49.705020          NaN           NaN      4.33
2 2025-04-17 08:00:00    yfinance          GC=F  3341.199951  3308.800049    85432.0  2025-05-17T15:10:49.705063  5288.119954  7.160882e+08      4.33
3 2025-04-17 12:00:00    yfinance          GC=F  3309.300049  3334.500000    31907.0  2025-05-17T15:10:49.705105  5296.062500  1.296482e+09      4.33
4 2025-04-17 16:00:00    yfinance          GC=F  3334.600098  3341.300049     3560.0  2025-05-17T15:10:49.705146          NaN           NaN      4.33
[2025-05-17T15:11:25.943+0000] {logging_mixin.py:151} INFO - Taille de merged_df après dropna: (186, 10)
[2025-05-17T15:11:25.983+0000] {client.py:496} INFO - Writing to '/gold_datalake/processed/gold_prices_2025-05-17.parquet'.
[2025-05-17T15:11:26.035+0000] {logging_mixin.py:151} INFO - Fichier écrit avec succès dans HDFS: /gold_datalake/processed/gold_prices_2025-05-17.parquet
[2025-05-17T15:11:26.043+0000] {client.py:496} INFO - Writing to '/gold_datalake/processed/dim_date_2025-05-17.parquet'.
[2025-05-17T15:11:26.106+0000] {logging_mixin.py:151} INFO - Fichier écrit avec succès dans HDFS: /gold_datalake/processed/dim_date_2025-05-17.parquet
[2025-05-17T15:11:26.112+0000] {client.py:496} INFO - Writing to '/gold_datalake/processed/dim_marche_2025-05-17.parquet'.
[2025-05-17T15:11:26.171+0000] {logging_mixin.py:151} INFO - Fichier écrit avec succès dans HDFS: /gold_datalake/processed/dim_marche_2025-05-17.parquet
[2025-05-17T15:11:26.172+0000] {python.py:194} INFO - Done. Returned value was: (                date_id      prix_or  ...  variation_or_pct  variation_or_abs
0   2025-04-17 00:00:00  3336.500000  ...          0.000000          0.000000
1   2025-04-17 04:00:00  3341.199951  ...          0.140865          4.699951
2   2025-04-17 08:00:00  3308.800049  ...         -0.830210        -27.699951
3   2025-04-17 12:00:00  3334.500000  ...         -0.059943         -2.000000
4   2025-04-17 16:00:00  3341.300049  ...          0.143865          4.800049
..                  ...          ...  ...               ...               ...
181 2025-05-17 04:00:00  3205.300049  ...         -3.932263       -131.199951
182 2025-05-17 08:00:00  3205.300049  ...         -3.932263       -131.199951
183 2025-05-17 12:00:00  3205.300049  ...         -3.932263       -131.199951
184 2025-05-17 16:00:00  3205.300049  ...         -3.932263       -131.199951
185 2025-05-17 20:00:00  3205.300049  ...         -3.932263       -131.199951

[186 rows x 7 columns],                 date_id  jour  mois  annee  heure trimestre
0   2025-04-17 00:00:00    17     4   2025      0    2025Q2
1   2025-04-17 04:00:00    17     4   2025      4    2025Q2
2   2025-04-17 08:00:00    17     4   2025      8    2025Q2
3   2025-04-17 12:00:00    17     4   2025     12    2025Q2
4   2025-04-17 16:00:00    17     4   2025     16    2025Q2
..                  ...   ...   ...    ...    ...       ...
181 2025-05-17 04:00:00    17     5   2025      4    2025Q2
182 2025-05-17 08:00:00    17     5   2025      8    2025Q2
183 2025-05-17 12:00:00    17     5   2025     12    2025Q2
184 2025-05-17 16:00:00    17     5   2025     16    2025Q2
185 2025-05-17 20:00:00    17     5   2025     20    2025Q2

[186 rows x 6 columns],                 date_id  volume_sp500  marche_id
0   2025-04-17 00:00:00           NaN          1
1   2025-04-17 04:00:00           NaN          2
2   2025-04-17 08:00:00  7.160882e+08          3
3   2025-04-17 12:00:00  1.296482e+09          4
4   2025-04-17 16:00:00  1.265446e+09          5
..                  ...           ...        ...
181 2025-05-17 04:00:00  1.120128e+09        182
182 2025-05-17 08:00:00  1.120128e+09        183
183 2025-05-17 12:00:00  1.120128e+09        184
184 2025-05-17 16:00:00  1.120128e+09        185
185 2025-05-17 20:00:00  1.120128e+09        186

[186 rows x 3 columns])
[2025-05-17T15:11:26.250+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=gold_pipeline, task_id=transform_gold_data, execution_date=20250517T151015, start_date=20250517T151125, end_date=20250517T151126
[2025-05-17T15:11:26.313+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-05-17T15:11:26.338+0000] {taskinstance.py:2776} INFO - 1 downstream tasks scheduled from follow-on schedule check
