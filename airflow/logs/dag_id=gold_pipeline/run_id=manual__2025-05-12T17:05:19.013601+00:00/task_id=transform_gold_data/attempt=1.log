[2025-05-12T17:06:14.585+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: gold_pipeline.transform_gold_data manual__2025-05-12T17:05:19.013601+00:00 [queued]>
[2025-05-12T17:06:14.604+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: gold_pipeline.transform_gold_data manual__2025-05-12T17:05:19.013601+00:00 [queued]>
[2025-05-12T17:06:14.605+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 1
[2025-05-12T17:06:14.623+0000] {taskinstance.py:1380} INFO - Executing <Task(PythonOperator): transform_gold_data> on 2025-05-12 17:05:19.013601+00:00
[2025-05-12T17:06:14.630+0000] {standard_task_runner.py:57} INFO - Started process 621 to run task
[2025-05-12T17:06:14.634+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'gold_pipeline', 'transform_gold_data', 'manual__2025-05-12T17:05:19.013601+00:00', '--job-id', '75', '--raw', '--subdir', 'DAGS_FOLDER/pipeline.py', '--cfg-path', '/tmp/tmp95_njdfj']
[2025-05-12T17:06:14.639+0000] {standard_task_runner.py:85} INFO - Job 75: Subtask transform_gold_data
[2025-05-12T17:06:14.700+0000] {task_command.py:415} INFO - Running <TaskInstance: gold_pipeline.transform_gold_data manual__2025-05-12T17:05:19.013601+00:00 [running]> on host 51d6065cf9f5
[2025-05-12T17:06:14.823+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='gold_pipeline' AIRFLOW_CTX_TASK_ID='transform_gold_data' AIRFLOW_CTX_EXECUTION_DATE='2025-05-12T17:05:19.013601+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-12T17:05:19.013601+00:00'
[2025-05-12T17:06:14.824+0000] {client.py:724} INFO - Reading file '/gold_datalake/raw/gold_prices/2025-05-12.csv'.
[2025-05-12T17:06:14.949+0000] {client.py:724} INFO - Reading file '/gold_datalake/raw/fed_rates/2025-05-12.csv'.
[2025-05-12T17:06:14.982+0000] {client.py:724} INFO - Reading file '/gold_datalake/raw/sp500/2025-05-12.csv'.
[2025-05-12T17:06:15.057+0000] {logging_mixin.py:151} INFO - Dates uniques dans gold_df: <DatetimeArray>
['2025-04-13 16:00:00', '2025-04-13 20:00:00', '2025-04-14 00:00:00',
 '2025-04-14 04:00:00', '2025-04-14 08:00:00']
Length: 5, dtype: datetime64[ns]
[2025-05-12T17:06:15.058+0000] {logging_mixin.py:151} INFO - Dates uniques dans sp500_df: <DatetimeArray>
['2025-04-14 09:30:00', '2025-04-14 10:30:00', '2025-04-14 11:30:00',
 '2025-04-14 12:30:00', '2025-04-14 13:30:00']
Length: 5, dtype: datetime64[ns]
[2025-05-12T17:06:15.073+0000] {logging_mixin.py:151} INFO - Dates uniques dans sp500_4h: <DatetimeArray>
['2025-04-14 08:00:00', '2025-04-14 12:00:00', '2025-04-15 08:00:00',
 '2025-04-15 12:00:00', '2025-04-16 08:00:00']
Length: 5, dtype: datetime64[ns]
[2025-05-12T17:06:15.078+0000] {logging_mixin.py:151} INFO - Dates uniques dans calendar_df: <DatetimeArray>
['2025-04-12 00:00:00', '2025-04-12 04:00:00', '2025-04-12 08:00:00',
 '2025-04-12 12:00:00', '2025-04-12 16:00:00']
Length: 5, dtype: datetime64[ns]
[2025-05-12T17:06:15.103+0000] {logging_mixin.py:151} INFO - Colonnes dans merged_df: ['date', 'source_name', 'ticker_symbol', 'open_price', 'prix_or', 'volume_or', 'ingestion_timestamp', 'prix_sp500', 'volume_sp500', 'taux_fed']
[2025-05-12T17:06:15.104+0000] {logging_mixin.py:151} INFO - Taille de merged_df: (186, 10)
[2025-05-12T17:06:15.116+0000] {logging_mixin.py:151} INFO - Échantillon de merged_df:
                 date source_name ticker_symbol  open_price  prix_or  volume_or ingestion_timestamp  prix_sp500  volume_sp500  taux_fed
0 2025-04-12 00:00:00         NaN           NaN         NaN      NaN        NaN                 NaN         NaN           NaN      4.33
1 2025-04-12 04:00:00         NaN           NaN         NaN      NaN        NaN                 NaN         NaN           NaN      4.33
2 2025-04-12 08:00:00         NaN           NaN         NaN      NaN        NaN                 NaN         NaN           NaN      4.33
3 2025-04-12 12:00:00         NaN           NaN         NaN      NaN        NaN                 NaN         NaN           NaN      4.33
4 2025-04-12 16:00:00         NaN           NaN         NaN      NaN        NaN                 NaN         NaN           NaN      4.33
[2025-05-12T17:06:15.129+0000] {logging_mixin.py:151} INFO - Taille de merged_df après dropna: (176, 10)
[2025-05-12T17:06:15.149+0000] {client.py:496} INFO - Writing to '/gold_datalake/processed/gold_prices_2025-05-12.parquet'.
[2025-05-12T17:06:15.204+0000] {logging_mixin.py:151} INFO - Fichier écrit avec succès dans HDFS: /gold_datalake/processed/gold_prices_2025-05-12.parquet
[2025-05-12T17:06:15.208+0000] {client.py:496} INFO - Writing to '/gold_datalake/processed/dim_date_2025-05-12.parquet'.
[2025-05-12T17:06:15.264+0000] {logging_mixin.py:151} INFO - Fichier écrit avec succès dans HDFS: /gold_datalake/processed/dim_date_2025-05-12.parquet
[2025-05-12T17:06:15.267+0000] {client.py:496} INFO - Writing to '/gold_datalake/processed/dim_marche_2025-05-12.parquet'.
[2025-05-12T17:06:15.319+0000] {logging_mixin.py:151} INFO - Fichier écrit avec succès dans HDFS: /gold_datalake/processed/dim_marche_2025-05-12.parquet
[2025-05-12T17:06:15.322+0000] {python.py:194} INFO - Done. Returned value was: (                date_id      prix_or  ...  variation_or_pct  variation_or_abs
10  2025-04-13 16:00:00  3240.699951  ...          0.000000          0.000000
11  2025-04-13 20:00:00  3247.600098  ...          0.212921          6.900146
12  2025-04-14 00:00:00  3243.300049  ...          0.080233          2.600098
13  2025-04-14 04:00:00  3239.100098  ...         -0.049368         -1.599854
14  2025-04-14 08:00:00  3214.600098  ...         -0.805377        -26.099854
..                  ...          ...  ...               ...               ...
181 2025-05-12 04:00:00  3287.000000  ...          1.428705         46.300049
182 2025-05-12 08:00:00  3287.000000  ...          1.428705         46.300049
183 2025-05-12 12:00:00  3287.000000  ...          1.428705         46.300049
184 2025-05-12 16:00:00  3287.000000  ...          1.428705         46.300049
185 2025-05-12 20:00:00  3287.000000  ...          1.428705         46.300049

[176 rows x 7 columns],                 date_id  jour  mois  annee  heure trimestre
10  2025-04-13 16:00:00    13     4   2025     16    2025Q2
11  2025-04-13 20:00:00    13     4   2025     20    2025Q2
12  2025-04-14 00:00:00    14     4   2025      0    2025Q2
13  2025-04-14 04:00:00    14     4   2025      4    2025Q2
14  2025-04-14 08:00:00    14     4   2025      8    2025Q2
..                  ...   ...   ...    ...    ...       ...
181 2025-05-12 04:00:00    12     5   2025      4    2025Q2
182 2025-05-12 08:00:00    12     5   2025      8    2025Q2
183 2025-05-12 12:00:00    12     5   2025     12    2025Q2
184 2025-05-12 16:00:00    12     5   2025     16    2025Q2
185 2025-05-12 20:00:00    12     5   2025     20    2025Q2

[176 rows x 6 columns],                 date_id  volume_sp500  marche_id
10  2025-04-13 16:00:00           NaN          1
11  2025-04-13 20:00:00           NaN          2
12  2025-04-14 00:00:00           NaN          3
13  2025-04-14 04:00:00           NaN          4
14  2025-04-14 08:00:00  7.750197e+08          5
..                  ...           ...        ...
181 2025-05-12 04:00:00  1.555969e+09        172
182 2025-05-12 08:00:00  1.590095e+09        173
183 2025-05-12 12:00:00  1.607920e+08        174
184 2025-05-12 16:00:00  1.607920e+08        175
185 2025-05-12 20:00:00  1.607920e+08        176

[176 rows x 3 columns])
[2025-05-12T17:06:15.406+0000] {taskinstance.py:1398} INFO - Marking task as SUCCESS. dag_id=gold_pipeline, task_id=transform_gold_data, execution_date=20250512T170519, start_date=20250512T170614, end_date=20250512T170615
[2025-05-12T17:06:15.449+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-05-12T17:06:15.497+0000] {taskinstance.py:2776} INFO - 1 downstream tasks scheduled from follow-on schedule check
