[2025-05-09T19:08:33.719+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: gold_news_pipeline.run_consumer manual__2025-05-09T19:08:26.179175+00:00 [queued]>
[2025-05-09T19:08:33.781+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: gold_news_pipeline.run_consumer manual__2025-05-09T19:08:26.179175+00:00 [queued]>
[2025-05-09T19:08:33.783+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 1
[2025-05-09T19:08:33.854+0000] {taskinstance.py:1380} INFO - Executing <Task(BashOperator): run_consumer> on 2025-05-09 19:08:26.179175+00:00
[2025-05-09T19:08:33.874+0000] {standard_task_runner.py:57} INFO - Started process 5175 to run task
[2025-05-09T19:08:33.950+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'gold_news_pipeline', 'run_consumer', 'manual__2025-05-09T19:08:26.179175+00:00', '--job-id', '61', '--raw', '--subdir', 'DAGS_FOLDER/dag_streaming.py', '--cfg-path', '/tmp/tmpyum64oc2']
[2025-05-09T19:08:33.956+0000] {standard_task_runner.py:85} INFO - Job 61: Subtask run_consumer
[2025-05-09T19:08:34.280+0000] {task_command.py:415} INFO - Running <TaskInstance: gold_news_pipeline.run_consumer manual__2025-05-09T19:08:26.179175+00:00 [running]> on host 666ef047fba4
[2025-05-09T19:08:34.602+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='gold_news_pipeline' AIRFLOW_CTX_TASK_ID='run_consumer' AIRFLOW_CTX_EXECUTION_DATE='2025-05-09T19:08:26.179175+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-09T19:08:26.179175+00:00'
[2025-05-09T19:08:34.611+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-05-09T19:08:34.615+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'docker exec gold_price_project-spark-1 spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,com.datastax.spark:spark-cassandra-connector_2.12:3.5.0 /scripts/spark_news.py']
[2025-05-09T19:08:34.651+0000] {subprocess.py:86} INFO - Output:
[2025-05-09T19:08:40.612+0000] {subprocess.py:93} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-05-09T19:08:40.712+0000] {subprocess.py:93} INFO - Ivy Default Cache set to: /root/.ivy2/cache
[2025-05-09T19:08:40.713+0000] {subprocess.py:93} INFO - The jars for the packages stored in: /root/.ivy2/jars
[2025-05-09T19:08:40.720+0000] {subprocess.py:93} INFO - org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
[2025-05-09T19:08:40.721+0000] {subprocess.py:93} INFO - com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency
[2025-05-09T19:08:40.722+0000] {subprocess.py:93} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-5fbf6d59-8897-4809-8c0c-c0f04ef2ce41;1.0
[2025-05-09T19:08:40.722+0000] {subprocess.py:93} INFO - 	confs: [default]
[2025-05-09T19:08:41.032+0000] {subprocess.py:93} INFO - 	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central
[2025-05-09T19:08:41.221+0000] {subprocess.py:93} INFO - 	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central
[2025-05-09T19:08:41.330+0000] {subprocess.py:93} INFO - 	found org.apache.kafka#kafka-clients;3.4.1 in central
[2025-05-09T19:08:41.578+0000] {subprocess.py:93} INFO - 	found org.lz4#lz4-java;1.8.0 in central
[2025-05-09T19:08:41.584+0000] {subprocess.py:93} INFO - 	found org.xerial.snappy#snappy-java;1.1.10.3 in central
[2025-05-09T19:08:41.662+0000] {subprocess.py:93} INFO - 	found org.slf4j#slf4j-api;2.0.7 in central
[2025-05-09T19:08:41.750+0000] {subprocess.py:93} INFO - 	found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
[2025-05-09T19:08:41.860+0000] {subprocess.py:93} INFO - 	found org.apache.hadoop#hadoop-client-api;3.3.4 in central
[2025-05-09T19:08:41.960+0000] {subprocess.py:93} INFO - 	found commons-logging#commons-logging;1.1.3 in central
[2025-05-09T19:08:42.209+0000] {subprocess.py:93} INFO - 	found com.google.code.findbugs#jsr305;3.0.0 in central
[2025-05-09T19:08:42.266+0000] {subprocess.py:93} INFO - 	found org.apache.commons#commons-pool2;2.11.1 in central
[2025-05-09T19:08:43.841+0000] {subprocess.py:93} INFO - 	found com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 in central
[2025-05-09T19:08:44.025+0000] {subprocess.py:93} INFO - 	found com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 in central
[2025-05-09T19:08:44.207+0000] {subprocess.py:93} INFO - 	found org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central
[2025-05-09T19:08:44.261+0000] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-core-shaded;4.13.0 in central
[2025-05-09T19:08:44.303+0000] {subprocess.py:93} INFO - 	found com.datastax.oss#native-protocol;1.5.0 in central
[2025-05-09T19:08:44.363+0000] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central
[2025-05-09T19:08:44.414+0000] {subprocess.py:93} INFO - 	found com.typesafe#config;1.4.1 in central
[2025-05-09T19:08:44.460+0000] {subprocess.py:93} INFO - 	found io.dropwizard.metrics#metrics-core;4.1.18 in central
[2025-05-09T19:08:44.507+0000] {subprocess.py:93} INFO - 	found org.hdrhistogram#HdrHistogram;2.1.12 in central
[2025-05-09T19:08:44.534+0000] {subprocess.py:93} INFO - 	found org.reactivestreams#reactive-streams;1.0.3 in central
[2025-05-09T19:08:44.568+0000] {subprocess.py:93} INFO - 	found com.github.stephenc.jcip#jcip-annotations;1.0-1 in central
[2025-05-09T19:08:44.611+0000] {subprocess.py:93} INFO - 	found com.github.spotbugs#spotbugs-annotations;3.1.12 in central
[2025-05-09T19:08:44.672+0000] {subprocess.py:93} INFO - 	found com.google.code.findbugs#jsr305;3.0.2 in central
[2025-05-09T19:08:44.717+0000] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central
[2025-05-09T19:08:44.765+0000] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-query-builder;4.13.0 in central
[2025-05-09T19:08:44.981+0000] {subprocess.py:93} INFO - 	found org.apache.commons#commons-lang3;3.10 in central
[2025-05-09T19:08:45.042+0000] {subprocess.py:93} INFO - 	found com.thoughtworks.paranamer#paranamer;2.8 in central
[2025-05-09T19:08:45.062+0000] {subprocess.py:93} INFO - 	found org.scala-lang#scala-reflect;2.12.11 in central
[2025-05-09T19:08:45.168+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector_2.12/3.5.0/spark-cassandra-connector_2.12-3.5.0.jar ...
[2025-05-09T19:08:46.580+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector_2.12;3.5.0!spark-cassandra-connector_2.12.jar (1471ms)
[2025-05-09T19:08:46.665+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector-driver_2.12/3.5.0/spark-cassandra-connector-driver_2.12-3.5.0.jar ...
[2025-05-09T19:08:48.082+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0!spark-cassandra-connector-driver_2.12.jar (1478ms)
[2025-05-09T19:08:48.144+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-collection-compat_2.12/2.11.0/scala-collection-compat_2.12-2.11.0.jar ...
[2025-05-09T19:08:48.304+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] org.scala-lang.modules#scala-collection-compat_2.12;2.11.0!scala-collection-compat_2.12.jar (223ms)
[2025-05-09T19:08:48.356+0000] {subprocess.py:93} INFO - :: resolution report :: resolve 4380ms :: artifacts dl 3243ms
[2025-05-09T19:08:48.358+0000] {subprocess.py:93} INFO - 	:: modules in use:
[2025-05-09T19:08:48.359+0000] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]
[2025-05-09T19:08:48.361+0000] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]
[2025-05-09T19:08:48.366+0000] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]
[2025-05-09T19:08:48.372+0000] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]
[2025-05-09T19:08:48.380+0000] {subprocess.py:93} INFO - 	com.datastax.oss#native-protocol;1.5.0 from central in [default]
[2025-05-09T19:08:48.384+0000] {subprocess.py:93} INFO - 	com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 from central in [default]
[2025-05-09T19:08:48.385+0000] {subprocess.py:93} INFO - 	com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 from central in [default]
[2025-05-09T19:08:48.386+0000] {subprocess.py:93} INFO - 	com.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]
[2025-05-09T19:08:48.386+0000] {subprocess.py:93} INFO - 	com.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]
[2025-05-09T19:08:48.387+0000] {subprocess.py:93} INFO - 	com.google.code.findbugs#jsr305;3.0.2 from central in [default]
[2025-05-09T19:08:48.388+0000] {subprocess.py:93} INFO - 	com.thoughtworks.paranamer#paranamer;2.8 from central in [default]
[2025-05-09T19:08:48.388+0000] {subprocess.py:93} INFO - 	com.typesafe#config;1.4.1 from central in [default]
[2025-05-09T19:08:48.389+0000] {subprocess.py:93} INFO - 	commons-logging#commons-logging;1.1.3 from central in [default]
[2025-05-09T19:08:48.389+0000] {subprocess.py:93} INFO - 	io.dropwizard.metrics#metrics-core;4.1.18 from central in [default]
[2025-05-09T19:08:48.390+0000] {subprocess.py:93} INFO - 	org.apache.commons#commons-lang3;3.10 from central in [default]
[2025-05-09T19:08:48.391+0000] {subprocess.py:93} INFO - 	org.apache.commons#commons-pool2;2.11.1 from central in [default]
[2025-05-09T19:08:48.391+0000] {subprocess.py:93} INFO - 	org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
[2025-05-09T19:08:48.392+0000] {subprocess.py:93} INFO - 	org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
[2025-05-09T19:08:48.392+0000] {subprocess.py:93} INFO - 	org.apache.kafka#kafka-clients;3.4.1 from central in [default]
[2025-05-09T19:08:48.395+0000] {subprocess.py:93} INFO - 	org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]
[2025-05-09T19:08:48.395+0000] {subprocess.py:93} INFO - 	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]
[2025-05-09T19:08:48.396+0000] {subprocess.py:93} INFO - 	org.hdrhistogram#HdrHistogram;2.1.12 from central in [default]
[2025-05-09T19:08:48.397+0000] {subprocess.py:93} INFO - 	org.lz4#lz4-java;1.8.0 from central in [default]
[2025-05-09T19:08:48.399+0000] {subprocess.py:93} INFO - 	org.reactivestreams#reactive-streams;1.0.3 from central in [default]
[2025-05-09T19:08:48.401+0000] {subprocess.py:93} INFO - 	org.scala-lang#scala-reflect;2.12.11 from central in [default]
[2025-05-09T19:08:48.402+0000] {subprocess.py:93} INFO - 	org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]
[2025-05-09T19:08:48.403+0000] {subprocess.py:93} INFO - 	org.slf4j#slf4j-api;2.0.7 from central in [default]
[2025-05-09T19:08:48.404+0000] {subprocess.py:93} INFO - 	org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
[2025-05-09T19:08:48.404+0000] {subprocess.py:93} INFO - 	:: evicted modules:
[2025-05-09T19:08:48.405+0000] {subprocess.py:93} INFO - 	com.google.code.findbugs#jsr305;3.0.0 by [com.google.code.findbugs#jsr305;3.0.2] in [default]
[2025-05-09T19:08:48.406+0000] {subprocess.py:93} INFO - 	org.slf4j#slf4j-api;1.7.26 by [org.slf4j#slf4j-api;2.0.7] in [default]
[2025-05-09T19:08:48.407+0000] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-05-09T19:08:48.409+0000] {subprocess.py:93} INFO - 	|                  |            modules            ||   artifacts   |
[2025-05-09T19:08:48.410+0000] {subprocess.py:93} INFO - 	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-05-09T19:08:48.411+0000] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-05-09T19:08:48.412+0000] {subprocess.py:93} INFO - 	|      default     |   30  |   3   |   3   |   2   ||   28  |   3   |
[2025-05-09T19:08:48.414+0000] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-05-09T19:08:48.415+0000] {subprocess.py:93} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-5fbf6d59-8897-4809-8c0c-c0f04ef2ce41
[2025-05-09T19:08:48.421+0000] {subprocess.py:93} INFO - 	confs: [default]
[2025-05-09T19:08:48.727+0000] {subprocess.py:93} INFO - 	28 artifacts copied, 0 already retrieved (75061kB/343ms)
[2025-05-09T19:08:49.317+0000] {subprocess.py:93} INFO - 25/05/09 19:08:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-05-09T19:08:51.166+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO SparkContext: Running Spark version 3.5.1
[2025-05-09T19:08:51.166+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO SparkContext: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64
[2025-05-09T19:08:51.167+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO SparkContext: Java version 11.0.22
[2025-05-09T19:08:51.206+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO ResourceUtils: ==============================================================
[2025-05-09T19:08:51.208+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-05-09T19:08:51.210+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO ResourceUtils: ==============================================================
[2025-05-09T19:08:51.210+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO SparkContext: Submitted application: GoldNewsStreaming
[2025-05-09T19:08:51.254+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-05-09T19:08:51.279+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO ResourceProfile: Limiting resource is cpu
[2025-05-09T19:08:51.283+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-05-09T19:08:51.442+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO SecurityManager: Changing view acls to: root
[2025-05-09T19:08:51.443+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO SecurityManager: Changing modify acls to: root
[2025-05-09T19:08:51.445+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO SecurityManager: Changing view acls groups to:
[2025-05-09T19:08:51.446+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO SecurityManager: Changing modify acls groups to:
[2025-05-09T19:08:51.448+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
[2025-05-09T19:08:51.883+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO Utils: Successfully started service 'sparkDriver' on port 46579.
[2025-05-09T19:08:51.940+0000] {subprocess.py:93} INFO - 25/05/09 19:08:51 INFO SparkEnv: Registering MapOutputTracker
[2025-05-09T19:08:52.040+0000] {subprocess.py:93} INFO - 25/05/09 19:08:52 INFO SparkEnv: Registering BlockManagerMaster
[2025-05-09T19:08:52.072+0000] {subprocess.py:93} INFO - 25/05/09 19:08:52 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-05-09T19:08:52.073+0000] {subprocess.py:93} INFO - 25/05/09 19:08:52 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-05-09T19:08:52.080+0000] {subprocess.py:93} INFO - 25/05/09 19:08:52 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-05-09T19:08:52.166+0000] {subprocess.py:93} INFO - 25/05/09 19:08:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-4919aeaa-d32f-4e54-a668-6f8a098a1c1a
[2025-05-09T19:08:52.191+0000] {subprocess.py:93} INFO - 25/05/09 19:08:52 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-05-09T19:08:52.221+0000] {subprocess.py:93} INFO - 25/05/09 19:08:52 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-05-09T19:08:52.440+0000] {subprocess.py:93} INFO - 25/05/09 19:08:52 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-05-09T19:08:52.536+0000] {subprocess.py:93} INFO - 25/05/09 19:08:52 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-05-09T18:08:55.601+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at spark://b7f8b9fbbc8f:46579/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T18:08:55.603+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar at spark://b7f8b9fbbc8f:46579/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T18:08:55.603+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at spark://b7f8b9fbbc8f:46579/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T18:08:55.604+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at spark://b7f8b9fbbc8f:46579/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1746817731151
[2025-05-09T18:08:55.605+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://b7f8b9fbbc8f:46579/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1746817731151
[2025-05-09T18:08:55.605+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://b7f8b9fbbc8f:46579/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1746817731151
[2025-05-09T18:08:55.606+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at spark://b7f8b9fbbc8f:46579/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1746817731151
[2025-05-09T18:08:55.606+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://b7f8b9fbbc8f:46579/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1746817731151
[2025-05-09T18:08:55.607+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://b7f8b9fbbc8f:46579/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1746817731151
[2025-05-09T18:08:55.607+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://b7f8b9fbbc8f:46579/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1746817731151
[2025-05-09T18:08:55.608+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://b7f8b9fbbc8f:46579/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1746817731151
[2025-05-09T18:08:55.609+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar at spark://b7f8b9fbbc8f:46579/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.311+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar at spark://b7f8b9fbbc8f:46579/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.312+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar at spark://b7f8b9fbbc8f:46579/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.312+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar at spark://b7f8b9fbbc8f:46579/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.313+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at spark://b7f8b9fbbc8f:46579/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1746817731151
[2025-05-09T19:08:55.315+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at spark://b7f8b9fbbc8f:46579/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1746817731151
[2025-05-09T19:08:55.315+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at spark://b7f8b9fbbc8f:46579/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1746817731151
[2025-05-09T19:08:55.316+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at spark://b7f8b9fbbc8f:46579/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.317+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at spark://b7f8b9fbbc8f:46579/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1746817731151
[2025-05-09T19:08:55.317+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar at spark://b7f8b9fbbc8f:46579/jars/com.typesafe_config-1.4.1.jar with timestamp 1746817731151
[2025-05-09T19:08:55.318+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at spark://b7f8b9fbbc8f:46579/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1746817731151
[2025-05-09T19:08:55.318+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at spark://b7f8b9fbbc8f:46579/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1746817731151
[2025-05-09T19:08:55.319+0000] {subprocess.py:93} INFO - 25/05/09 18:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at spark://b7f8b9fbbc8f:46579/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1746817731151
[2025-05-09T19:08:55.319+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at spark://b7f8b9fbbc8f:46579/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1746817731151
[2025-05-09T19:08:55.320+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at spark://b7f8b9fbbc8f:46579/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1746817731151
[2025-05-09T19:08:55.320+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at spark://b7f8b9fbbc8f:46579/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1746817731151
[2025-05-09T19:08:55.321+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar at spark://b7f8b9fbbc8f:46579/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.321+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.323+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
[2025-05-09T19:08:55.342+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar at file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.343+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-05-09T19:08:55.355+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.355+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
[2025-05-09T19:08:55.362+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1746817731151
[2025-05-09T19:08:55.363+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.kafka_kafka-clients-3.4.1.jar
[2025-05-09T19:08:55.378+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1746817731151
[2025-05-09T19:08:55.379+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.commons_commons-pool2-2.11.1.jar
[2025-05-09T19:08:55.388+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1746817731151
[2025-05-09T19:08:55.389+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2025-05-09T19:08:55.475+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.476+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.lz4_lz4-java-1.8.0.jar
[2025-05-09T19:08:55.492+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1746817731151
[2025-05-09T19:08:55.493+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2025-05-09T19:08:55.502+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1746817731151
[2025-05-09T19:08:55.503+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.slf4j_slf4j-api-2.0.7.jar
[2025-05-09T19:08:55.508+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1746817731151
[2025-05-09T19:08:55.510+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2025-05-09T19:08:55.668+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1746817731151
[2025-05-09T19:08:55.669+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/commons-logging_commons-logging-1.1.3.jar
[2025-05-09T19:08:55.674+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar at file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.674+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-05-09T19:08:55.685+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar at file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.686+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-05-09T19:08:55.692+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar at file:///root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.694+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-05-09T19:08:55.730+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar at file:///root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.730+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-05-09T19:08:55.734+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at file:///root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1746817731151
[2025-05-09T19:08:55.735+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.commons_commons-lang3-3.10.jar
[2025-05-09T19:08:55.742+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at file:///root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1746817731151
[2025-05-09T19:08:55.743+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-05-09T19:08:55.750+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at file:///root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1746817731151
[2025-05-09T19:08:55.751+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.scala-lang_scala-reflect-2.12.11.jar
[2025-05-09T19:08:55.768+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at file:///root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.769+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_native-protocol-1.5.0.jar
[2025-05-09T19:08:55.775+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at file:///root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1746817731151
[2025-05-09T19:08:55.775+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-05-09T19:08:55.806+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar at file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar with timestamp 1746817731151
[2025-05-09T19:08:55.807+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/com.typesafe_config-1.4.1.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.typesafe_config-1.4.1.jar
[2025-05-09T19:08:55.814+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at file:///root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1746817731151
[2025-05-09T19:08:55.814+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-05-09T19:08:55.822+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at file:///root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1746817731151
[2025-05-09T19:08:55.823+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-05-09T19:08:55.831+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at file:///root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1746817731151
[2025-05-09T19:08:55.832+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-05-09T19:08:55.836+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at file:///root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1746817731151
[2025-05-09T19:08:55.837+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-05-09T19:08:55.845+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at file:///root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1746817731151
[2025-05-09T19:08:55.846+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-05-09T19:08:55.851+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1746817731151
[2025-05-09T19:08:55.851+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-05-09T19:08:55.856+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar at file:///root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1746817731151
[2025-05-09T19:08:55.858+0000] {subprocess.py:93} INFO - 25/05/09 19:08:55 INFO Utils: Copying /root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-05-09T19:08:56.169+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Starting executor ID driver on host b7f8b9fbbc8f
[2025-05-09T19:08:56.170+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64
[2025-05-09T19:08:56.171+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Java version 11.0.22
[2025-05-09T19:08:56.188+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-05-09T19:08:56.189+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@2a51ab71 for default.
[2025-05-09T19:08:56.216+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:56.251+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
[2025-05-09T19:08:56.256+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1746817731151
[2025-05-09T19:08:56.258+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.commons_commons-lang3-3.10.jar
[2025-05-09T19:08:56.262+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1746817731151
[2025-05-09T19:08:56.293+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2025-05-09T19:08:56.297+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1746817731151
[2025-05-09T19:08:56.327+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2025-05-09T19:08:56.331+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1746817731151
[2025-05-09T19:08:56.336+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-05-09T19:08:56.341+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1746817731151
[2025-05-09T19:08:56.343+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-05-09T19:08:56.350+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1746817731151
[2025-05-09T19:08:56.352+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-05-09T19:08:56.355+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1746817731151
[2025-05-09T19:08:56.366+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-05-09T19:08:56.372+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar with timestamp 1746817731151
[2025-05-09T19:08:56.374+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/com.typesafe_config-1.4.1.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.typesafe_config-1.4.1.jar
[2025-05-09T19:08:56.379+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1746817731151
[2025-05-09T19:08:56.383+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2025-05-09T19:08:56.389+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1746817731151
[2025-05-09T19:08:56.390+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-05-09T19:08:56.395+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:56.396+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
[2025-05-09T19:08:56.400+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1746817731151
[2025-05-09T19:08:56.401+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.slf4j_slf4j-api-2.0.7.jar
[2025-05-09T19:08:56.405+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1746817731151
[2025-05-09T19:08:56.406+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-05-09T19:08:56.410+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1746817731151
[2025-05-09T19:08:56.411+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-05-09T19:08:56.415+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1746817731151
[2025-05-09T19:08:56.416+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.commons_commons-pool2-2.11.1.jar
[2025-05-09T19:08:56.422+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:56.423+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_native-protocol-1.5.0.jar
[2025-05-09T19:08:56.427+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1746817731151
[2025-05-09T19:08:56.428+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/commons-logging_commons-logging-1.1.3.jar
[2025-05-09T19:08:56.432+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1746817731151
[2025-05-09T19:08:56.433+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-05-09T19:08:56.436+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1746817731151
[2025-05-09T19:08:56.437+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-05-09T19:08:56.442+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1746817731151
[2025-05-09T19:08:56.447+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.scala-lang_scala-reflect-2.12.11.jar
[2025-05-09T19:08:56.451+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:56.453+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-05-09T19:08:56.456+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1746817731151
[2025-05-09T19:08:56.458+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-05-09T19:08:56.461+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1746817731151
[2025-05-09T19:08:56.462+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-05-09T19:08:56.466+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1746817731151
[2025-05-09T19:08:56.466+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-05-09T19:08:56.470+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:56.471+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-05-09T19:08:56.478+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1746817731151
[2025-05-09T19:08:56.479+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.lz4_lz4-java-1.8.0.jar
[2025-05-09T19:08:56.482+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1746817731151
[2025-05-09T19:08:56.491+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.kafka_kafka-clients-3.4.1.jar
[2025-05-09T19:08:56.498+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:56.617+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO TransportClientFactory: Successfully created connection to b7f8b9fbbc8f/172.18.0.2:46579 after 84 ms (0 ms spent in bootstraps)
[2025-05-09T19:08:56.640+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp11445739041154825381.tmp
[2025-05-09T19:08:56.710+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp11445739041154825381.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-05-09T19:08:56.715+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to class loader default
[2025-05-09T19:08:56.718+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1746817731151
[2025-05-09T19:08:56.720+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp8075815233655320000.tmp
[2025-05-09T19:08:56.894+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp8075815233655320000.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2025-05-09T19:08:56.910+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.hadoop_hadoop-client-api-3.3.4.jar to class loader default
[2025-05-09T19:08:56.911+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1746817731151
[2025-05-09T19:08:56.911+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp9375909090153920714.tmp
[2025-05-09T19:08:56.931+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp9375909090153920714.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-05-09T19:08:56.938+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to class loader default
[2025-05-09T19:08:56.940+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1746817731151
[2025-05-09T19:08:56.941+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/org.reactivestreams_reactive-streams-1.0.3.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp16950900926018873692.tmp
[2025-05-09T19:08:56.942+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp16950900926018873692.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-05-09T19:08:56.947+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.reactivestreams_reactive-streams-1.0.3.jar to class loader default
[2025-05-09T19:08:56.948+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1746817731151
[2025-05-09T19:08:56.949+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp14683387170189638063.tmp
[2025-05-09T19:08:56.953+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp14683387170189638063.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-05-09T19:08:56.956+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to class loader default
[2025-05-09T19:08:56.956+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/com.typesafe_config-1.4.1.jar with timestamp 1746817731151
[2025-05-09T19:08:56.957+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/com.typesafe_config-1.4.1.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp1392563013954809838.tmp
[2025-05-09T19:08:56.960+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp1392563013954809838.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.typesafe_config-1.4.1.jar
[2025-05-09T19:08:56.963+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.typesafe_config-1.4.1.jar to class loader default
[2025-05-09T19:08:56.964+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1746817731151
[2025-05-09T19:08:56.964+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp9389587968488908281.tmp
[2025-05-09T19:08:56.968+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp9389587968488908281.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-05-09T19:08:56.971+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-query-builder-4.13.0.jar to class loader default
[2025-05-09T19:08:56.972+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:56.972+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp7123622313750882587.tmp
[2025-05-09T19:08:56.980+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp7123622313750882587.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-05-09T19:08:56.983+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to class loader default
[2025-05-09T19:08:56.984+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1746817731151
[2025-05-09T19:08:56.985+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp1627721862547801750.tmp
[2025-05-09T19:08:56.986+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp1627721862547801750.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-05-09T19:08:56.989+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to class loader default
[2025-05-09T19:08:56.990+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1746817731151
[2025-05-09T19:08:56.991+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp5196267362609916159.tmp
[2025-05-09T19:08:56.994+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp5196267362609916159.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-05-09T19:08:56.997+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to class loader default
[2025-05-09T19:08:56.998+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1746817731151
[2025-05-09T19:08:56.999+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp5328902923070546718.tmp
[2025-05-09T19:08:57.000+0000] {subprocess.py:93} INFO - 25/05/09 19:08:56 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp5328902923070546718.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-05-09T19:08:57.003+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to class loader default
[2025-05-09T19:08:57.004+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1746817731151
[2025-05-09T19:08:57.004+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp16824758198151225276.tmp
[2025-05-09T19:08:57.192+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp16824758198151225276.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2025-05-09T19:08:57.201+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to class loader default
[2025-05-09T19:08:57.202+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:57.203+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/com.datastax.oss_native-protocol-1.5.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp16372519691982575634.tmp
[2025-05-09T19:08:57.208+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp16372519691982575634.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_native-protocol-1.5.0.jar
[2025-05-09T19:08:57.212+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_native-protocol-1.5.0.jar to class loader default
[2025-05-09T19:08:57.213+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1746817731151
[2025-05-09T19:08:57.214+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp13077578668898763765.tmp
[2025-05-09T19:08:57.216+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp13077578668898763765.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-05-09T19:08:57.224+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/io.dropwizard.metrics_metrics-core-4.1.18.jar to class loader default
[2025-05-09T19:08:57.225+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1746817731151
[2025-05-09T19:08:57.229+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/com.google.code.findbugs_jsr305-3.0.2.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp7867671678513190383.tmp
[2025-05-09T19:08:57.230+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp7867671678513190383.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-05-09T19:08:57.230+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.google.code.findbugs_jsr305-3.0.2.jar to class loader default
[2025-05-09T19:08:57.231+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1746817731151
[2025-05-09T19:08:57.232+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp16597165132782464305.tmp
[2025-05-09T19:08:57.238+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp16597165132782464305.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.lz4_lz4-java-1.8.0.jar
[2025-05-09T19:08:57.243+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.lz4_lz4-java-1.8.0.jar to class loader default
[2025-05-09T19:08:57.244+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1746817731151
[2025-05-09T19:08:57.245+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp12217881059708198041.tmp
[2025-05-09T19:08:57.249+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp12217881059708198041.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-05-09T19:08:57.253+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.hdrhistogram_HdrHistogram-2.1.12.jar to class loader default
[2025-05-09T19:08:57.254+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1746817731151
[2025-05-09T19:08:57.256+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp12768844318333128136.tmp
[2025-05-09T19:08:57.257+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp12768844318333128136.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-05-09T19:08:57.262+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.thoughtworks.paranamer_paranamer-2.8.jar to class loader default
[2025-05-09T19:08:57.263+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1746817731151
[2025-05-09T19:08:57.264+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/org.scala-lang_scala-reflect-2.12.11.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp16680543255860402244.tmp
[2025-05-09T19:08:57.284+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp16680543255860402244.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.scala-lang_scala-reflect-2.12.11.jar
[2025-05-09T19:08:57.288+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.scala-lang_scala-reflect-2.12.11.jar to class loader default
[2025-05-09T19:08:57.291+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1746817731151
[2025-05-09T19:08:57.294+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp5229633381670816926.tmp
[2025-05-09T19:08:57.339+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp5229633381670816926.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-05-09T19:08:57.348+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to class loader default
[2025-05-09T19:08:57.349+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1746817731151
[2025-05-09T19:08:57.351+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp7790716663600568896.tmp
[2025-05-09T19:08:57.375+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp7790716663600568896.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.kafka_kafka-clients-3.4.1.jar
[2025-05-09T19:08:57.383+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.kafka_kafka-clients-3.4.1.jar to class loader default
[2025-05-09T19:08:57.383+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1746817731151
[2025-05-09T19:08:57.384+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp1701336718944809254.tmp
[2025-05-09T19:08:57.386+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp1701336718944809254.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.commons_commons-pool2-2.11.1.jar
[2025-05-09T19:08:57.393+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.commons_commons-pool2-2.11.1.jar to class loader default
[2025-05-09T19:08:57.398+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:57.399+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp15093526490760900058.tmp
[2025-05-09T19:08:57.400+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp15093526490760900058.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
[2025-05-09T19:08:57.413+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to class loader default
[2025-05-09T19:08:57.414+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1746817731151
[2025-05-09T19:08:57.414+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp15045022358022677702.tmp
[2025-05-09T19:08:57.415+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp15045022358022677702.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.slf4j_slf4j-api-2.0.7.jar
[2025-05-09T19:08:57.415+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.slf4j_slf4j-api-2.0.7.jar to class loader default
[2025-05-09T19:08:57.416+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1746817731151
[2025-05-09T19:08:57.416+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp13427176333648920978.tmp
[2025-05-09T19:08:57.417+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp13427176333648920978.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
[2025-05-09T19:08:57.420+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to class loader default
[2025-05-09T19:08:57.421+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1746817731151
[2025-05-09T19:08:57.422+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/org.apache.commons_commons-lang3-3.10.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp6405891492966114422.tmp
[2025-05-09T19:08:57.426+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp6405891492966114422.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.commons_commons-lang3-3.10.jar
[2025-05-09T19:08:57.429+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.apache.commons_commons-lang3-3.10.jar to class loader default
[2025-05-09T19:08:57.430+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1746817731151
[2025-05-09T19:08:57.431+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp13446865409079355187.tmp
[2025-05-09T19:08:57.432+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp13446865409079355187.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/commons-logging_commons-logging-1.1.3.jar
[2025-05-09T19:08:57.435+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/commons-logging_commons-logging-1.1.3.jar to class loader default
[2025-05-09T19:08:57.436+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Fetching spark://b7f8b9fbbc8f:46579/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1746817731151
[2025-05-09T19:08:57.437+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Fetching spark://b7f8b9fbbc8f:46579/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp10513825626600816456.tmp
[2025-05-09T19:08:57.445+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/fetchFileTemp10513825626600816456.tmp has been previously copied to /tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2025-05-09T19:08:57.449+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Executor: Adding file:/tmp/spark-2fc6862d-d283-4b9f-bfb2-d1fa697e63dc/userFiles-c0f941da-21d5-4689-8dbf-19305e9fcd46/org.xerial.snappy_snappy-java-1.1.10.3.jar to class loader default
[2025-05-09T19:08:57.467+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39589.
[2025-05-09T19:08:57.468+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO NettyBlockTransferService: Server created on b7f8b9fbbc8f:39589
[2025-05-09T19:08:57.471+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-05-09T19:08:57.482+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b7f8b9fbbc8f, 39589, None)
[2025-05-09T19:08:57.487+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO BlockManagerMasterEndpoint: Registering block manager b7f8b9fbbc8f:39589 with 434.4 MiB RAM, BlockManagerId(driver, b7f8b9fbbc8f, 39589, None)
[2025-05-09T19:08:57.493+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b7f8b9fbbc8f, 39589, None)
[2025-05-09T19:08:57.493+0000] {subprocess.py:93} INFO - 25/05/09 19:08:57 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b7f8b9fbbc8f, 39589, None)
[2025-05-09T19:08:58.356+0000] {subprocess.py:93} INFO - 25/05/09 19:08:58 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-05-09T19:08:58.361+0000] {subprocess.py:93} INFO - 25/05/09 19:08:58 INFO SharedState: Warehouse path is 'file:/opt/spark-apps/spark-warehouse'.
[2025-05-09T19:09:04.012+0000] {subprocess.py:93} INFO - 25/05/09 19:09:04 INFO DefaultMavenCoordinates: DataStax Java driver for Apache Cassandra(R) (com.datastax.oss:java-driver-core-shaded) version 4.13.0
[2025-05-09T19:09:04.235+0000] {subprocess.py:93} INFO - 25/05/09 19:09:04 INFO Native: Unable to load JNR native implementation. This could be normal if JNR is excluded from the classpath
[2025-05-09T19:09:04.236+0000] {subprocess.py:93} INFO - java.lang.NoClassDefFoundError: jnr/posix/POSIXHandler
[2025-05-09T19:09:04.237+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.os.Native$LibcLoader.load(Native.java:42)
[2025-05-09T19:09:04.238+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.os.Native.<clinit>(Native.java:59)
[2025-05-09T19:09:04.239+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.time.Clock.getInstance(Clock.java:41)
[2025-05-09T19:09:04.239+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.time.MonotonicTimestampGenerator.buildClock(MonotonicTimestampGenerator.java:109)
[2025-05-09T19:09:04.240+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.time.MonotonicTimestampGenerator.<init>(MonotonicTimestampGenerator.java:43)
[2025-05-09T19:09:04.241+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.time.AtomicTimestampGenerator.<init>(AtomicTimestampGenerator.java:52)
[2025-05-09T19:09:04.242+0000] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-05-09T19:09:04.242+0000] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)
[2025-05-09T19:09:04.243+0000] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)
[2025-05-09T19:09:04.244+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)
[2025-05-09T19:09:04.244+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.util.Reflection.resolveClass(Reflection.java:329)
[2025-05-09T19:09:04.245+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.util.Reflection.buildFromConfig(Reflection.java:235)
[2025-05-09T19:09:04.245+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.util.Reflection.buildFromConfig(Reflection.java:110)
[2025-05-09T19:09:04.246+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.context.DefaultDriverContext.buildTimestampGenerator(DefaultDriverContext.java:377)
[2025-05-09T19:09:04.247+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.util.concurrent.LazyReference.get(LazyReference.java:55)
[2025-05-09T19:09:04.247+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.context.DefaultDriverContext.getTimestampGenerator(DefaultDriverContext.java:773)
[2025-05-09T19:09:04.248+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.session.DefaultSession$SingleThreaded.init(DefaultSession.java:349)
[2025-05-09T19:09:04.249+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.session.DefaultSession$SingleThreaded.access$1100(DefaultSession.java:300)
[2025-05-09T19:09:04.249+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.session.DefaultSession.lambda$init$0(DefaultSession.java:146)
[2025-05-09T19:09:04.250+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.util.concurrent.PromiseTask.runTask(PromiseTask.java:98)
[2025-05-09T19:09:04.251+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.util.concurrent.PromiseTask.run(PromiseTask.java:106)
[2025-05-09T19:09:04.251+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.channel.DefaultEventLoop.run(DefaultEventLoop.java:54)
[2025-05-09T19:09:04.252+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
[2025-05-09T19:09:04.253+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2025-05-09T19:09:04.254+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2025-05-09T19:09:04.254+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Unknown Source)
[2025-05-09T19:09:04.255+0000] {subprocess.py:93} INFO - Caused by: java.lang.ClassNotFoundException: jnr.posix.POSIXHandler
[2025-05-09T19:09:04.255+0000] {subprocess.py:93} INFO - 	at java.base/java.net.URLClassLoader.findClass(Unknown Source)
[2025-05-09T19:09:04.256+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.ClassLoader.loadClass(Unknown Source)
[2025-05-09T19:09:04.257+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.ClassLoader.loadClass(Unknown Source)
[2025-05-09T19:09:04.258+0000] {subprocess.py:93} INFO - 	... 26 more
[2025-05-09T19:09:04.258+0000] {subprocess.py:93} INFO - 25/05/09 19:09:04 INFO Clock: Could not access native clock (see debug logs for details), falling back to Java system clock
[2025-05-09T19:09:04.956+0000] {subprocess.py:93} INFO - 25/05/09 19:09:04 INFO CassandraConnector: Connected to Cassandra cluster.
[2025-05-09T19:09:05.015+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
[2025-05-09T19:09:05.108+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO ResolveWriteToStream: Checkpoint root /tmp/spark-checkpoint/cassandra resolved to file:/tmp/spark-checkpoint/cassandra.
[2025-05-09T19:09:05.108+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-05-09T19:09:05.196+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/spark-checkpoint/cassandra/metadata using temp file file:/tmp/spark-checkpoint/cassandra/.metadata.d63ffde7-b263-4a3d-9958-2b456a7f21c9.tmp
[2025-05-09T19:09:05.301+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/spark-checkpoint/cassandra/.metadata.d63ffde7-b263-4a3d-9958-2b456a7f21c9.tmp to file:/tmp/spark-checkpoint/cassandra/metadata
[2025-05-09T19:09:05.357+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO MicroBatchExecution: Starting [id = eb0506f2-bf19-4afa-82b0-c9f5bf74b418, runId = f54b8c68-441c-405c-82c9-d1f0001c5b29]. Use file:/tmp/spark-checkpoint/cassandra to store the query checkpoint.
[2025-05-09T19:09:05.378+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@312b4dbf] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@26442ba1]
[2025-05-09T19:09:05.418+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO ResolveWriteToStream: Checkpoint root /tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037 resolved to file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037.
[2025-05-09T19:09:05.419+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-05-09T19:09:05.441+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO CheckpointFileManager: Writing atomically to file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/metadata using temp file file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/.metadata.bac053f2-81d4-42a6-8d18-19c8b610ccba.tmp
[2025-05-09T19:09:05.442+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO OffsetSeqLog: BatchIds found from listing:
[2025-05-09T19:09:05.445+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO OffsetSeqLog: BatchIds found from listing:
[2025-05-09T19:09:05.445+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO MicroBatchExecution: Starting new streaming query.
[2025-05-09T19:09:05.451+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO MicroBatchExecution: Stream started from {}
[2025-05-09T19:09:05.477+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO CheckpointFileManager: Renamed temp file file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/.metadata.bac053f2-81d4-42a6-8d18-19c8b610ccba.tmp to file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/metadata
[2025-05-09T19:09:05.493+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO MicroBatchExecution: Starting [id = e8a79812-275e-472f-9ede-b95cdfc5b5c0, runId = 3292e765-3448-466c-bedb-0f5bde4015ec]. Use file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037 to store the query checkpoint.
[2025-05-09T19:09:05.496+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@312b4dbf] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@26442ba1]
[2025-05-09T19:09:05.499+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO OffsetSeqLog: BatchIds found from listing:
[2025-05-09T19:09:05.500+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO OffsetSeqLog: BatchIds found from listing:
[2025-05-09T19:09:05.501+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO MicroBatchExecution: Starting new streaming query.
[2025-05-09T19:09:05.501+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO MicroBatchExecution: Stream started from {}
[2025-05-09T19:09:05.866+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO AdminClientConfig: AdminClientConfig values:
[2025-05-09T19:09:05.867+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-05-09T19:09:05.867+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-05-09T19:09:05.868+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-05-09T19:09:05.869+0000] {subprocess.py:93} INFO - 	client.id =
[2025-05-09T19:09:05.869+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-05-09T19:09:05.869+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-05-09T19:09:05.870+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-05-09T19:09:05.870+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-05-09T19:09:05.871+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-05-09T19:09:05.871+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-05-09T19:09:05.872+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-05-09T19:09:05.872+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-05-09T19:09:05.873+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-05-09T19:09:05.873+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-05-09T19:09:05.874+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-05-09T19:09:05.875+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-05-09T19:09:05.876+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-05-09T19:09:05.877+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-05-09T19:09:05.878+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-05-09T19:09:05.879+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-05-09T19:09:05.880+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-05-09T19:09:05.880+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-05-09T19:09:05.881+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-05-09T19:09:05.881+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-05-09T19:09:05.881+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-05-09T19:09:05.882+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-05-09T19:09:05.882+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-05-09T19:09:05.883+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-05-09T19:09:05.883+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-05-09T19:09:05.884+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-05-09T19:09:05.884+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-05-09T19:09:05.884+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-05-09T19:09:05.885+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-05-09T19:09:05.885+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-05-09T19:09:05.886+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-05-09T19:09:05.886+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-05-09T19:09:05.887+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-05-09T19:09:05.887+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-05-09T19:09:05.887+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-05-09T19:09:05.888+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-05-09T19:09:05.888+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-05-09T19:09:05.888+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-05-09T19:09:05.889+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-05-09T19:09:05.890+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-05-09T19:09:05.891+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-05-09T19:09:05.891+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-05-09T19:09:05.892+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-05-09T19:09:05.892+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-05-09T19:09:05.893+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-05-09T19:09:05.893+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-05-09T19:09:05.894+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-05-09T19:09:05.894+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-05-09T19:09:05.895+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-05-09T19:09:05.895+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-05-09T19:09:05.896+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-05-09T19:09:05.896+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-05-09T19:09:05.897+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-05-09T19:09:05.897+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-05-09T19:09:05.898+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-05-09T19:09:05.898+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-05-09T19:09:05.899+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-05-09T19:09:05.899+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-05-09T19:09:05.899+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-05-09T19:09:05.900+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-05-09T19:09:05.900+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-05-09T19:09:05.900+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-05-09T19:09:05.901+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-05-09T19:09:05.901+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-05-09T19:09:05.901+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-05-09T19:09:05.902+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:05.902+0000] {subprocess.py:93} INFO - 25/05/09 19:09:05 INFO AdminClientConfig: AdminClientConfig values:
[2025-05-09T19:09:05.902+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-05-09T19:09:05.903+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-05-09T19:09:05.903+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-05-09T19:09:05.904+0000] {subprocess.py:93} INFO - 	client.id =
[2025-05-09T19:09:05.904+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-05-09T19:09:05.905+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-05-09T19:09:05.906+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-05-09T19:09:05.906+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-05-09T19:09:05.907+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-05-09T19:09:05.907+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-05-09T19:09:05.908+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-05-09T19:09:05.909+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-05-09T19:09:05.909+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-05-09T19:09:05.910+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-05-09T19:09:05.910+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-05-09T19:09:05.911+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-05-09T19:09:05.911+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-05-09T19:09:05.912+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-05-09T19:09:05.913+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-05-09T19:09:05.913+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-05-09T19:09:05.913+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-05-09T19:09:05.914+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-05-09T19:09:05.914+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-05-09T19:09:05.915+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-05-09T19:09:05.915+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-05-09T19:09:05.916+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-05-09T19:09:05.916+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-05-09T19:09:05.916+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-05-09T19:09:05.917+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-05-09T19:09:05.917+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-05-09T19:09:05.917+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-05-09T19:09:05.918+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-05-09T19:09:05.918+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-05-09T19:09:05.919+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-05-09T19:09:05.920+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-05-09T19:09:05.920+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-05-09T19:09:05.920+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-05-09T19:09:05.921+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-05-09T19:09:05.921+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-05-09T19:09:05.922+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-05-09T19:09:05.922+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-05-09T19:09:05.922+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-05-09T19:09:05.923+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-05-09T19:09:05.923+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-05-09T19:09:05.924+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-05-09T19:09:05.924+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-05-09T19:09:05.924+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-05-09T19:09:05.925+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-05-09T19:09:05.925+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-05-09T19:09:05.925+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-05-09T19:09:05.926+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-05-09T19:09:05.926+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-05-09T19:09:05.927+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-05-09T19:09:05.927+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-05-09T19:09:05.927+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-05-09T19:09:05.928+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-05-09T19:09:05.929+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-05-09T19:09:05.929+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-05-09T19:09:05.930+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-05-09T19:09:05.931+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-05-09T19:09:05.931+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-05-09T19:09:05.932+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-05-09T19:09:05.932+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-05-09T19:09:05.933+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-05-09T19:09:05.933+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-05-09T19:09:05.934+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-05-09T19:09:05.934+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-05-09T19:09:05.935+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-05-09T19:09:05.935+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-05-09T19:09:05.936+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:06.019+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-05-09T19:09:06.020+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-05-09T19:09:06.024+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO AppInfoParser: Kafka version: 3.4.1
[2025-05-09T19:09:06.024+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89
[2025-05-09T19:09:06.025+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO AppInfoParser: Kafka startTimeMs: 1746817746018
[2025-05-09T19:09:06.027+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO AppInfoParser: Kafka version: 3.4.1
[2025-05-09T19:09:06.028+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89
[2025-05-09T19:09:06.029+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO AppInfoParser: Kafka startTimeMs: 1746817746018
[2025-05-09T19:09:06.620+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/spark-checkpoint/cassandra/sources/0/0 using temp file file:/tmp/spark-checkpoint/cassandra/sources/0/.0.12056192-65f4-446b-877b-71ddc32318e8.tmp
[2025-05-09T19:09:06.625+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/sources/0/0 using temp file file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/sources/0/.0.354b05d0-d1d1-4f24-86d1-d160443b240d.tmp
[2025-05-09T19:09:06.663+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/spark-checkpoint/cassandra/sources/0/.0.12056192-65f4-446b-877b-71ddc32318e8.tmp to file:/tmp/spark-checkpoint/cassandra/sources/0/0
[2025-05-09T19:09:06.663+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO KafkaMicroBatchStream: Initial offsets: {"gold-news":{"0":0}}
[2025-05-09T19:09:06.674+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/sources/0/.0.354b05d0-d1d1-4f24-86d1-d160443b240d.tmp to file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/sources/0/0
[2025-05-09T19:09:06.675+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO KafkaMicroBatchStream: Initial offsets: {"gold-news":{"0":0}}
[2025-05-09T19:09:06.703+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/offsets/0 using temp file file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/offsets/.0.de184df6-57d7-4848-b587-7e5bf1d0c997.tmp
[2025-05-09T19:09:06.704+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO CheckpointFileManager: Writing atomically to file:/tmp/spark-checkpoint/cassandra/offsets/0 using temp file file:/tmp/spark-checkpoint/cassandra/offsets/.0.7627eb58-4df2-4003-b80f-d71fc4e9350f.tmp
[2025-05-09T19:09:06.757+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/offsets/.0.de184df6-57d7-4848-b587-7e5bf1d0c997.tmp to file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/offsets/0
[2025-05-09T19:09:06.758+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1746817746689,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-05-09T19:09:06.763+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO CheckpointFileManager: Renamed temp file file:/tmp/spark-checkpoint/cassandra/offsets/.0.7627eb58-4df2-4003-b80f-d71fc4e9350f.tmp to file:/tmp/spark-checkpoint/cassandra/offsets/0
[2025-05-09T19:09:06.764+0000] {subprocess.py:93} INFO - 25/05/09 19:09:06 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1746817746689,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-05-09T19:09:07.436+0000] {subprocess.py:93} INFO - 25/05/09 19:09:07 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-09T19:09:07.436+0000] {subprocess.py:93} INFO - 25/05/09 19:09:07 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-09T19:09:07.530+0000] {subprocess.py:93} INFO - 25/05/09 19:09:07 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-09T19:09:07.536+0000] {subprocess.py:93} INFO - 25/05/09 19:09:07 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-09T19:09:07.612+0000] {subprocess.py:93} INFO - 25/05/09 19:09:07 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-09T19:09:07.615+0000] {subprocess.py:93} INFO - 25/05/09 19:09:07 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-09T19:09:07.616+0000] {subprocess.py:93} INFO - 25/05/09 19:09:07 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-09T19:09:07.619+0000] {subprocess.py:93} INFO - 25/05/09 19:09:07 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-09T19:09:07.706+0000] {subprocess.py:93} INFO - 25/05/09 19:09:07 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-09T19:09:07.710+0000] {subprocess.py:93} INFO - 25/05/09 19:09:07 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-09T19:09:08.302+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO CodeGenerator: Code generated in 441.047952 ms
[2025-05-09T19:09:08.462+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: CassandraBulkWrite(org.apache.spark.sql.SparkSession@60ae6d54,com.datastax.spark.connector.cql.CassandraConnector@5edc8a47,TableDef(gold_news,articles,ArrayBuffer(ColumnDef(id,PartitionKeyColumn,UUIDType)),ArrayBuffer(),Stream(ColumnDef(description,RegularColumn,VarCharType), ColumnDef(ingestion_time,RegularColumn,VarCharType), ColumnDef(published_at,RegularColumn,VarCharType), ColumnDef(source,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType), ColumnDef(url,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(BytesInBatch(1024),1000,Partition,ONE,false,false,5,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(id,StringType,true),StructField(title,StringType,true),StructField(source,StringType,true),StructField(published_at,StringType,true),StructField(description,StringType,true),StructField(url,StringType,true),StructField(ingestion_time,StringType,true)),org.apache.spark.SparkConf@66688fbc)]. The input RDD has 1 partitions.
[2025-05-09T19:09:08.597+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO CodeGenerator: Code generated in 12.149435 ms
[2025-05-09T19:09:08.607+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO SparkContext: Starting job: start at <unknown>:0
[2025-05-09T19:09:08.618+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO SparkContext: Starting job: start at <unknown>:0
[2025-05-09T19:09:08.628+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO DAGScheduler: Got job 0 (start at <unknown>:0) with 1 output partitions
[2025-05-09T19:09:08.628+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO DAGScheduler: Final stage: ResultStage 0 (start at <unknown>:0)
[2025-05-09T19:09:08.629+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO DAGScheduler: Parents of final stage: List()
[2025-05-09T19:09:08.632+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO DAGScheduler: Missing parents: List()
[2025-05-09T19:09:08.637+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at start at <unknown>:0), which has no missing parents
[2025-05-09T19:09:08.832+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 30.3 KiB, free 434.4 MiB)
[2025-05-09T19:09:08.868+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 13.5 KiB, free 434.4 MiB)
[2025-05-09T19:09:08.871+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b7f8b9fbbc8f:39589 (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-09T19:09:08.877+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
[2025-05-09T19:09:08.894+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-05-09T19:09:08.894+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-05-09T19:09:08.919+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO DAGScheduler: Got job 1 (start at <unknown>:0) with 1 output partitions
[2025-05-09T19:09:08.920+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO DAGScheduler: Final stage: ResultStage 1 (start at <unknown>:0)
[2025-05-09T19:09:08.920+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO DAGScheduler: Parents of final stage: List()
[2025-05-09T19:09:08.923+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO DAGScheduler: Missing parents: List()
[2025-05-09T19:09:08.925+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[10] at start at <unknown>:0), which has no missing parents
[2025-05-09T19:09:08.947+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 40.5 KiB, free 434.3 MiB)
[2025-05-09T19:09:08.950+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 434.3 MiB)
[2025-05-09T19:09:08.951+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on b7f8b9fbbc8f:39589 (size: 15.6 KiB, free: 434.4 MiB)
[2025-05-09T19:09:08.952+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[2025-05-09T19:09:08.952+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-05-09T19:09:08.953+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2025-05-09T19:09:08.974+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (b7f8b9fbbc8f, executor driver, partition 0, PROCESS_LOCAL, 13811 bytes)
[2025-05-09T19:09:08.989+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (b7f8b9fbbc8f, executor driver, partition 0, PROCESS_LOCAL, 13812 bytes)
[2025-05-09T19:09:08.995+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-05-09T19:09:08.996+0000] {subprocess.py:93} INFO - 25/05/09 19:09:08 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2025-05-09T19:09:09.268+0000] {subprocess.py:93} INFO - 25/05/09 19:09:09 INFO CodeGenerator: Code generated in 60.20945 ms
[2025-05-09T19:09:09.318+0000] {subprocess.py:93} INFO - 25/05/09 19:09:09 INFO CodeGenerator: Code generated in 42.945113 ms
[2025-05-09T19:09:09.342+0000] {subprocess.py:93} INFO - 25/05/09 19:09:09 INFO CodeGenerator: Code generated in 16.771157 ms
[2025-05-09T19:09:09.346+0000] {subprocess.py:93} INFO - 25/05/09 19:09:09 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=gold-news-0 fromOffset=0 untilOffset=30, for query queryId=e8a79812-275e-472f-9ede-b95cdfc5b5c0 batchId=0 taskId=1 partitionId=0
[2025-05-09T19:09:09.529+0000] {subprocess.py:93} INFO - 25/05/09 19:09:09 INFO CodeGenerator: Code generated in 30.933514 ms
[2025-05-09T19:09:09.623+0000] {subprocess.py:93} INFO - 25/05/09 19:09:09 INFO CodeGenerator: Code generated in 64.631102 ms
[2025-05-09T19:09:09.708+0000] {subprocess.py:93} INFO - 25/05/09 19:09:09 INFO ConsumerConfig: ConsumerConfig values:
[2025-05-09T19:09:09.710+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-05-09T19:09:09.711+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-05-09T19:09:09.712+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-05-09T19:09:09.718+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-05-09T19:09:09.718+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-05-09T19:09:09.719+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-05-09T19:09:09.724+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-05-09T19:09:09.727+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor-1
[2025-05-09T19:09:09.739+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-05-09T19:09:09.740+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-05-09T19:09:09.745+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-05-09T19:09:09.755+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-05-09T19:09:09.758+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-05-09T19:09:09.761+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-05-09T19:09:09.765+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-05-09T19:09:09.768+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-05-09T19:09:09.770+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor
[2025-05-09T19:09:09.770+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-05-09T19:09:09.776+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-05-09T19:09:09.777+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-05-09T19:09:09.779+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-05-09T19:09:09.780+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-05-09T19:09:09.782+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-05-09T19:09:09.786+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-05-09T19:09:09.788+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-05-09T19:09:09.789+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-05-09T19:09:09.790+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-05-09T19:09:09.791+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-05-09T19:09:09.792+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-05-09T19:09:09.794+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-05-09T19:09:09.796+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-05-09T19:09:09.803+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-05-09T19:09:09.804+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-05-09T19:09:09.805+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-05-09T19:09:09.806+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-05-09T19:09:09.807+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-05-09T19:09:09.808+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-05-09T19:09:09.809+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-05-09T19:09:09.810+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-05-09T19:09:09.812+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-05-09T19:09:09.815+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-05-09T19:09:09.817+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-05-09T19:09:09.818+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-05-09T19:09:09.819+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-05-09T19:09:09.820+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-05-09T19:09:09.823+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-05-09T19:09:09.825+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-05-09T19:09:09.826+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-05-09T19:09:09.828+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-05-09T19:09:09.829+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-05-09T19:09:09.830+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-05-09T19:09:09.831+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-05-09T19:09:09.832+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-05-09T19:09:09.833+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-05-09T19:09:09.835+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-05-09T19:09:09.835+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-05-09T19:09:09.836+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-05-09T19:09:09.837+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-05-09T19:09:09.837+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-05-09T19:09:09.838+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-05-09T19:09:09.839+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-05-09T19:09:09.839+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-05-09T19:09:09.840+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-05-09T19:09:09.841+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-05-09T19:09:09.841+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-05-09T19:09:09.843+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-05-09T19:09:09.845+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-05-09T19:09:09.847+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-05-09T19:09:09.849+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-05-09T19:09:09.850+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-05-09T19:09:09.852+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-05-09T19:09:09.853+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-05-09T19:09:09.854+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-05-09T19:09:09.855+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-05-09T19:09:09.855+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-05-09T19:09:09.856+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-05-09T19:09:09.857+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-05-09T19:09:09.858+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-05-09T19:09:09.860+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-05-09T19:09:09.860+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-05-09T19:09:09.861+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-05-09T19:09:09.862+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-05-09T19:09:09.863+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-05-09T19:09:09.864+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-05-09T19:09:09.864+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-05-09T19:09:09.865+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-05-09T19:09:09.866+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-05-09T19:09:09.867+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-05-09T19:09:09.868+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-05-09T19:09:09.868+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-05-09T19:09:09.869+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-05-09T19:09:09.869+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-05-09T19:09:09.870+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:09.884+0000] {subprocess.py:93} INFO - 25/05/09 19:09:09 INFO AppInfoParser: Kafka version: 3.4.1
[2025-05-09T19:09:09.885+0000] {subprocess.py:93} INFO - 25/05/09 19:09:09 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89
[2025-05-09T19:09:09.886+0000] {subprocess.py:93} INFO - 25/05/09 19:09:09 INFO AppInfoParser: Kafka startTimeMs: 1746817749880
[2025-05-09T19:09:09.891+0000] {subprocess.py:93} INFO - 25/05/09 19:09:09 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor-1, groupId=spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor] Assigned to partition(s): gold-news-0
[2025-05-09T19:09:09.932+0000] {subprocess.py:93} INFO - 25/05/09 19:09:09 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor-1, groupId=spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor] Seeking to offset 0 for partition gold-news-0
[2025-05-09T19:09:09.968+0000] {subprocess.py:93} INFO - 25/05/09 19:09:09 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor-1, groupId=spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor] Resetting the last seen epoch of partition gold-news-0 to 0 since the associated topicId changed from null to EyFovrTXQQOm3GPuq8IGNA
[2025-05-09T19:09:09.974+0000] {subprocess.py:93} INFO - 25/05/09 19:09:09 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor-1, groupId=spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor] Cluster ID: HTSY0p8VS7eCaEFoyzBH3g
[2025-05-09T19:09:10.344+0000] {subprocess.py:93} INFO - 25/05/09 19:09:10 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=gold-news-0 fromOffset=0 untilOffset=30, for query queryId=eb0506f2-bf19-4afa-82b0-c9f5bf74b418 batchId=0 taskId=0 partitionId=0
[2025-05-09T19:09:10.385+0000] {subprocess.py:93} INFO - 25/05/09 19:09:10 INFO ConsumerConfig: ConsumerConfig values:
[2025-05-09T19:09:10.386+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-05-09T19:09:10.386+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-05-09T19:09:10.387+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-05-09T19:09:10.387+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-05-09T19:09:10.388+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-05-09T19:09:10.388+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-05-09T19:09:10.389+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-05-09T19:09:10.390+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor-2
[2025-05-09T19:09:10.390+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-05-09T19:09:10.393+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-05-09T19:09:10.401+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-05-09T19:09:10.402+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-05-09T19:09:10.403+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-05-09T19:09:10.404+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-05-09T19:09:10.405+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-05-09T19:09:10.407+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-05-09T19:09:10.410+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor
[2025-05-09T19:09:10.411+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-05-09T19:09:10.412+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-05-09T19:09:10.412+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-05-09T19:09:10.413+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-05-09T19:09:10.413+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-05-09T19:09:10.414+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-05-09T19:09:10.414+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-05-09T19:09:10.415+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-05-09T19:09:10.415+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-05-09T19:09:10.416+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-05-09T19:09:10.416+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-05-09T19:09:10.416+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-05-09T19:09:10.417+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-05-09T19:09:10.418+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-05-09T19:09:10.419+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-05-09T19:09:10.419+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-05-09T19:09:10.420+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-05-09T19:09:10.421+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-05-09T19:09:10.421+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-05-09T19:09:10.424+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-05-09T19:09:10.425+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-05-09T19:09:10.426+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-05-09T19:09:10.427+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-05-09T19:09:10.430+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-05-09T19:09:10.431+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-05-09T19:09:10.434+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-05-09T19:09:10.437+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-05-09T19:09:10.440+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-05-09T19:09:10.448+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-05-09T19:09:10.452+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-05-09T19:09:10.453+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-05-09T19:09:10.454+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-05-09T19:09:10.456+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-05-09T19:09:10.457+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-05-09T19:09:10.459+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-05-09T19:09:10.460+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-05-09T19:09:10.460+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-05-09T19:09:10.461+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-05-09T19:09:10.481+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-05-09T19:09:10.488+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-05-09T19:09:10.490+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-05-09T19:09:10.491+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-05-09T19:09:10.491+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-05-09T19:09:10.492+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-05-09T19:09:10.493+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-05-09T19:09:10.494+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-05-09T19:09:10.495+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-05-09T19:09:10.496+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-05-09T19:09:10.497+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-05-09T19:09:10.498+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-05-09T19:09:10.499+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-05-09T19:09:10.500+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-05-09T19:09:10.502+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-05-09T19:09:10.503+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-05-09T19:09:10.503+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-05-09T19:09:10.504+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-05-09T19:09:10.505+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-05-09T19:09:10.505+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-05-09T19:09:10.505+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-05-09T19:09:10.506+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-05-09T19:09:10.507+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-05-09T19:09:10.507+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-05-09T19:09:10.507+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-05-09T19:09:10.508+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-05-09T19:09:10.508+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-05-09T19:09:10.509+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-05-09T19:09:10.509+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-05-09T19:09:10.510+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-05-09T19:09:10.510+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-05-09T19:09:10.512+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-05-09T19:09:10.513+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-05-09T19:09:10.518+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-05-09T19:09:10.519+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-05-09T19:09:10.520+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-05-09T19:09:10.521+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-05-09T19:09:10.522+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:10.523+0000] {subprocess.py:93} INFO - 25/05/09 19:09:10 INFO AppInfoParser: Kafka version: 3.4.1
[2025-05-09T19:09:10.524+0000] {subprocess.py:93} INFO - 25/05/09 19:09:10 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89
[2025-05-09T19:09:10.524+0000] {subprocess.py:93} INFO - 25/05/09 19:09:10 INFO AppInfoParser: Kafka startTimeMs: 1746817750394
[2025-05-09T19:09:10.525+0000] {subprocess.py:93} INFO - 25/05/09 19:09:10 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor-2, groupId=spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor] Assigned to partition(s): gold-news-0
[2025-05-09T19:09:10.525+0000] {subprocess.py:93} INFO - 25/05/09 19:09:10 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor-2, groupId=spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor] Seeking to offset 0 for partition gold-news-0
[2025-05-09T19:09:10.525+0000] {subprocess.py:93} INFO - 25/05/09 19:09:10 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor-2, groupId=spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor] Resetting the last seen epoch of partition gold-news-0 to 0 since the associated topicId changed from null to EyFovrTXQQOm3GPuq8IGNA
[2025-05-09T19:09:10.526+0000] {subprocess.py:93} INFO - 25/05/09 19:09:10 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor-2, groupId=spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor] Cluster ID: HTSY0p8VS7eCaEFoyzBH3g
[2025-05-09T19:09:10.615+0000] {subprocess.py:93} INFO - 25/05/09 19:09:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor-2, groupId=spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor] Seeking to earliest offset of partition gold-news-0
[2025-05-09T19:09:10.616+0000] {subprocess.py:93} INFO - 25/05/09 19:09:10 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor-1, groupId=spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor] Seeking to earliest offset of partition gold-news-0
[2025-05-09T19:09:11.176+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor-1, groupId=spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor] Resetting offset for partition gold-news-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-05-09T19:09:11.177+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor-1, groupId=spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor] Seeking to latest offset of partition gold-news-0
[2025-05-09T19:09:11.180+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor-1, groupId=spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor] Resetting offset for partition gold-news-0 to position FetchPosition{offset=30, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-05-09T19:09:11.181+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor-2, groupId=spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor] Resetting offset for partition gold-news-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-05-09T19:09:11.182+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor-2, groupId=spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor] Seeking to latest offset of partition gold-news-0
[2025-05-09T19:09:11.184+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor-2, groupId=spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor] Resetting offset for partition gold-news-0 to position FetchPosition{offset=30, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-05-09T19:09:11.355+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO KafkaDataConsumer: From Kafka topicPartition=gold-news-0 groupId=spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor read 1 records through 1 polls (polled  out 30 records), taking 1250349195 nanos, during time span of 1448552989 nanos.
[2025-05-09T19:09:11.393+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1914 bytes result sent to driver
[2025-05-09T19:09:11.428+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 2436 ms on b7f8b9fbbc8f (executor driver) (1/1)
[2025-05-09T19:09:11.433+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-05-09T19:09:11.443+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO DAGScheduler: ResultStage 1 (start at <unknown>:0) finished in 2.515 s
[2025-05-09T19:09:11.456+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-09T19:09:11.459+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2025-05-09T19:09:11.464+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 0, attempt 0, stage 0.0)
[2025-05-09T19:09:11.465+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO DAGScheduler: Job 1 finished: start at <unknown>:0, took 2.842973 s
[2025-05-09T19:09:11.661+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO DataWritingSparkTask: Committed partition 0 (task 0, attempt 0, stage 0.0)
[2025-05-09T19:09:11.663+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO KafkaDataConsumer: From Kafka topicPartition=gold-news-0 groupId=spark-kafka-source-234a2297-f3a6-4c38-98cd-c7ad68201380-1979046052-executor read 30 records through 1 polls (polled  out 30 records), taking 785509388 nanos, during time span of 1262471751 nanos.
[2025-05-09T19:09:11.669+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO CodeGenerator: Code generated in 48.148451 ms
[2025-05-09T19:09:11.674+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1808 bytes result sent to driver
[2025-05-09T19:09:11.677+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2734 ms on b7f8b9fbbc8f (executor driver) (1/1)
[2025-05-09T19:09:11.680+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO DAGScheduler: ResultStage 0 (start at <unknown>:0) finished in 3.019 s
[2025-05-09T19:09:11.681+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-09T19:09:11.683+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-05-09T19:09:11.684+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2025-05-09T19:09:11.686+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO DAGScheduler: Job 0 finished: start at <unknown>:0, took 3.074282 s
[2025-05-09T19:09:11.687+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: CassandraBulkWrite(org.apache.spark.sql.SparkSession@60ae6d54,com.datastax.spark.connector.cql.CassandraConnector@5edc8a47,TableDef(gold_news,articles,ArrayBuffer(ColumnDef(id,PartitionKeyColumn,UUIDType)),ArrayBuffer(),Stream(ColumnDef(description,RegularColumn,VarCharType), ColumnDef(ingestion_time,RegularColumn,VarCharType), ColumnDef(published_at,RegularColumn,VarCharType), ColumnDef(source,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType), ColumnDef(url,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(BytesInBatch(1024),1000,Partition,ONE,false,false,5,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(id,StringType,true),StructField(title,StringType,true),StructField(source,StringType,true),StructField(published_at,StringType,true),StructField(description,StringType,true),StructField(url,StringType,true),StructField(ingestion_time,StringType,true)),org.apache.spark.SparkConf@66688fbc)] is committing.
[2025-05-09T19:09:11.688+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: CassandraBulkWrite(org.apache.spark.sql.SparkSession@60ae6d54,com.datastax.spark.connector.cql.CassandraConnector@5edc8a47,TableDef(gold_news,articles,ArrayBuffer(ColumnDef(id,PartitionKeyColumn,UUIDType)),ArrayBuffer(),Stream(ColumnDef(description,RegularColumn,VarCharType), ColumnDef(ingestion_time,RegularColumn,VarCharType), ColumnDef(published_at,RegularColumn,VarCharType), ColumnDef(source,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType), ColumnDef(url,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(BytesInBatch(1024),1000,Partition,ONE,false,false,5,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(id,StringType,true),StructField(title,StringType,true),StructField(source,StringType,true),StructField(published_at,StringType,true),StructField(description,StringType,true),StructField(url,StringType,true),StructField(ingestion_time,StringType,true)),org.apache.spark.SparkConf@66688fbc)] committed.
[2025-05-09T19:09:11.710+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2025-05-09T19:09:11.711+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO DAGScheduler: Got job 2 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2025-05-09T19:09:11.713+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO DAGScheduler: Final stage: ResultStage 2 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2025-05-09T19:09:11.714+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO DAGScheduler: Parents of final stage: List()
[2025-05-09T19:09:11.715+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO DAGScheduler: Missing parents: List()
[2025-05-09T19:09:11.718+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2025-05-09T19:09:11.719+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO CheckpointFileManager: Writing atomically to file:/tmp/spark-checkpoint/cassandra/commits/0 using temp file file:/tmp/spark-checkpoint/cassandra/commits/.0.bd0e90e1-75bf-42c9-8def-d11877977009.tmp
[2025-05-09T19:09:11.733+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 41.2 KiB, free 434.3 MiB)
[2025-05-09T19:09:11.734+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 434.2 MiB)
[2025-05-09T19:09:11.735+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on b7f8b9fbbc8f:39589 (size: 15.8 KiB, free: 434.4 MiB)
[2025-05-09T19:09:11.739+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
[2025-05-09T19:09:11.740+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2025-05-09T19:09:11.742+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2025-05-09T19:09:11.743+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (b7f8b9fbbc8f, executor driver, partition 0, PROCESS_LOCAL, 13812 bytes)
[2025-05-09T19:09:11.744+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
[2025-05-09T19:09:11.767+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO CheckpointFileManager: Renamed temp file file:/tmp/spark-checkpoint/cassandra/commits/.0.bd0e90e1-75bf-42c9-8def-d11877977009.tmp to file:/tmp/spark-checkpoint/cassandra/commits/0
[2025-05-09T19:09:11.823+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO CodeGenerator: Code generated in 17.62735 ms
[2025-05-09T19:09:11.825+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=gold-news-0 fromOffset=0 untilOffset=30, for query queryId=e8a79812-275e-472f-9ede-b95cdfc5b5c0 batchId=0 taskId=2 partitionId=0
[2025-05-09T19:09:11.842+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO BlockManagerInfo: Removed broadcast_0_piece0 on b7f8b9fbbc8f:39589 in memory (size: 13.5 KiB, free: 434.4 MiB)
[2025-05-09T19:09:11.845+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor-1, groupId=spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor] Seeking to offset 0 for partition gold-news-0
[2025-05-09T19:09:11.855+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor-1, groupId=spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor] Seeking to earliest offset of partition gold-news-0
[2025-05-09T19:09:11.863+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO BlockManagerInfo: Removed broadcast_1_piece0 on b7f8b9fbbc8f:39589 in memory (size: 15.6 KiB, free: 434.4 MiB)
[2025-05-09T19:09:11.878+0000] {subprocess.py:93} INFO - 25/05/09 19:09:11 INFO MicroBatchExecution: Streaming query made progress: {
[2025-05-09T19:09:11.878+0000] {subprocess.py:93} INFO -   "id" : "eb0506f2-bf19-4afa-82b0-c9f5bf74b418",
[2025-05-09T19:09:11.879+0000] {subprocess.py:93} INFO -   "runId" : "f54b8c68-441c-405c-82c9-d1f0001c5b29",
[2025-05-09T19:09:11.879+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-05-09T19:09:11.880+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-05-09T19:09:05.436Z",
[2025-05-09T19:09:11.880+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-05-09T19:09:11.880+0000] {subprocess.py:93} INFO -   "numInputRows" : 30,
[2025-05-09T19:09:11.881+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-05-09T19:09:11.881+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 4.739336492890995,
[2025-05-09T19:09:11.881+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-05-09T19:09:11.882+0000] {subprocess.py:93} INFO -     "addBatch" : 4118,
[2025-05-09T19:09:11.882+0000] {subprocess.py:93} INFO -     "commitOffsets" : 72,
[2025-05-09T19:09:11.882+0000] {subprocess.py:93} INFO -     "getBatch" : 23,
[2025-05-09T19:09:11.882+0000] {subprocess.py:93} INFO -     "latestOffset" : 1235,
[2025-05-09T19:09:11.883+0000] {subprocess.py:93} INFO -     "queryPlanning" : 776,
[2025-05-09T19:09:11.883+0000] {subprocess.py:93} INFO -     "triggerExecution" : 6329,
[2025-05-09T19:09:11.883+0000] {subprocess.py:93} INFO -     "walCommit" : 71
[2025-05-09T19:09:11.883+0000] {subprocess.py:93} INFO -   },
[2025-05-09T19:09:11.883+0000] {subprocess.py:93} INFO -   "stateOperators" : [ ],
[2025-05-09T19:09:11.884+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-05-09T19:09:11.884+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[gold-news]]",
[2025-05-09T19:09:11.884+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-05-09T19:09:11.885+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-05-09T19:09:11.885+0000] {subprocess.py:93} INFO -       "gold-news" : {
[2025-05-09T19:09:11.885+0000] {subprocess.py:93} INFO -         "0" : 30
[2025-05-09T19:09:11.886+0000] {subprocess.py:93} INFO -       }
[2025-05-09T19:09:11.886+0000] {subprocess.py:93} INFO -     },
[2025-05-09T19:09:11.887+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-05-09T19:09:11.887+0000] {subprocess.py:93} INFO -       "gold-news" : {
[2025-05-09T19:09:11.888+0000] {subprocess.py:93} INFO -         "0" : 30
[2025-05-09T19:09:11.888+0000] {subprocess.py:93} INFO -       }
[2025-05-09T19:09:11.889+0000] {subprocess.py:93} INFO -     },
[2025-05-09T19:09:11.889+0000] {subprocess.py:93} INFO -     "numInputRows" : 30,
[2025-05-09T19:09:11.889+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-05-09T19:09:11.890+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 4.739336492890995,
[2025-05-09T19:09:11.890+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-05-09T19:09:11.891+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-05-09T19:09:11.891+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-05-09T19:09:11.891+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-05-09T19:09:11.892+0000] {subprocess.py:93} INFO -     }
[2025-05-09T19:09:11.892+0000] {subprocess.py:93} INFO -   } ],
[2025-05-09T19:09:11.893+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-05-09T19:09:11.893+0000] {subprocess.py:93} INFO -     "description" : "CassandraTable(org.apache.spark.sql.SparkSession@60ae6d54,org.apache.spark.sql.util.CaseInsensitiveStringMap@6e619b4c,com.datastax.spark.connector.cql.CassandraConnector@23e18307,default,DefaultTableMetadata@938fa7c3(gold_news.articles),None)",
[2025-05-09T19:09:11.893+0000] {subprocess.py:93} INFO -     "numOutputRows" : 30
[2025-05-09T19:09:11.894+0000] {subprocess.py:93} INFO -   }
[2025-05-09T19:09:11.894+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:12.359+0000] {subprocess.py:93} INFO - 25/05/09 19:09:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor-1, groupId=spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor] Resetting offset for partition gold-news-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-05-09T19:09:12.360+0000] {subprocess.py:93} INFO - 25/05/09 19:09:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor-1, groupId=spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor] Seeking to latest offset of partition gold-news-0
[2025-05-09T19:09:12.363+0000] {subprocess.py:93} INFO - 25/05/09 19:09:12 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor-1, groupId=spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor] Resetting offset for partition gold-news-0 to position FetchPosition{offset=30, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-05-09T19:09:12.380+0000] {subprocess.py:93} INFO - 25/05/09 19:09:12 INFO KafkaDataConsumer: From Kafka topicPartition=gold-news-0 groupId=spark-kafka-source-f9724d01-6c3b-491f-a22b-7b332b84883f--1541781609-executor read 30 records through 1 polls (polled  out 30 records), taking 518556385 nanos, during time span of 535811525 nanos.
[2025-05-09T19:09:12.383+0000] {subprocess.py:93} INFO - 25/05/09 19:09:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 4349 bytes result sent to driver
[2025-05-09T19:09:12.385+0000] {subprocess.py:93} INFO - 25/05/09 19:09:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 648 ms on b7f8b9fbbc8f (executor driver) (1/1)
[2025-05-09T19:09:12.386+0000] {subprocess.py:93} INFO - 25/05/09 19:09:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-05-09T19:09:12.388+0000] {subprocess.py:93} INFO - 25/05/09 19:09:12 INFO DAGScheduler: ResultStage 2 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.667 s
[2025-05-09T19:09:12.390+0000] {subprocess.py:93} INFO - 25/05/09 19:09:12 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-09T19:09:12.391+0000] {subprocess.py:93} INFO - 25/05/09 19:09:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-05-09T19:09:12.392+0000] {subprocess.py:93} INFO - 25/05/09 19:09:12 INFO DAGScheduler: Job 2 finished: call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.683437 s
[2025-05-09T19:09:12.427+0000] {subprocess.py:93} INFO - Processing batch 0 with 30 descriptions
[2025-05-09T19:09:22.094+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.095+0000] {subprocess.py:93} INFO - Analysis for article: How Is AI Redefining Content in the Attention Econ...
[2025-05-09T19:09:22.096+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.097+0000] {subprocess.py:93} INFO -   "description_number": "1",
[2025-05-09T19:09:22.097+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.098+0000] {subprocess.py:93} INFO -   "impact_explanation": "Irrelevant to gold market.",
[2025-05-09T19:09:22.099+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.100+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.104+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.111+0000] {subprocess.py:93} INFO - Analysis for article: Latin Metals Appoints Eduardo Leon as Vice Preside...
[2025-05-09T19:09:22.112+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.113+0000] {subprocess.py:93} INFO -   "description_number": "2",
[2025-05-09T19:09:22.113+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.115+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about a mining company's financing may indirectly affect gold prices if successful exploration leads to increased gold supply in the long term.",
[2025-05-09T19:09:22.115+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.116+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.121+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.125+0000] {subprocess.py:93} INFO - Analysis for article: The LockBit ransomware site was breached, database...
[2025-05-09T19:09:22.127+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.127+0000] {subprocess.py:93} INFO -   "description_number": "3",
[2025-05-09T19:09:22.128+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.129+0000] {subprocess.py:93} INFO -   "impact_explanation": "Cybersecurity news is generally not directly related to gold market movements.",
[2025-05-09T19:09:22.129+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.130+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.131+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.131+0000] {subprocess.py:93} INFO - Analysis for article: Trump Says Fed Chair 'Is Not in Love With Me' as C...
[2025-05-09T19:09:22.132+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.133+0000] {subprocess.py:93} INFO -   "description_number": "4",
[2025-05-09T19:09:22.133+0000] {subprocess.py:93} INFO -   "sentiment": "Negative",
[2025-05-09T19:09:22.134+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's rise may divert investments away from gold, as both are considered safe haven assets.",
[2025-05-09T19:09:22.134+0000] {subprocess.py:93} INFO -   "recommendation": "Sell"
[2025-05-09T19:09:22.135+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.136+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.136+0000] {subprocess.py:93} INFO - Analysis for article: Is US President Trump A Bitcoin Whale? Son Eric Sa...
[2025-05-09T19:09:22.137+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.137+0000] {subprocess.py:93} INFO -   "description_number": "5",
[2025-05-09T19:09:22.138+0000] {subprocess.py:93} INFO -   "sentiment": "Negative",
[2025-05-09T19:09:22.138+0000] {subprocess.py:93} INFO -   "impact_explanation": "Positive sentiment towards Bitcoin could reduce demand for gold as an alternative investment.",
[2025-05-09T19:09:22.139+0000] {subprocess.py:93} INFO -   "recommendation": "Sell"
[2025-05-09T19:09:22.139+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.140+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.140+0000] {subprocess.py:93} INFO - Analysis for article: RFK Jr.’s Former Running Mate Shanahan Says He ‘Li...
[2025-05-09T19:09:22.141+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.141+0000] {subprocess.py:93} INFO -   "description_number": "6",
[2025-05-09T19:09:22.142+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.143+0000] {subprocess.py:93} INFO -   "impact_explanation": "Irrelevant to gold market.",
[2025-05-09T19:09:22.144+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.146+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.147+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.148+0000] {subprocess.py:93} INFO - Analysis for article: McEwen Mining: Q1 2025 Results...
[2025-05-09T19:09:22.154+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.155+0000] {subprocess.py:93} INFO -   "description_number": "7",
[2025-05-09T19:09:22.156+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.156+0000] {subprocess.py:93} INFO -   "impact_explanation": "McEwen Mining's quarterly results may indicate the state of the gold mining industry, but their impact on gold price is indirect and uncertain.",
[2025-05-09T19:09:22.157+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.158+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.158+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.159+0000] {subprocess.py:93} INFO - Analysis for article: IIFL Finance Q4 Results: Profit falls 42% to Rs 25...
[2025-05-09T19:09:22.160+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.161+0000] {subprocess.py:93} INFO -   "description_number": "8",
[2025-05-09T19:09:22.163+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.164+0000] {subprocess.py:93} INFO -   "impact_explanation": "Financial news from an unrelated company has little direct influence on the gold market.",
[2025-05-09T19:09:22.165+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.165+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.166+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.167+0000] {subprocess.py:93} INFO - Analysis for article: Gold ETFs Record Strongest Inflows Since 2022, Say...
[2025-05-09T19:09:22.167+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.168+0000] {subprocess.py:93} INFO -   "description_number": "9",
[2025-05-09T19:09:22.169+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-09T19:09:22.178+0000] {subprocess.py:93} INFO -   "impact_explanation": "Increased gold ETF assets indicate higher demand for gold.",
[2025-05-09T19:09:22.180+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-09T19:09:22.186+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.187+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.187+0000] {subprocess.py:93} INFO - Analysis for article: (PR) Lenovo Unveils the New Legion 9i (18", 10) Ga...
[2025-05-09T19:09:22.188+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.198+0000] {subprocess.py:93} INFO -   "description_number": "10",
[2025-05-09T19:09:22.209+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.217+0000] {subprocess.py:93} INFO -   "impact_explanation": "Irrelevant to gold market.",
[2025-05-09T19:09:22.223+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.227+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.232+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.243+0000] {subprocess.py:93} INFO - Analysis for article: How Is AI Redefining Content in the Attention Econ...
[2025-05-09T19:09:22.245+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.250+0000] {subprocess.py:93} INFO -   "description_number": "11",
[2025-05-09T19:09:22.251+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.253+0000] {subprocess.py:93} INFO -   "impact_explanation": "Irrelevant to gold market.",
[2025-05-09T19:09:22.257+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.260+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.260+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.261+0000] {subprocess.py:93} INFO - Analysis for article: Latin Metals Appoints Eduardo Leon as Vice Preside...
[2025-05-09T19:09:22.262+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.263+0000] {subprocess.py:93} INFO -   "description_number": "12",
[2025-05-09T19:09:22.264+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.265+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about a mining company's financing may indirectly affect gold prices if successful exploration leads to increased gold supply in the long term.",
[2025-05-09T19:09:22.266+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.269+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.270+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.271+0000] {subprocess.py:93} INFO - Analysis for article: The LockBit ransomware site was breached, database...
[2025-05-09T19:09:22.271+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.272+0000] {subprocess.py:93} INFO -   "description_number": "13",
[2025-05-09T19:09:22.272+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.273+0000] {subprocess.py:93} INFO -   "impact_explanation": "Cybersecurity news is generally not directly related to gold market movements.",
[2025-05-09T19:09:22.273+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.274+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.274+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.275+0000] {subprocess.py:93} INFO - Analysis for article: Trump Says Fed Chair 'Is Not in Love With Me' as C...
[2025-05-09T19:09:22.275+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.276+0000] {subprocess.py:93} INFO -   "description_number": "14",
[2025-05-09T19:09:22.276+0000] {subprocess.py:93} INFO -   "sentiment": "Negative",
[2025-05-09T19:09:22.277+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's rise may divert investments away from gold, as both are considered safe haven assets.",
[2025-05-09T19:09:22.277+0000] {subprocess.py:93} INFO -   "recommendation": "Sell"
[2025-05-09T19:09:22.278+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.279+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.279+0000] {subprocess.py:93} INFO - Analysis for article: Is US President Trump A Bitcoin Whale? Son Eric Sa...
[2025-05-09T19:09:22.280+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.281+0000] {subprocess.py:93} INFO -   "description_number": "15",
[2025-05-09T19:09:22.284+0000] {subprocess.py:93} INFO -   "sentiment": "Negative",
[2025-05-09T19:09:22.285+0000] {subprocess.py:93} INFO -   "impact_explanation": "Positive sentiment towards Bitcoin could reduce demand for gold as an alternative investment.",
[2025-05-09T19:09:22.286+0000] {subprocess.py:93} INFO -   "recommendation": "Sell"
[2025-05-09T19:09:22.287+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.287+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.288+0000] {subprocess.py:93} INFO - Analysis for article: RFK Jr.’s Former Running Mate Shanahan Says He ‘Li...
[2025-05-09T19:09:22.288+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.289+0000] {subprocess.py:93} INFO -   "description_number": "16",
[2025-05-09T19:09:22.289+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.290+0000] {subprocess.py:93} INFO -   "impact_explanation": "Irrelevant to gold market.",
[2025-05-09T19:09:22.290+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.291+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.291+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.291+0000] {subprocess.py:93} INFO - Analysis for article: McEwen Mining: Q1 2025 Results...
[2025-05-09T19:09:22.292+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.292+0000] {subprocess.py:93} INFO -   "description_number": "17",
[2025-05-09T19:09:22.293+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.293+0000] {subprocess.py:93} INFO -   "impact_explanation": "McEwen Mining's quarterly results may indicate the state of the gold mining industry, but their impact on gold price is indirect and uncertain.",
[2025-05-09T19:09:22.294+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.294+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.295+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.295+0000] {subprocess.py:93} INFO - Analysis for article: IIFL Finance Q4 Results: Profit falls 42% to Rs 25...
[2025-05-09T19:09:22.296+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.300+0000] {subprocess.py:93} INFO -   "description_number": "18",
[2025-05-09T19:09:22.302+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.302+0000] {subprocess.py:93} INFO -   "impact_explanation": "Financial news from an unrelated company has little direct influence on the gold market.",
[2025-05-09T19:09:22.303+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.304+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.304+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.305+0000] {subprocess.py:93} INFO - Analysis for article: Gold ETFs Record Strongest Inflows Since 2022, Say...
[2025-05-09T19:09:22.305+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.306+0000] {subprocess.py:93} INFO -   "description_number": "19",
[2025-05-09T19:09:22.306+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-09T19:09:22.307+0000] {subprocess.py:93} INFO -   "impact_explanation": "Increased gold ETF assets indicate higher demand for gold.",
[2025-05-09T19:09:22.307+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-09T19:09:22.308+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.308+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.309+0000] {subprocess.py:93} INFO - Analysis for article: (PR) Lenovo Unveils the New Legion 9i (18", 10) Ga...
[2025-05-09T19:09:22.310+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.310+0000] {subprocess.py:93} INFO -   "description_number": "20",
[2025-05-09T19:09:22.311+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.311+0000] {subprocess.py:93} INFO -   "impact_explanation": "Irrelevant to gold market.",
[2025-05-09T19:09:22.312+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.312+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.313+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.313+0000] {subprocess.py:93} INFO - Analysis for article: How Is AI Redefining Content in the Attention Econ...
[2025-05-09T19:09:22.314+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.314+0000] {subprocess.py:93} INFO -   "description_number": "21",
[2025-05-09T19:09:22.315+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.316+0000] {subprocess.py:93} INFO -   "impact_explanation": "Irrelevant to gold market.",
[2025-05-09T19:09:22.318+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.319+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.320+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.321+0000] {subprocess.py:93} INFO - Analysis for article: Latin Metals Appoints Eduardo Leon as Vice Preside...
[2025-05-09T19:09:22.321+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.322+0000] {subprocess.py:93} INFO -   "description_number": "22",
[2025-05-09T19:09:22.322+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.323+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about a mining company's financing may indirectly affect gold prices if successful exploration leads to increased gold supply in the long term.",
[2025-05-09T19:09:22.323+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.324+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.324+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.325+0000] {subprocess.py:93} INFO - Analysis for article: The LockBit ransomware site was breached, database...
[2025-05-09T19:09:22.325+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.326+0000] {subprocess.py:93} INFO -   "description_number": "23",
[2025-05-09T19:09:22.326+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.327+0000] {subprocess.py:93} INFO -   "impact_explanation": "Cybersecurity news is generally not directly related to gold market movements.",
[2025-05-09T19:09:22.327+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.329+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.329+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.330+0000] {subprocess.py:93} INFO - Analysis for article: Trump Says Fed Chair 'Is Not in Love With Me' as C...
[2025-05-09T19:09:22.330+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.331+0000] {subprocess.py:93} INFO -   "description_number": "24",
[2025-05-09T19:09:22.332+0000] {subprocess.py:93} INFO -   "sentiment": "Negative",
[2025-05-09T19:09:22.333+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's rise may divert investments away from gold, as both are considered safe haven assets.",
[2025-05-09T19:09:22.334+0000] {subprocess.py:93} INFO -   "recommendation": "Sell"
[2025-05-09T19:09:22.335+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.336+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.337+0000] {subprocess.py:93} INFO - Analysis for article: Is US President Trump A Bitcoin Whale? Son Eric Sa...
[2025-05-09T19:09:22.337+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.338+0000] {subprocess.py:93} INFO -   "description_number": "25",
[2025-05-09T19:09:22.339+0000] {subprocess.py:93} INFO -   "sentiment": "Negative",
[2025-05-09T19:09:22.339+0000] {subprocess.py:93} INFO -   "impact_explanation": "Positive sentiment towards Bitcoin could reduce demand for gold as an alternative investment.",
[2025-05-09T19:09:22.340+0000] {subprocess.py:93} INFO -   "recommendation": "Sell"
[2025-05-09T19:09:22.340+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.340+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.341+0000] {subprocess.py:93} INFO - Analysis for article: RFK Jr.’s Former Running Mate Shanahan Says He ‘Li...
[2025-05-09T19:09:22.341+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.342+0000] {subprocess.py:93} INFO -   "description_number": "26",
[2025-05-09T19:09:22.342+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.343+0000] {subprocess.py:93} INFO -   "impact_explanation": "Irrelevant to gold market.",
[2025-05-09T19:09:22.344+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.345+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.346+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.347+0000] {subprocess.py:93} INFO - Analysis for article: McEwen Mining: Q1 2025 Results...
[2025-05-09T19:09:22.348+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.351+0000] {subprocess.py:93} INFO -   "description_number": "27",
[2025-05-09T19:09:22.352+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.353+0000] {subprocess.py:93} INFO -   "impact_explanation": "McEwen Mining's quarterly results may indicate the state of the gold mining industry, but their impact on gold price is indirect and uncertain.",
[2025-05-09T19:09:22.353+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.355+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.356+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.357+0000] {subprocess.py:93} INFO - Analysis for article: IIFL Finance Q4 Results: Profit falls 42% to Rs 25...
[2025-05-09T19:09:22.357+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.358+0000] {subprocess.py:93} INFO -   "description_number": "28",
[2025-05-09T19:09:22.359+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.360+0000] {subprocess.py:93} INFO -   "impact_explanation": "Financial news from an unrelated company has little direct influence on the gold market.",
[2025-05-09T19:09:22.360+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.361+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.362+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.363+0000] {subprocess.py:93} INFO - Analysis for article: Gold ETFs Record Strongest Inflows Since 2022, Say...
[2025-05-09T19:09:22.363+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.364+0000] {subprocess.py:93} INFO -   "description_number": "29",
[2025-05-09T19:09:22.366+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-09T19:09:22.367+0000] {subprocess.py:93} INFO -   "impact_explanation": "Increased gold ETF assets indicate higher demand for gold.",
[2025-05-09T19:09:22.368+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-09T19:09:22.368+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.369+0000] {subprocess.py:93} INFO - 
[2025-05-09T19:09:22.369+0000] {subprocess.py:93} INFO - Analysis for article: (PR) Lenovo Unveils the New Legion 9i (18", 10) Ga...
[2025-05-09T19:09:22.370+0000] {subprocess.py:93} INFO - {
[2025-05-09T19:09:22.370+0000] {subprocess.py:93} INFO -   "description_number": "30",
[2025-05-09T19:09:22.371+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-09T19:09:22.372+0000] {subprocess.py:93} INFO -   "impact_explanation": "Irrelevant to gold market.",
[2025-05-09T19:09:22.372+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-09T19:09:22.382+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.398+0000] {subprocess.py:93} INFO - 25/05/09 19:09:22 INFO CheckpointFileManager: Writing atomically to file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/commits/0 using temp file file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/commits/.0.b3cc94ec-861f-46ae-8307-8026c3000edb.tmp
[2025-05-09T19:09:22.400+0000] {subprocess.py:93} INFO - 25/05/09 19:09:22 INFO CheckpointFileManager: Renamed temp file file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/commits/.0.b3cc94ec-861f-46ae-8307-8026c3000edb.tmp to file:/tmp/spark-checkpoint/981a99d0-2d5d-4a34-be79-d56092617037/commits/0
[2025-05-09T19:09:22.413+0000] {subprocess.py:93} INFO - 25/05/09 19:09:22 INFO MicroBatchExecution: Streaming query made progress: {
[2025-05-09T19:09:22.426+0000] {subprocess.py:93} INFO -   "id" : "e8a79812-275e-472f-9ede-b95cdfc5b5c0",
[2025-05-09T19:09:22.427+0000] {subprocess.py:93} INFO -   "runId" : "3292e765-3448-466c-bedb-0f5bde4015ec",
[2025-05-09T19:09:22.440+0000] {subprocess.py:93} INFO -   "name" : null,
[2025-05-09T19:09:22.441+0000] {subprocess.py:93} INFO -   "timestamp" : "2025-05-09T19:09:05.497Z",
[2025-05-09T19:09:22.442+0000] {subprocess.py:93} INFO -   "batchId" : 0,
[2025-05-09T19:09:22.443+0000] {subprocess.py:93} INFO -   "numInputRows" : 31,
[2025-05-09T19:09:22.444+0000] {subprocess.py:93} INFO -   "inputRowsPerSecond" : 0.0,
[2025-05-09T19:09:22.445+0000] {subprocess.py:93} INFO -   "processedRowsPerSecond" : 1.8616382416526542,
[2025-05-09T19:09:22.445+0000] {subprocess.py:93} INFO -   "durationMs" : {
[2025-05-09T19:09:22.446+0000] {subprocess.py:93} INFO -     "addBatch" : 14522,
[2025-05-09T19:09:22.447+0000] {subprocess.py:93} INFO -     "commitOffsets" : 54,
[2025-05-09T19:09:22.448+0000] {subprocess.py:93} INFO -     "getBatch" : 27,
[2025-05-09T19:09:22.449+0000] {subprocess.py:93} INFO -     "latestOffset" : 1188,
[2025-05-09T19:09:22.450+0000] {subprocess.py:93} INFO -     "queryPlanning" : 776,
[2025-05-09T19:09:22.451+0000] {subprocess.py:93} INFO -     "triggerExecution" : 16652,
[2025-05-09T19:09:22.451+0000] {subprocess.py:93} INFO -     "walCommit" : 66
[2025-05-09T19:09:22.452+0000] {subprocess.py:93} INFO -   },
[2025-05-09T19:09:22.455+0000] {subprocess.py:93} INFO -   "stateOperators" : [ ],
[2025-05-09T19:09:22.456+0000] {subprocess.py:93} INFO -   "sources" : [ {
[2025-05-09T19:09:22.456+0000] {subprocess.py:93} INFO -     "description" : "KafkaV2[Subscribe[gold-news]]",
[2025-05-09T19:09:22.463+0000] {subprocess.py:93} INFO -     "startOffset" : null,
[2025-05-09T19:09:22.469+0000] {subprocess.py:93} INFO -     "endOffset" : {
[2025-05-09T19:09:22.470+0000] {subprocess.py:93} INFO -       "gold-news" : {
[2025-05-09T19:09:22.473+0000] {subprocess.py:93} INFO -         "0" : 30
[2025-05-09T19:09:22.474+0000] {subprocess.py:93} INFO -       }
[2025-05-09T19:09:22.475+0000] {subprocess.py:93} INFO -     },
[2025-05-09T19:09:22.476+0000] {subprocess.py:93} INFO -     "latestOffset" : {
[2025-05-09T19:09:22.477+0000] {subprocess.py:93} INFO -       "gold-news" : {
[2025-05-09T19:09:22.477+0000] {subprocess.py:93} INFO -         "0" : 30
[2025-05-09T19:09:22.478+0000] {subprocess.py:93} INFO -       }
[2025-05-09T19:09:22.478+0000] {subprocess.py:93} INFO -     },
[2025-05-09T19:09:22.479+0000] {subprocess.py:93} INFO -     "numInputRows" : 31,
[2025-05-09T19:09:22.479+0000] {subprocess.py:93} INFO -     "inputRowsPerSecond" : 0.0,
[2025-05-09T19:09:22.480+0000] {subprocess.py:93} INFO -     "processedRowsPerSecond" : 1.8616382416526542,
[2025-05-09T19:09:22.480+0000] {subprocess.py:93} INFO -     "metrics" : {
[2025-05-09T19:09:22.484+0000] {subprocess.py:93} INFO -       "avgOffsetsBehindLatest" : "0.0",
[2025-05-09T19:09:22.487+0000] {subprocess.py:93} INFO -       "maxOffsetsBehindLatest" : "0",
[2025-05-09T19:09:22.488+0000] {subprocess.py:93} INFO -       "minOffsetsBehindLatest" : "0"
[2025-05-09T19:09:22.489+0000] {subprocess.py:93} INFO -     }
[2025-05-09T19:09:22.489+0000] {subprocess.py:93} INFO -   } ],
[2025-05-09T19:09:22.489+0000] {subprocess.py:93} INFO -   "sink" : {
[2025-05-09T19:09:22.490+0000] {subprocess.py:93} INFO -     "description" : "ForeachBatchSink",
[2025-05-09T19:09:22.490+0000] {subprocess.py:93} INFO -     "numOutputRows" : -1
[2025-05-09T19:09:22.491+0000] {subprocess.py:93} INFO -   }
[2025-05-09T19:09:22.493+0000] {subprocess.py:93} INFO - }
[2025-05-09T19:09:22.493+0000] {subprocess.py:93} INFO - 25/05/09 19:09:22 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 10000 milliseconds, but spent 16658 milliseconds
[2025-05-09T19:09:30.019+0000] {subprocess.py:93} INFO - 25/05/09 19:09:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-05-09T19:09:40.012+0000] {subprocess.py:93} INFO - 25/05/09 19:09:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-05-09T19:09:50.014+0000] {subprocess.py:93} INFO - 25/05/09 19:09:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-05-09T19:09:50.015+0000] {subprocess.py:93} INFO - 25/05/09 19:09:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-05-09T19:10:00.013+0000] {subprocess.py:93} INFO - 25/05/09 19:10:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-05-09T19:10:00.014+0000] {subprocess.py:93} INFO - 25/05/09 19:10:00 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-05-09T19:10:10.026+0000] {subprocess.py:93} INFO - 25/05/09 19:10:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-05-09T19:10:10.050+0000] {subprocess.py:93} INFO - 25/05/09 19:10:10 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-05-09T19:10:30.015+0000] {subprocess.py:93} INFO - 25/05/09 19:10:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-05-09T19:10:30.016+0000] {subprocess.py:93} INFO - 25/05/09 19:10:30 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-05-09T19:10:40.013+0000] {subprocess.py:93} INFO - 25/05/09 19:10:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-05-09T19:10:40.014+0000] {subprocess.py:93} INFO - 25/05/09 19:10:40 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-05-09T19:10:50.017+0000] {subprocess.py:93} INFO - 25/05/09 19:10:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-05-09T19:10:50.018+0000] {subprocess.py:93} INFO - 25/05/09 19:10:50 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
[2025-05-09T19:10:51.998+0000] {local_task_job_runner.py:294} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2025-05-09T19:10:52.008+0000] {process_utils.py:131} INFO - Sending 15 to group 5175. PIDs of all processes in the group: [5176, 5175]
[2025-05-09T19:10:52.009+0000] {process_utils.py:86} INFO - Sending the signal 15 to group 5175
[2025-05-09T19:10:52.010+0000] {taskinstance.py:1630} ERROR - Received SIGTERM. Terminating subprocesses.
[2025-05-09T19:10:52.011+0000] {subprocess.py:104} INFO - Sending SIGTERM signal to process group
[2025-05-09T19:10:52.104+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=5176, status='terminated', started='19:08:34') (5176) terminated with exit code None
[2025-05-09T19:10:52.106+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=5175, status='terminated', exitcode=0, started='19:08:33') (5175) terminated with exit code 0
