[2025-05-12T18:03:50.251+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: gold_news_pipeline.run_consumer manual__2025-05-12T18:03:42.950231+00:00 [queued]>
[2025-05-12T18:03:50.288+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: gold_news_pipeline.run_consumer manual__2025-05-12T18:03:42.950231+00:00 [queued]>
[2025-05-12T18:03:50.293+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 1
[2025-05-12T18:03:50.342+0000] {taskinstance.py:1380} INFO - Executing <Task(BashOperator): run_consumer> on 2025-05-12 18:03:42.950231+00:00
[2025-05-12T18:03:50.360+0000] {standard_task_runner.py:57} INFO - Started process 457 to run task
[2025-05-12T18:03:50.371+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'gold_news_pipeline', 'run_consumer', 'manual__2025-05-12T18:03:42.950231+00:00', '--job-id', '98', '--raw', '--subdir', 'DAGS_FOLDER/dag_news.py', '--cfg-path', '/tmp/tmpkqbjq92w']
[2025-05-12T18:03:50.379+0000] {standard_task_runner.py:85} INFO - Job 98: Subtask run_consumer
[2025-05-12T18:03:50.539+0000] {task_command.py:415} INFO - Running <TaskInstance: gold_news_pipeline.run_consumer manual__2025-05-12T18:03:42.950231+00:00 [running]> on host c26e5a949b49
[2025-05-12T18:03:50.689+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='gold_news_pipeline' AIRFLOW_CTX_TASK_ID='run_consumer' AIRFLOW_CTX_EXECUTION_DATE='2025-05-12T18:03:42.950231+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-12T18:03:42.950231+00:00'
[2025-05-12T18:03:50.692+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-05-12T18:03:50.693+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'docker exec gold_price_project-spark-1 spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,com.datastax.spark:spark-cassandra-connector_2.12:3.5.0 /scripts/spark_news.py']
[2025-05-12T18:03:50.709+0000] {subprocess.py:86} INFO - Output:
[2025-05-12T18:03:55.171+0000] {subprocess.py:93} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-05-12T18:03:55.339+0000] {subprocess.py:93} INFO - Ivy Default Cache set to: /root/.ivy2/cache
[2025-05-12T18:03:55.340+0000] {subprocess.py:93} INFO - The jars for the packages stored in: /root/.ivy2/jars
[2025-05-12T18:03:55.351+0000] {subprocess.py:93} INFO - org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
[2025-05-12T18:03:55.352+0000] {subprocess.py:93} INFO - com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency
[2025-05-12T18:03:55.355+0000] {subprocess.py:93} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-50b6a47c-2c84-4d77-8ce7-157ffa12aa64;1.0
[2025-05-12T18:03:55.357+0000] {subprocess.py:93} INFO - 	confs: [default]
[2025-05-12T18:03:58.138+0000] {subprocess.py:93} INFO - 	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central
[2025-05-12T18:03:58.808+0000] {subprocess.py:93} INFO - 	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central
[2025-05-12T18:03:58.953+0000] {subprocess.py:93} INFO - 	found org.apache.kafka#kafka-clients;3.4.1 in central
[2025-05-12T18:03:59.104+0000] {subprocess.py:93} INFO - 	found org.lz4#lz4-java;1.8.0 in central
[2025-05-12T18:03:59.257+0000] {subprocess.py:93} INFO - 	found org.xerial.snappy#snappy-java;1.1.10.3 in central
[2025-05-12T18:03:59.855+0000] {subprocess.py:93} INFO - 	found org.slf4j#slf4j-api;2.0.7 in central
[2025-05-12T18:04:00.946+0000] {subprocess.py:93} INFO - 	found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
[2025-05-12T18:04:01.163+0000] {subprocess.py:93} INFO - 	found org.apache.hadoop#hadoop-client-api;3.3.4 in central
[2025-05-12T18:04:04.839+0000] {subprocess.py:93} INFO - 	found commons-logging#commons-logging;1.1.3 in central
[2025-05-12T18:04:04.987+0000] {subprocess.py:93} INFO - 	found com.google.code.findbugs#jsr305;3.0.0 in central
[2025-05-12T18:04:06.278+0000] {subprocess.py:93} INFO - 	found org.apache.commons#commons-pool2;2.11.1 in central
[2025-05-12T18:04:06.408+0000] {subprocess.py:93} INFO - 	found com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 in central
[2025-05-12T18:04:06.543+0000] {subprocess.py:93} INFO - 	found com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 in central
[2025-05-12T18:04:06.669+0000] {subprocess.py:93} INFO - 	found org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central
[2025-05-12T18:04:09.051+0000] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-core-shaded;4.13.0 in central
[2025-05-12T18:04:09.200+0000] {subprocess.py:93} INFO - 	found com.datastax.oss#native-protocol;1.5.0 in central
[2025-05-12T18:04:09.351+0000] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central
[2025-05-12T18:04:09.496+0000] {subprocess.py:93} INFO - 	found com.typesafe#config;1.4.1 in central
[2025-05-12T18:04:10.368+0000] {subprocess.py:93} INFO - 	found io.dropwizard.metrics#metrics-core;4.1.18 in central
[2025-05-12T18:04:10.489+0000] {subprocess.py:93} INFO - 	found org.hdrhistogram#HdrHistogram;2.1.12 in central
[2025-05-12T18:04:10.610+0000] {subprocess.py:93} INFO - 	found org.reactivestreams#reactive-streams;1.0.3 in central
[2025-05-12T18:04:10.969+0000] {subprocess.py:93} INFO - 	found com.github.stephenc.jcip#jcip-annotations;1.0-1 in central
[2025-05-12T18:04:11.083+0000] {subprocess.py:93} INFO - 	found com.github.spotbugs#spotbugs-annotations;3.1.12 in central
[2025-05-12T18:04:11.216+0000] {subprocess.py:93} INFO - 	found com.google.code.findbugs#jsr305;3.0.2 in central
[2025-05-12T18:04:11.355+0000] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central
[2025-05-12T18:04:11.479+0000] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-query-builder;4.13.0 in central
[2025-05-12T18:04:12.667+0000] {subprocess.py:93} INFO - 	found org.apache.commons#commons-lang3;3.10 in central
[2025-05-12T18:04:13.661+0000] {subprocess.py:93} INFO - 	found com.thoughtworks.paranamer#paranamer;2.8 in central
[2025-05-12T18:04:13.799+0000] {subprocess.py:93} INFO - 	found org.scala-lang#scala-reflect;2.12.11 in central
[2025-05-12T18:04:13.903+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.0/spark-sql-kafka-0-10_2.12-3.5.0.jar ...
[2025-05-12T18:04:14.153+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0!spark-sql-kafka-0-10_2.12.jar (306ms)
[2025-05-12T18:04:14.211+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector_2.12/3.5.0/spark-cassandra-connector_2.12-3.5.0.jar ...
[2025-05-12T18:04:14.716+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector_2.12;3.5.0!spark-cassandra-connector_2.12.jar (563ms)
[2025-05-12T18:04:14.772+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.5.0/spark-token-provider-kafka-0-10_2.12-3.5.0.jar ...
[2025-05-12T18:04:14.838+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0!spark-token-provider-kafka-0-10_2.12.jar (120ms)
[2025-05-12T18:04:14.890+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.4.1/kafka-clients-3.4.1.jar ...
[2025-05-12T18:04:16.223+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] org.apache.kafka#kafka-clients;3.4.1!kafka-clients.jar (1384ms)
[2025-05-12T18:04:16.276+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.11.1/commons-pool2-2.11.1.jar ...
[2025-05-12T18:04:16.359+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] org.apache.commons#commons-pool2;2.11.1!commons-pool2.jar (135ms)
[2025-05-12T18:04:16.416+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.3.4/hadoop-client-runtime-3.3.4.jar ...
[2025-05-12T18:04:21.856+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] org.apache.hadoop#hadoop-client-runtime;3.3.4!hadoop-client-runtime.jar (5497ms)
[2025-05-12T18:04:21.912+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar ...
[2025-05-12T18:04:22.039+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] org.lz4#lz4-java;1.8.0!lz4-java.jar (181ms)
[2025-05-12T18:04:22.096+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.10.3/snappy-java-1.1.10.3.jar ...
[2025-05-12T18:04:22.411+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.10.3!snappy-java.jar(bundle) (371ms)
[2025-05-12T18:04:22.515+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/2.0.7/slf4j-api-2.0.7.jar ...
[2025-05-12T18:04:22.572+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] org.slf4j#slf4j-api;2.0.7!slf4j-api.jar (160ms)
[2025-05-12T18:04:22.625+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.3.4/hadoop-client-api-3.3.4.jar ...
[2025-05-12T18:04:25.340+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] org.apache.hadoop#hadoop-client-api;3.3.4!hadoop-client-api.jar (2768ms)
[2025-05-12T18:04:25.397+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...
[2025-05-12T18:04:25.462+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (120ms)
[2025-05-12T18:04:25.517+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector-driver_2.12/3.5.0/spark-cassandra-connector-driver_2.12-3.5.0.jar ...
[2025-05-12T18:04:25.688+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0!spark-cassandra-connector-driver_2.12.jar (225ms)
[2025-05-12T18:04:25.739+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-collection-compat_2.12/2.11.0/scala-collection-compat_2.12-2.11.0.jar ...
[2025-05-12T18:04:25.821+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] org.scala-lang.modules#scala-collection-compat_2.12;2.11.0!scala-collection-compat_2.12.jar (130ms)
[2025-05-12T18:04:25.873+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-core-shaded/4.13.0/java-driver-core-shaded-4.13.0.jar ...
[2025-05-12T18:04:26.730+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] com.datastax.oss#java-driver-core-shaded;4.13.0!java-driver-core-shaded.jar (910ms)
[2025-05-12T18:04:26.784+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-mapper-runtime/4.13.0/java-driver-mapper-runtime-4.13.0.jar ...
[2025-05-12T18:04:26.845+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] com.datastax.oss#java-driver-mapper-runtime;4.13.0!java-driver-mapper-runtime.jar(bundle) (113ms)
[2025-05-12T18:04:26.900+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.10/commons-lang3-3.10.jar ...
[2025-05-12T18:04:27.006+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] org.apache.commons#commons-lang3;3.10!commons-lang3.jar (159ms)
[2025-05-12T18:04:27.059+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar ...
[2025-05-12T18:04:27.119+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.8!paranamer.jar(bundle) (110ms)
[2025-05-12T18:04:27.173+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.12.11/scala-reflect-2.12.11.jar ...
[2025-05-12T18:04:27.644+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] org.scala-lang#scala-reflect;2.12.11!scala-reflect.jar (523ms)
[2025-05-12T18:04:27.700+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/com/datastax/oss/native-protocol/1.5.0/native-protocol-1.5.0.jar ...
[2025-05-12T18:04:27.783+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] com.datastax.oss#native-protocol;1.5.0!native-protocol.jar(bundle) (139ms)
[2025-05-12T18:04:27.905+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-shaded-guava/25.1-jre-graal-sub-1/java-driver-shaded-guava-25.1-jre-graal-sub-1.jar ...
[2025-05-12T18:04:28.255+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1!java-driver-shaded-guava.jar (471ms)
[2025-05-12T18:04:28.310+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/com/typesafe/config/1.4.1/config-1.4.1.jar ...
[2025-05-12T18:04:28.391+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] com.typesafe#config;1.4.1!config.jar(bundle) (134ms)
[2025-05-12T18:04:28.446+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/4.1.18/metrics-core-4.1.18.jar ...
[2025-05-12T18:04:28.509+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] io.dropwizard.metrics#metrics-core;4.1.18!metrics-core.jar(bundle) (117ms)
[2025-05-12T18:04:28.562+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/org/hdrhistogram/HdrHistogram/2.1.12/HdrHistogram-2.1.12.jar ...
[2025-05-12T18:04:28.633+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] org.hdrhistogram#HdrHistogram;2.1.12!HdrHistogram.jar(bundle) (123ms)
[2025-05-12T18:04:28.686+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/org/reactivestreams/reactive-streams/1.0.3/reactive-streams-1.0.3.jar ...
[2025-05-12T18:04:28.741+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] org.reactivestreams#reactive-streams;1.0.3!reactive-streams.jar (106ms)
[2025-05-12T18:04:28.792+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar ...
[2025-05-12T18:04:28.846+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] com.github.stephenc.jcip#jcip-annotations;1.0-1!jcip-annotations.jar (104ms)
[2025-05-12T18:04:28.898+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar ...
[2025-05-12T18:04:28.956+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] com.github.spotbugs#spotbugs-annotations;3.1.12!spotbugs-annotations.jar (108ms)
[2025-05-12T18:04:29.009+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar ...
[2025-05-12T18:04:29.062+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.2!jsr305.jar (105ms)
[2025-05-12T18:04:29.114+0000] {subprocess.py:93} INFO - downloading https://repo1.maven.org/maven2/com/datastax/oss/java-driver-query-builder/4.13.0/java-driver-query-builder-4.13.0.jar ...
[2025-05-12T18:04:29.195+0000] {subprocess.py:93} INFO - 	[SUCCESSFUL ] com.datastax.oss#java-driver-query-builder;4.13.0!java-driver-query-builder.jar(bundle) (130ms)
[2025-05-12T18:04:29.196+0000] {subprocess.py:93} INFO - :: resolution report :: resolve 18491ms :: artifacts dl 15349ms
[2025-05-12T18:04:29.197+0000] {subprocess.py:93} INFO - 	:: modules in use:
[2025-05-12T18:04:29.198+0000] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]
[2025-05-12T18:04:29.198+0000] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]
[2025-05-12T18:04:29.199+0000] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]
[2025-05-12T18:04:29.199+0000] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]
[2025-05-12T18:04:29.200+0000] {subprocess.py:93} INFO - 	com.datastax.oss#native-protocol;1.5.0 from central in [default]
[2025-05-12T18:04:29.200+0000] {subprocess.py:93} INFO - 	com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 from central in [default]
[2025-05-12T18:04:29.201+0000] {subprocess.py:93} INFO - 	com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 from central in [default]
[2025-05-12T18:04:29.201+0000] {subprocess.py:93} INFO - 	com.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]
[2025-05-12T18:04:29.202+0000] {subprocess.py:93} INFO - 	com.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]
[2025-05-12T18:04:29.202+0000] {subprocess.py:93} INFO - 	com.google.code.findbugs#jsr305;3.0.2 from central in [default]
[2025-05-12T18:04:29.203+0000] {subprocess.py:93} INFO - 	com.thoughtworks.paranamer#paranamer;2.8 from central in [default]
[2025-05-12T18:04:29.204+0000] {subprocess.py:93} INFO - 	com.typesafe#config;1.4.1 from central in [default]
[2025-05-12T18:04:29.204+0000] {subprocess.py:93} INFO - 	commons-logging#commons-logging;1.1.3 from central in [default]
[2025-05-12T18:04:29.205+0000] {subprocess.py:93} INFO - 	io.dropwizard.metrics#metrics-core;4.1.18 from central in [default]
[2025-05-12T18:04:29.205+0000] {subprocess.py:93} INFO - 	org.apache.commons#commons-lang3;3.10 from central in [default]
[2025-05-12T18:04:29.206+0000] {subprocess.py:93} INFO - 	org.apache.commons#commons-pool2;2.11.1 from central in [default]
[2025-05-12T18:04:29.206+0000] {subprocess.py:93} INFO - 	org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
[2025-05-12T18:04:29.208+0000] {subprocess.py:93} INFO - 	org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
[2025-05-12T18:04:29.209+0000] {subprocess.py:93} INFO - 	org.apache.kafka#kafka-clients;3.4.1 from central in [default]
[2025-05-12T18:04:29.210+0000] {subprocess.py:93} INFO - 	org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]
[2025-05-12T18:04:29.210+0000] {subprocess.py:93} INFO - 	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]
[2025-05-12T18:04:29.211+0000] {subprocess.py:93} INFO - 	org.hdrhistogram#HdrHistogram;2.1.12 from central in [default]
[2025-05-12T18:04:29.211+0000] {subprocess.py:93} INFO - 	org.lz4#lz4-java;1.8.0 from central in [default]
[2025-05-12T18:04:29.212+0000] {subprocess.py:93} INFO - 	org.reactivestreams#reactive-streams;1.0.3 from central in [default]
[2025-05-12T18:04:29.212+0000] {subprocess.py:93} INFO - 	org.scala-lang#scala-reflect;2.12.11 from central in [default]
[2025-05-12T18:04:29.213+0000] {subprocess.py:93} INFO - 	org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]
[2025-05-12T18:04:29.214+0000] {subprocess.py:93} INFO - 	org.slf4j#slf4j-api;2.0.7 from central in [default]
[2025-05-12T18:04:29.214+0000] {subprocess.py:93} INFO - 	org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
[2025-05-12T18:04:29.215+0000] {subprocess.py:93} INFO - 	:: evicted modules:
[2025-05-12T18:04:29.215+0000] {subprocess.py:93} INFO - 	com.google.code.findbugs#jsr305;3.0.0 by [com.google.code.findbugs#jsr305;3.0.2] in [default]
[2025-05-12T18:04:29.216+0000] {subprocess.py:93} INFO - 	org.slf4j#slf4j-api;1.7.26 by [org.slf4j#slf4j-api;2.0.7] in [default]
[2025-05-12T18:04:29.216+0000] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-05-12T18:04:29.217+0000] {subprocess.py:93} INFO - 	|                  |            modules            ||   artifacts   |
[2025-05-12T18:04:29.218+0000] {subprocess.py:93} INFO - 	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-05-12T18:04:29.218+0000] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-05-12T18:04:29.219+0000] {subprocess.py:93} INFO - 	|      default     |   30  |   29  |   29  |   2   ||   28  |   28  |
[2025-05-12T18:04:29.220+0000] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-05-12T18:04:29.220+0000] {subprocess.py:93} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-50b6a47c-2c84-4d77-8ce7-157ffa12aa64
[2025-05-12T18:04:29.221+0000] {subprocess.py:93} INFO - 	confs: [default]
[2025-05-12T18:04:29.332+0000] {subprocess.py:93} INFO - 	28 artifacts copied, 0 already retrieved (75061kB/111ms)
[2025-05-12T18:04:29.601+0000] {subprocess.py:93} INFO - 25/05/12 18:04:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-05-12T18:04:31.761+0000] {subprocess.py:93} INFO - 25/05/12 18:04:31 INFO SparkContext: Running Spark version 3.5.1
[2025-05-12T18:04:31.762+0000] {subprocess.py:93} INFO - 25/05/12 18:04:31 INFO SparkContext: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64
[2025-05-12T18:04:31.763+0000] {subprocess.py:93} INFO - 25/05/12 18:04:31 INFO SparkContext: Java version 11.0.22
[2025-05-12T18:04:31.825+0000] {subprocess.py:93} INFO - 25/05/12 18:04:31 INFO ResourceUtils: ==============================================================
[2025-05-12T18:04:31.827+0000] {subprocess.py:93} INFO - 25/05/12 18:04:31 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-05-12T18:04:31.828+0000] {subprocess.py:93} INFO - 25/05/12 18:04:31 INFO ResourceUtils: ==============================================================
[2025-05-12T18:04:31.828+0000] {subprocess.py:93} INFO - 25/05/12 18:04:31 INFO SparkContext: Submitted application: GoldNewsStreaming
[2025-05-12T18:04:31.889+0000] {subprocess.py:93} INFO - 25/05/12 18:04:31 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-05-12T18:04:31.920+0000] {subprocess.py:93} INFO - 25/05/12 18:04:31 INFO ResourceProfile: Limiting resource is cpu
[2025-05-12T18:04:31.922+0000] {subprocess.py:93} INFO - 25/05/12 18:04:31 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-05-12T18:04:32.056+0000] {subprocess.py:93} INFO - 25/05/12 18:04:32 INFO SecurityManager: Changing view acls to: root
[2025-05-12T18:04:32.057+0000] {subprocess.py:93} INFO - 25/05/12 18:04:32 INFO SecurityManager: Changing modify acls to: root
[2025-05-12T18:04:32.058+0000] {subprocess.py:93} INFO - 25/05/12 18:04:32 INFO SecurityManager: Changing view acls groups to:
[2025-05-12T18:04:32.059+0000] {subprocess.py:93} INFO - 25/05/12 18:04:32 INFO SecurityManager: Changing modify acls groups to:
[2025-05-12T18:04:32.060+0000] {subprocess.py:93} INFO - 25/05/12 18:04:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
[2025-05-12T18:04:32.508+0000] {subprocess.py:93} INFO - 25/05/12 18:04:32 INFO Utils: Successfully started service 'sparkDriver' on port 33439.
[2025-05-12T18:04:32.556+0000] {subprocess.py:93} INFO - 25/05/12 18:04:32 INFO SparkEnv: Registering MapOutputTracker
[2025-05-12T18:04:32.644+0000] {subprocess.py:93} INFO - 25/05/12 18:04:32 INFO SparkEnv: Registering BlockManagerMaster
[2025-05-12T18:04:32.685+0000] {subprocess.py:93} INFO - 25/05/12 18:04:32 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-05-12T18:04:32.690+0000] {subprocess.py:93} INFO - 25/05/12 18:04:32 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-05-12T18:04:32.698+0000] {subprocess.py:93} INFO - 25/05/12 18:04:32 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-05-12T18:04:32.771+0000] {subprocess.py:93} INFO - 25/05/12 18:04:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-020b2ac6-973c-4f83-ad83-b00b05d25a02
[2025-05-12T18:04:32.800+0000] {subprocess.py:93} INFO - 25/05/12 18:04:32 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-05-12T18:04:32.834+0000] {subprocess.py:93} INFO - 25/05/12 18:04:32 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-05-12T18:04:33.170+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-05-12T18:04:33.346+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-05-12T18:04:33.440+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at spark://dedf70ba0687:33439/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.442+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar at spark://dedf70ba0687:33439/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.443+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at spark://dedf70ba0687:33439/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.444+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at spark://dedf70ba0687:33439/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1747073071726
[2025-05-12T18:04:33.444+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://dedf70ba0687:33439/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1747073071726
[2025-05-12T18:04:33.445+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://dedf70ba0687:33439/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1747073071726
[2025-05-12T18:04:33.446+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at spark://dedf70ba0687:33439/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.447+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://dedf70ba0687:33439/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1747073071726
[2025-05-12T18:04:33.448+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://dedf70ba0687:33439/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1747073071726
[2025-05-12T18:04:33.448+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://dedf70ba0687:33439/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1747073071726
[2025-05-12T18:04:33.450+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://dedf70ba0687:33439/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1747073071726
[2025-05-12T18:04:33.451+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar at spark://dedf70ba0687:33439/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.453+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar at spark://dedf70ba0687:33439/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.455+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar at spark://dedf70ba0687:33439/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.456+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar at spark://dedf70ba0687:33439/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.457+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at spark://dedf70ba0687:33439/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1747073071726
[2025-05-12T18:04:33.458+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at spark://dedf70ba0687:33439/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1747073071726
[2025-05-12T18:04:33.459+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at spark://dedf70ba0687:33439/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1747073071726
[2025-05-12T18:04:33.459+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at spark://dedf70ba0687:33439/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.460+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at spark://dedf70ba0687:33439/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1747073071726
[2025-05-12T18:04:33.461+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar at spark://dedf70ba0687:33439/jars/com.typesafe_config-1.4.1.jar with timestamp 1747073071726
[2025-05-12T18:04:33.461+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at spark://dedf70ba0687:33439/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1747073071726
[2025-05-12T18:04:33.462+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at spark://dedf70ba0687:33439/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1747073071726
[2025-05-12T18:04:33.462+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at spark://dedf70ba0687:33439/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1747073071726
[2025-05-12T18:04:33.463+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at spark://dedf70ba0687:33439/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1747073071726
[2025-05-12T18:04:33.463+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at spark://dedf70ba0687:33439/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1747073071726
[2025-05-12T18:04:33.467+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at spark://dedf70ba0687:33439/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1747073071726
[2025-05-12T18:04:33.469+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar at spark://dedf70ba0687:33439/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.470+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.471+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
[2025-05-12T18:04:33.501+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar at file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.505+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-05-12T18:04:33.566+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.566+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
[2025-05-12T18:04:33.567+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1747073071726
[2025-05-12T18:04:33.579+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.kafka_kafka-clients-3.4.1.jar
[2025-05-12T18:04:33.600+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1747073071726
[2025-05-12T18:04:33.602+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.commons_commons-pool2-2.11.1.jar
[2025-05-12T18:04:33.622+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1747073071726
[2025-05-12T18:04:33.623+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2025-05-12T18:04:33.712+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.713+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.lz4_lz4-java-1.8.0.jar
[2025-05-12T18:04:33.718+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1747073071726
[2025-05-12T18:04:33.719+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2025-05-12T18:04:33.734+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1747073071726
[2025-05-12T18:04:33.734+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.slf4j_slf4j-api-2.0.7.jar
[2025-05-12T18:04:33.741+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1747073071726
[2025-05-12T18:04:33.742+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2025-05-12T18:04:33.800+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1747073071726
[2025-05-12T18:04:33.804+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/commons-logging_commons-logging-1.1.3.jar
[2025-05-12T18:04:33.811+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar at file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.812+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-05-12T18:04:33.821+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar at file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.822+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-05-12T18:04:33.827+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar at file:///root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.828+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-05-12T18:04:33.857+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar at file:///root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.860+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-05-12T18:04:33.865+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at file:///root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1747073071726
[2025-05-12T18:04:33.866+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.commons_commons-lang3-3.10.jar
[2025-05-12T18:04:33.882+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at file:///root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1747073071726
[2025-05-12T18:04:33.884+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-05-12T18:04:33.889+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at file:///root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1747073071726
[2025-05-12T18:04:33.890+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.scala-lang_scala-reflect-2.12.11.jar
[2025-05-12T18:04:33.914+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at file:///root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:33.915+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_native-protocol-1.5.0.jar
[2025-05-12T18:04:33.931+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at file:///root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1747073071726
[2025-05-12T18:04:33.933+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-05-12T18:04:33.950+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar at file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar with timestamp 1747073071726
[2025-05-12T18:04:33.951+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/com.typesafe_config-1.4.1.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.typesafe_config-1.4.1.jar
[2025-05-12T18:04:33.967+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at file:///root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1747073071726
[2025-05-12T18:04:33.972+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-05-12T18:04:33.988+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO SparkContext: Added file file:///root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at file:///root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1747073071726
[2025-05-12T18:04:33.996+0000] {subprocess.py:93} INFO - 25/05/12 18:04:33 INFO Utils: Copying /root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-05-12T18:04:34.043+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO SparkContext: Added file file:///root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at file:///root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1747073071726
[2025-05-12T18:04:34.045+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: Copying /root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-05-12T18:04:34.053+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO SparkContext: Added file file:///root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at file:///root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1747073071726
[2025-05-12T18:04:34.054+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: Copying /root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-05-12T18:04:34.064+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO SparkContext: Added file file:///root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at file:///root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1747073071726
[2025-05-12T18:04:34.065+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: Copying /root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-05-12T18:04:34.069+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO SparkContext: Added file file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1747073071726
[2025-05-12T18:04:34.071+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: Copying /root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-05-12T18:04:34.081+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar at file:///root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1747073071726
[2025-05-12T18:04:34.082+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: Copying /root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-05-12T18:04:34.238+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Starting executor ID driver on host dedf70ba0687
[2025-05-12T18:04:34.239+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64
[2025-05-12T18:04:34.240+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Java version 11.0.22
[2025-05-12T18:04:34.253+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-05-12T18:04:34.255+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4fed5e6a for default.
[2025-05-12T18:04:34.286+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:34.320+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
[2025-05-12T18:04:34.335+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1747073071726
[2025-05-12T18:04:34.337+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.commons_commons-lang3-3.10.jar
[2025-05-12T18:04:34.338+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1747073071726
[2025-05-12T18:04:34.355+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2025-05-12T18:04:34.359+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1747073071726
[2025-05-12T18:04:34.391+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2025-05-12T18:04:34.396+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1747073071726
[2025-05-12T18:04:34.402+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-05-12T18:04:34.406+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1747073071726
[2025-05-12T18:04:34.407+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-05-12T18:04:34.416+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1747073071726
[2025-05-12T18:04:34.417+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-05-12T18:04:34.429+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1747073071726
[2025-05-12T18:04:34.435+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-05-12T18:04:34.444+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar with timestamp 1747073071726
[2025-05-12T18:04:34.445+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/com.typesafe_config-1.4.1.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.typesafe_config-1.4.1.jar
[2025-05-12T18:04:34.449+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1747073071726
[2025-05-12T18:04:34.451+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2025-05-12T18:04:34.455+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1747073071726
[2025-05-12T18:04:34.463+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-05-12T18:04:34.465+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:34.466+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
[2025-05-12T18:04:34.469+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1747073071726
[2025-05-12T18:04:34.471+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.slf4j_slf4j-api-2.0.7.jar
[2025-05-12T18:04:34.485+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1747073071726
[2025-05-12T18:04:34.491+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-05-12T18:04:34.492+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1747073071726
[2025-05-12T18:04:34.493+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-05-12T18:04:34.495+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1747073071726
[2025-05-12T18:04:34.496+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.commons_commons-pool2-2.11.1.jar
[2025-05-12T18:04:34.500+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:34.501+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_native-protocol-1.5.0.jar
[2025-05-12T18:04:34.508+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1747073071726
[2025-05-12T18:04:34.509+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/commons-logging_commons-logging-1.1.3.jar
[2025-05-12T18:04:34.512+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1747073071726
[2025-05-12T18:04:34.513+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-05-12T18:04:34.524+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1747073071726
[2025-05-12T18:04:34.526+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-05-12T18:04:34.527+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1747073071726
[2025-05-12T18:04:34.538+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.scala-lang_scala-reflect-2.12.11.jar
[2025-05-12T18:04:34.540+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:34.544+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-05-12T18:04:34.551+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1747073071726
[2025-05-12T18:04:34.552+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-05-12T18:04:34.555+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1747073071726
[2025-05-12T18:04:34.556+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-05-12T18:04:34.560+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1747073071726
[2025-05-12T18:04:34.561+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-05-12T17:04:38.779+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:37.299+0000] {subprocess.py:93} INFO - 25/05/12 18:04:34 INFO Utils: /root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-05-12T18:04:37.303+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Executor: Fetching file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1747073071726
[2025-05-12T18:04:37.312+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Utils: /root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.lz4_lz4-java-1.8.0.jar
[2025-05-12T18:04:37.316+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1747073071726
[2025-05-12T18:04:37.328+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Utils: /root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.kafka_kafka-clients-3.4.1.jar
[2025-05-12T18:04:37.335+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1747073071726
[2025-05-12T18:04:37.426+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO TransportClientFactory: Successfully created connection to dedf70ba0687/172.18.0.7:33439 after 59 ms (0 ms spent in bootstraps)
[2025-05-12T18:04:37.442+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp14652680671336267594.tmp
[2025-05-12T18:04:37.494+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp14652680671336267594.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-05-12T18:04:37.499+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.hdrhistogram_HdrHistogram-2.1.12.jar to class loader default
[2025-05-12T18:04:37.500+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1747073071726
[2025-05-12T18:04:37.500+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp4575961568292393769.tmp
[2025-05-12T18:04:37.810+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp4575961568292393769.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2025-05-12T18:04:37.824+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to class loader default
[2025-05-12T18:04:37.833+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1747073071726
[2025-05-12T18:04:37.834+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp17116848695569177609.tmp
[2025-05-12T18:04:37.837+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp17116848695569177609.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.lz4_lz4-java-1.8.0.jar
[2025-05-12T18:04:37.847+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.lz4_lz4-java-1.8.0.jar to class loader default
[2025-05-12T18:04:37.849+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1747073071726
[2025-05-12T18:04:37.850+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp7000102631155501162.tmp
[2025-05-12T18:04:37.900+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp7000102631155501162.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-05-12T18:04:37.908+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to class loader default
[2025-05-12T18:04:37.909+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1747073071726
[2025-05-12T18:04:37.910+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp1005005437212853330.tmp
[2025-05-12T18:04:37.927+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp1005005437212853330.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2025-05-12T18:04:37.931+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.xerial.snappy_snappy-java-1.1.10.3.jar to class loader default
[2025-05-12T18:04:37.935+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1747073071726
[2025-05-12T18:04:37.936+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/org.scala-lang_scala-reflect-2.12.11.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp43611587608277902.tmp
[2025-05-12T18:04:37.961+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp43611587608277902.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.scala-lang_scala-reflect-2.12.11.jar
[2025-05-12T18:04:37.971+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.scala-lang_scala-reflect-2.12.11.jar to class loader default
[2025-05-12T18:04:37.972+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1747073071726
[2025-05-12T18:04:37.972+0000] {subprocess.py:93} INFO - 25/05/12 18:04:37 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp2412367166460589861.tmp
[2025-05-12T18:04:38.013+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp2412367166460589861.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.kafka_kafka-clients-3.4.1.jar
[2025-05-12T18:04:38.019+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.kafka_kafka-clients-3.4.1.jar to class loader default
[2025-05-12T18:04:38.020+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:38.021+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/com.datastax.oss_native-protocol-1.5.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp11408475870146022144.tmp
[2025-05-12T18:04:38.029+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp11408475870146022144.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_native-protocol-1.5.0.jar
[2025-05-12T18:04:38.034+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_native-protocol-1.5.0.jar to class loader default
[2025-05-12T18:04:38.035+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1747073071726
[2025-05-12T18:04:38.037+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp9899826396331358616.tmp
[2025-05-12T18:04:38.043+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp9899826396331358616.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-05-12T18:04:38.046+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to class loader default
[2025-05-12T18:04:38.047+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:38.048+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp474968443065691531.tmp
[2025-05-12T18:04:38.051+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp474968443065691531.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
[2025-05-12T18:04:38.057+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to class loader default
[2025-05-12T18:04:38.058+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1747073071726
[2025-05-12T18:04:38.059+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/com.google.code.findbugs_jsr305-3.0.2.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp10506515515519136239.tmp
[2025-05-12T18:04:38.061+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp10506515515519136239.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-05-12T18:04:38.064+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.google.code.findbugs_jsr305-3.0.2.jar to class loader default
[2025-05-12T18:04:38.065+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1747073071726
[2025-05-12T18:04:38.066+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp16496975524198357463.tmp
[2025-05-12T18:04:38.069+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp16496975524198357463.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.commons_commons-pool2-2.11.1.jar
[2025-05-12T18:04:38.074+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.commons_commons-pool2-2.11.1.jar to class loader default
[2025-05-12T18:04:38.075+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1747073071726
[2025-05-12T18:04:38.076+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp7359819828908884356.tmp
[2025-05-12T18:04:38.078+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp7359819828908884356.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-05-12T18:04:38.081+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/io.dropwizard.metrics_metrics-core-4.1.18.jar to class loader default
[2025-05-12T18:04:38.082+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1747073071726
[2025-05-12T18:04:38.083+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp3816484070982028529.tmp
[2025-05-12T18:04:38.087+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp3816484070982028529.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-05-12T18:04:38.091+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to class loader default
[2025-05-12T18:04:38.092+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1747073071726
[2025-05-12T18:04:38.092+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp17465409931442248348.tmp
[2025-05-12T18:04:38.094+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp17465409931442248348.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-05-12T18:04:38.097+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to class loader default
[2025-05-12T18:04:38.098+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1747073071726
[2025-05-12T18:04:38.098+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp16108725991392600134.tmp
[2025-05-12T18:04:38.104+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp16108725991392600134.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-05-12T18:04:38.107+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-query-builder-4.13.0.jar to class loader default
[2025-05-12T18:04:38.108+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:38.109+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp10938533736896312989.tmp
[2025-05-12T18:04:38.117+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp10938533736896312989.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-05-12T18:04:38.121+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to class loader default
[2025-05-12T18:04:38.123+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1747073071726
[2025-05-12T18:04:38.125+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp9402946073181764867.tmp
[2025-05-12T18:04:38.126+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp9402946073181764867.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-05-12T18:04:38.131+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.thoughtworks.paranamer_paranamer-2.8.jar to class loader default
[2025-05-12T18:04:38.133+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1747073071726
[2025-05-12T18:04:38.134+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp8177447524833468365.tmp
[2025-05-12T18:04:38.137+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp8177447524833468365.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/commons-logging_commons-logging-1.1.3.jar
[2025-05-12T18:04:38.141+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/commons-logging_commons-logging-1.1.3.jar to class loader default
[2025-05-12T18:04:38.142+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/com.typesafe_config-1.4.1.jar with timestamp 1747073071726
[2025-05-12T18:04:38.145+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/com.typesafe_config-1.4.1.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp9424396408393032105.tmp
[2025-05-12T18:04:38.150+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp9424396408393032105.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.typesafe_config-1.4.1.jar
[2025-05-12T18:04:38.155+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.typesafe_config-1.4.1.jar to class loader default
[2025-05-12T18:04:38.156+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:38.158+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp5973985466039379717.tmp
[2025-05-12T18:04:38.171+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp5973985466039379717.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-05-12T18:04:38.176+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to class loader default
[2025-05-12T18:04:38.180+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1747073071726
[2025-05-12T18:04:38.182+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp9408233621272592142.tmp
[2025-05-12T18:04:38.186+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp9408233621272592142.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.slf4j_slf4j-api-2.0.7.jar
[2025-05-12T18:04:38.190+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.slf4j_slf4j-api-2.0.7.jar to class loader default
[2025-05-12T18:04:38.191+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1747073071726
[2025-05-12T18:04:38.195+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp9836246363798454934.tmp
[2025-05-12T18:04:38.198+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp9836246363798454934.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-05-12T18:04:38.202+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to class loader default
[2025-05-12T18:04:38.203+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1747073071726
[2025-05-12T18:04:38.204+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp17358168249293610855.tmp
[2025-05-12T18:04:38.229+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp17358168249293610855.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-05-12T18:04:38.234+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to class loader default
[2025-05-12T18:04:38.234+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1747073071726
[2025-05-12T18:04:38.235+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/org.apache.commons_commons-lang3-3.10.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp3993274670847094297.tmp
[2025-05-12T18:04:38.242+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp3993274670847094297.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.commons_commons-lang3-3.10.jar
[2025-05-12T18:04:38.245+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.commons_commons-lang3-3.10.jar to class loader default
[2025-05-12T18:04:38.246+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1747073071726
[2025-05-12T18:04:38.247+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp4131539720682095938.tmp
[2025-05-12T18:04:38.251+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp4131539720682095938.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
[2025-05-12T18:04:38.257+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to class loader default
[2025-05-12T18:04:38.258+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1747073071726
[2025-05-12T18:04:38.259+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp4400492043344925968.tmp
[2025-05-12T18:04:38.366+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp4400492043344925968.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2025-05-12T18:04:38.383+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.apache.hadoop_hadoop-client-api-3.3.4.jar to class loader default
[2025-05-12T18:04:38.384+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Fetching spark://dedf70ba0687:33439/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1747073071726
[2025-05-12T18:04:38.385+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Fetching spark://dedf70ba0687:33439/jars/org.reactivestreams_reactive-streams-1.0.3.jar to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp14743567920825525389.tmp
[2025-05-12T18:04:38.386+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/fetchFileTemp14743567920825525389.tmp has been previously copied to /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-05-12T18:04:38.389+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Executor: Adding file:/tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/userFiles-2be8c3e9-406e-4f46-b012-2767880e30bd/org.reactivestreams_reactive-streams-1.0.3.jar to class loader default
[2025-05-12T18:04:38.409+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40903.
[2025-05-12T18:04:38.411+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO NettyBlockTransferService: Server created on dedf70ba0687:40903
[2025-05-12T18:04:38.417+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-05-12T18:04:38.430+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, dedf70ba0687, 40903, None)
[2025-05-12T18:04:38.441+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO BlockManagerMasterEndpoint: Registering block manager dedf70ba0687:40903 with 434.4 MiB RAM, BlockManagerId(driver, dedf70ba0687, 40903, None)
[2025-05-12T18:04:38.447+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, dedf70ba0687, 40903, None)
[2025-05-12T18:04:38.448+0000] {subprocess.py:93} INFO - 25/05/12 18:04:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, dedf70ba0687, 40903, None)
[2025-05-12T18:04:39.382+0000] {subprocess.py:93} INFO - 25/05/12 18:04:39 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-05-12T18:04:39.404+0000] {subprocess.py:93} INFO - 25/05/12 18:04:39 INFO SharedState: Warehouse path is 'file:/opt/spark-apps/spark-warehouse'.
[2025-05-12T18:04:45.251+0000] {subprocess.py:93} INFO - 25/05/12 18:04:45 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
[2025-05-12T18:04:45.409+0000] {subprocess.py:93} INFO - 25/05/12 18:04:45 INFO ResolveWriteToStream: Checkpoint root /tmp/spark-checkpoint/da3e8e3b-49c6-4cfd-ac26-a726975bfeb7 resolved to file:/tmp/spark-checkpoint/da3e8e3b-49c6-4cfd-ac26-a726975bfeb7.
[2025-05-12T18:04:45.411+0000] {subprocess.py:93} INFO - 25/05/12 18:04:45 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-05-12T18:04:45.569+0000] {subprocess.py:93} INFO - 25/05/12 18:04:45 INFO CheckpointFileManager: Writing atomically to file:/tmp/spark-checkpoint/da3e8e3b-49c6-4cfd-ac26-a726975bfeb7/metadata using temp file file:/tmp/spark-checkpoint/da3e8e3b-49c6-4cfd-ac26-a726975bfeb7/.metadata.18beaab8-d01f-4a02-9cf5-ce651e06721a.tmp
[2025-05-12T18:04:45.683+0000] {subprocess.py:93} INFO - 25/05/12 18:04:45 INFO CheckpointFileManager: Renamed temp file file:/tmp/spark-checkpoint/da3e8e3b-49c6-4cfd-ac26-a726975bfeb7/.metadata.18beaab8-d01f-4a02-9cf5-ce651e06721a.tmp to file:/tmp/spark-checkpoint/da3e8e3b-49c6-4cfd-ac26-a726975bfeb7/metadata
[2025-05-12T18:04:45.755+0000] {subprocess.py:93} INFO - 25/05/12 18:04:45 INFO MicroBatchExecution: Starting [id = c7b9f37f-0369-4636-b6a9-f6c520208c62, runId = 47574864-13b8-4cb4-8d6d-60d890e71de5]. Use file:/tmp/spark-checkpoint/da3e8e3b-49c6-4cfd-ac26-a726975bfeb7 to store the query checkpoint.
[2025-05-12T18:04:45.810+0000] {subprocess.py:93} INFO - 25/05/12 18:04:45 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@1313c32c] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@23bde56f]
[2025-05-12T18:04:45.884+0000] {subprocess.py:93} INFO - 25/05/12 18:04:45 WARN MicroBatchExecution: The read limit MaxRows: 100 for KafkaV2[Subscribe[gold-news]] is ignored when Trigger.Once is used.
[2025-05-12T18:04:45.905+0000] {subprocess.py:93} INFO - 25/05/12 18:04:45 INFO OffsetSeqLog: BatchIds found from listing:
[2025-05-12T18:04:45.908+0000] {subprocess.py:93} INFO - 25/05/12 18:04:45 INFO OffsetSeqLog: BatchIds found from listing:
[2025-05-12T18:04:45.909+0000] {subprocess.py:93} INFO - 25/05/12 18:04:45 INFO MicroBatchExecution: Starting new streaming query.
[2025-05-12T18:04:45.913+0000] {subprocess.py:93} INFO - 25/05/12 18:04:45 INFO MicroBatchExecution: Stream started from {}
[2025-05-12T18:04:46.751+0000] {subprocess.py:93} INFO - 25/05/12 18:04:46 INFO AdminClientConfig: AdminClientConfig values:
[2025-05-12T18:04:46.752+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-05-12T18:04:46.753+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-05-12T18:04:46.754+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-05-12T18:04:46.755+0000] {subprocess.py:93} INFO - 	client.id =
[2025-05-12T18:04:46.759+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-05-12T18:04:46.760+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-05-12T18:04:46.761+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-05-12T18:04:46.761+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-05-12T18:04:46.762+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-05-12T18:04:46.762+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-05-12T18:04:46.763+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-05-12T18:04:46.763+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-05-12T18:04:46.764+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-05-12T18:04:46.764+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-05-12T18:04:46.764+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-05-12T18:04:46.765+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-05-12T18:04:46.765+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-05-12T18:04:46.766+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-05-12T18:04:46.766+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-05-12T18:04:46.767+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-05-12T18:04:46.767+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-05-12T18:04:46.768+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-05-12T18:04:46.768+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-05-12T18:04:46.769+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-05-12T18:04:46.769+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-05-12T18:04:46.774+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-05-12T18:04:46.776+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-05-12T18:04:46.777+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-05-12T18:04:46.777+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-05-12T18:04:46.778+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-05-12T18:04:46.778+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-05-12T18:04:46.779+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-05-12T18:04:46.779+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-05-12T18:04:46.780+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-05-12T18:04:46.780+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-05-12T18:04:46.781+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-05-12T18:04:46.781+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-05-12T18:04:46.782+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-05-12T18:04:46.782+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-05-12T18:04:46.782+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-05-12T18:04:46.783+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-05-12T18:04:46.783+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-05-12T18:04:46.784+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-05-12T18:04:46.784+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-05-12T18:04:46.785+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-05-12T18:04:46.785+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-05-12T18:04:46.787+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-05-12T18:04:46.789+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-05-12T18:04:46.790+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-05-12T18:04:46.791+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-05-12T18:04:46.791+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-05-12T18:04:46.792+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-05-12T18:04:46.792+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-05-12T18:04:46.792+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-05-12T18:04:46.793+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-05-12T18:04:46.793+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-05-12T18:04:46.793+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-05-12T18:04:46.794+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-05-12T18:04:46.794+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-05-12T18:04:46.794+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-05-12T18:04:46.795+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-05-12T18:04:46.795+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-05-12T18:04:46.795+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-05-12T18:04:46.796+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-05-12T18:04:46.796+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-05-12T18:04:46.796+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-05-12T18:04:46.797+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-05-12T18:04:46.797+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-05-12T18:04:46.797+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-05-12T18:04:46.798+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:04:47.007+0000] {subprocess.py:93} INFO - 25/05/12 18:04:46 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-05-12T18:04:47.056+0000] {subprocess.py:93} INFO - 25/05/12 18:04:47 INFO AppInfoParser: Kafka version: 3.4.1
[2025-05-12T18:04:47.057+0000] {subprocess.py:93} INFO - 25/05/12 18:04:47 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89
[2025-05-12T18:04:47.058+0000] {subprocess.py:93} INFO - 25/05/12 18:04:47 INFO AppInfoParser: Kafka startTimeMs: 1747073086999
[2025-05-12T18:04:48.289+0000] {subprocess.py:93} INFO - 25/05/12 18:04:48 INFO CheckpointFileManager: Writing atomically to file:/tmp/spark-checkpoint/da3e8e3b-49c6-4cfd-ac26-a726975bfeb7/sources/0/0 using temp file file:/tmp/spark-checkpoint/da3e8e3b-49c6-4cfd-ac26-a726975bfeb7/sources/0/.0.1260cce3-10b6-4888-8b4d-5726b2087ad2.tmp
[2025-05-12T18:04:48.316+0000] {subprocess.py:93} INFO - 25/05/12 18:04:48 INFO CheckpointFileManager: Renamed temp file file:/tmp/spark-checkpoint/da3e8e3b-49c6-4cfd-ac26-a726975bfeb7/sources/0/.0.1260cce3-10b6-4888-8b4d-5726b2087ad2.tmp to file:/tmp/spark-checkpoint/da3e8e3b-49c6-4cfd-ac26-a726975bfeb7/sources/0/0
[2025-05-12T18:04:48.317+0000] {subprocess.py:93} INFO - 25/05/12 18:04:48 INFO KafkaMicroBatchStream: Initial offsets: {"gold-news":{"0":0}}
[2025-05-12T18:04:48.368+0000] {subprocess.py:93} INFO - 25/05/12 18:04:48 INFO CheckpointFileManager: Writing atomically to file:/tmp/spark-checkpoint/da3e8e3b-49c6-4cfd-ac26-a726975bfeb7/offsets/0 using temp file file:/tmp/spark-checkpoint/da3e8e3b-49c6-4cfd-ac26-a726975bfeb7/offsets/.0.9f2b0293-6d2a-4e96-9854-8c99171c373b.tmp
[2025-05-12T18:04:48.439+0000] {subprocess.py:93} INFO - 25/05/12 18:04:48 INFO CheckpointFileManager: Renamed temp file file:/tmp/spark-checkpoint/da3e8e3b-49c6-4cfd-ac26-a726975bfeb7/offsets/.0.9f2b0293-6d2a-4e96-9854-8c99171c373b.tmp to file:/tmp/spark-checkpoint/da3e8e3b-49c6-4cfd-ac26-a726975bfeb7/offsets/0
[2025-05-12T18:04:48.440+0000] {subprocess.py:93} INFO - 25/05/12 18:04:48 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1747073088347,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-05-12T18:04:49.541+0000] {subprocess.py:93} INFO - 25/05/12 18:04:49 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-12T18:04:49.664+0000] {subprocess.py:93} INFO - 25/05/12 18:04:49 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-12T18:04:49.800+0000] {subprocess.py:93} INFO - 25/05/12 18:04:49 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-12T18:04:49.805+0000] {subprocess.py:93} INFO - 25/05/12 18:04:49 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-12T18:04:50.504+0000] {subprocess.py:93} INFO - 25/05/12 18:04:50 INFO CodeGenerator: Code generated in 375.078667 ms
[2025-05-12T18:04:50.772+0000] {subprocess.py:93} INFO - 25/05/12 18:04:50 INFO CodeGenerator: Code generated in 14.031485 ms
[2025-05-12T18:04:50.813+0000] {subprocess.py:93} INFO - 25/05/12 18:04:50 INFO SparkContext: Starting job: start at <unknown>:0
[2025-05-12T18:04:50.838+0000] {subprocess.py:93} INFO - 25/05/12 18:04:50 INFO DAGScheduler: Got job 0 (start at <unknown>:0) with 1 output partitions
[2025-05-12T18:04:50.839+0000] {subprocess.py:93} INFO - 25/05/12 18:04:50 INFO DAGScheduler: Final stage: ResultStage 0 (start at <unknown>:0)
[2025-05-12T18:04:50.840+0000] {subprocess.py:93} INFO - 25/05/12 18:04:50 INFO DAGScheduler: Parents of final stage: List()
[2025-05-12T18:04:50.845+0000] {subprocess.py:93} INFO - 25/05/12 18:04:50 INFO DAGScheduler: Missing parents: List()
[2025-05-12T18:04:50.851+0000] {subprocess.py:93} INFO - 25/05/12 18:04:50 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at start at <unknown>:0), which has no missing parents
[2025-05-12T18:04:51.067+0000] {subprocess.py:93} INFO - 25/05/12 18:04:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 40.5 KiB, free 434.4 MiB)
[2025-05-12T18:04:51.122+0000] {subprocess.py:93} INFO - 25/05/12 18:04:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 434.3 MiB)
[2025-05-12T18:04:51.128+0000] {subprocess.py:93} INFO - 25/05/12 18:04:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on dedf70ba0687:40903 (size: 15.6 KiB, free: 434.4 MiB)
[2025-05-12T18:04:51.139+0000] {subprocess.py:93} INFO - 25/05/12 18:04:51 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
[2025-05-12T18:04:51.206+0000] {subprocess.py:93} INFO - 25/05/12 18:04:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-05-12T18:04:51.211+0000] {subprocess.py:93} INFO - 25/05/12 18:04:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-05-12T18:04:51.287+0000] {subprocess.py:93} INFO - 25/05/12 18:04:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (dedf70ba0687, executor driver, partition 0, PROCESS_LOCAL, 13812 bytes)
[2025-05-12T18:04:51.309+0000] {subprocess.py:93} INFO - 25/05/12 18:04:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-05-12T18:04:51.588+0000] {subprocess.py:93} INFO - 25/05/12 18:04:51 INFO CodeGenerator: Code generated in 149.036828 ms
[2025-05-12T18:04:51.629+0000] {subprocess.py:93} INFO - 25/05/12 18:04:51 INFO CodeGenerator: Code generated in 37.553159 ms
[2025-05-12T18:04:51.647+0000] {subprocess.py:93} INFO - 25/05/12 18:04:51 INFO CodeGenerator: Code generated in 11.596973 ms
[2025-05-12T18:04:51.651+0000] {subprocess.py:93} INFO - 25/05/12 18:04:51 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=gold-news-0 fromOffset=0 untilOffset=90, for query queryId=c7b9f37f-0369-4636-b6a9-f6c520208c62 batchId=0 taskId=0 partitionId=0
[2025-05-12T18:04:51.745+0000] {subprocess.py:93} INFO - 25/05/12 18:04:51 INFO CodeGenerator: Code generated in 25.719107 ms
[2025-05-12T18:04:51.811+0000] {subprocess.py:93} INFO - 25/05/12 18:04:51 INFO CodeGenerator: Code generated in 39.728304 ms
[2025-05-12T18:04:51.867+0000] {subprocess.py:93} INFO - 25/05/12 18:04:51 INFO ConsumerConfig: ConsumerConfig values:
[2025-05-12T18:04:51.870+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-05-12T18:04:51.872+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-05-12T18:04:51.872+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-05-12T18:04:51.873+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-05-12T18:04:51.874+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-05-12T18:04:51.874+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-05-12T18:04:51.875+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-05-12T18:04:51.876+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1
[2025-05-12T18:04:51.876+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-05-12T18:04:51.877+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-05-12T18:04:51.878+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-05-12T18:04:51.880+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-05-12T18:04:51.881+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-05-12T18:04:51.882+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-05-12T18:04:51.886+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-05-12T18:04:51.887+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-05-12T18:04:51.888+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor
[2025-05-12T18:04:51.889+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-05-12T18:04:51.890+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-05-12T18:04:51.890+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-05-12T18:04:51.891+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-05-12T18:04:51.892+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-05-12T18:04:51.892+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-05-12T18:04:51.893+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-05-12T18:04:51.893+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-05-12T18:04:51.894+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-05-12T18:04:51.894+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-05-12T18:04:51.895+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-05-12T18:04:51.896+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-05-12T18:04:51.896+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-05-12T18:04:51.897+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-05-12T18:04:51.897+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-05-12T18:04:51.898+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-05-12T18:04:51.899+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-05-12T18:04:51.901+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-05-12T18:04:51.902+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-05-12T18:04:51.902+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-05-12T18:04:51.903+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-05-12T18:04:51.904+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-05-12T18:04:51.904+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-05-12T18:04:51.905+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-05-12T18:04:51.905+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-05-12T18:04:51.906+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-05-12T18:04:51.906+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-05-12T18:04:51.907+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-05-12T18:04:51.907+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-05-12T18:04:51.908+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-05-12T18:04:51.908+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-05-12T18:04:51.909+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-05-12T18:04:51.925+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-05-12T18:04:51.927+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-05-12T18:04:51.927+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-05-12T18:04:51.928+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-05-12T18:04:51.949+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-05-12T18:04:51.972+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-05-12T18:04:51.995+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-05-12T18:04:51.996+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-05-12T18:04:51.997+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-05-12T18:04:51.997+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-05-12T18:04:51.997+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-05-12T18:04:51.998+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-05-12T18:04:51.998+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-05-12T18:04:51.999+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-05-12T18:04:51.999+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-05-12T18:04:51.999+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-05-12T18:04:52.000+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-05-12T18:04:52.000+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-05-12T18:04:52.001+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-05-12T18:04:52.001+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-05-12T18:04:52.002+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-05-12T18:04:52.002+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-05-12T18:04:52.002+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-05-12T18:04:52.003+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-05-12T18:04:52.003+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-05-12T18:04:52.004+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-05-12T18:04:52.009+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-05-12T18:04:52.010+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-05-12T18:04:52.011+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-05-12T18:04:52.012+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-05-12T18:04:52.012+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-05-12T18:04:52.013+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-05-12T18:04:52.013+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-05-12T18:04:52.014+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-05-12T18:04:52.015+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-05-12T18:04:52.015+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-05-12T18:04:52.016+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-05-12T18:04:52.016+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-05-12T18:04:52.017+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-05-12T18:04:52.017+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-05-12T18:04:52.018+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-05-12T18:04:52.018+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-05-12T18:04:52.019+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-05-12T18:04:52.020+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:04:52.056+0000] {subprocess.py:93} INFO - 25/05/12 18:04:52 INFO AppInfoParser: Kafka version: 3.4.1
[2025-05-12T18:04:52.057+0000] {subprocess.py:93} INFO - 25/05/12 18:04:52 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89
[2025-05-12T18:04:52.058+0000] {subprocess.py:93} INFO - 25/05/12 18:04:52 INFO AppInfoParser: Kafka startTimeMs: 1747073092054
[2025-05-12T18:04:52.059+0000] {subprocess.py:93} INFO - 25/05/12 18:04:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1, groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor] Assigned to partition(s): gold-news-0
[2025-05-12T18:04:52.077+0000] {subprocess.py:93} INFO - 25/05/12 18:04:52 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1, groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor] Seeking to offset 0 for partition gold-news-0
[2025-05-12T18:04:52.095+0000] {subprocess.py:93} INFO - 25/05/12 18:04:52 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1, groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor] Resetting the last seen epoch of partition gold-news-0 to 0 since the associated topicId changed from null to EyFovrTXQQOm3GPuq8IGNA
[2025-05-12T18:04:52.096+0000] {subprocess.py:93} INFO - 25/05/12 18:04:52 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1, groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor] Cluster ID: HTSY0p8VS7eCaEFoyzBH3g
[2025-05-12T18:04:52.357+0000] {subprocess.py:93} INFO - 25/05/12 18:04:52 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1, groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor] Seeking to earliest offset of partition gold-news-0
[2025-05-12T18:04:54.202+0000] {subprocess.py:93} INFO - 25/05/12 18:04:54 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1, groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor] Resetting offset for partition gold-news-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-05-12T18:04:54.203+0000] {subprocess.py:93} INFO - 25/05/12 18:04:54 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1, groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor] Seeking to latest offset of partition gold-news-0
[2025-05-12T18:04:54.207+0000] {subprocess.py:93} INFO - 25/05/12 18:04:54 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1, groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor] Resetting offset for partition gold-news-0 to position FetchPosition{offset=90, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-05-12T18:04:55.723+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO KafkaDataConsumer: From Kafka topicPartition=gold-news-0 groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor read 1 records through 1 polls (polled  out 90 records), taking 2129014363 nanos, during time span of 3651207849 nanos.
[2025-05-12T18:04:55.756+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1957 bytes result sent to driver
[2025-05-12T18:04:55.785+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4504 ms on dedf70ba0687 (executor driver) (1/1)
[2025-05-12T18:04:55.789+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-05-12T18:04:55.797+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO DAGScheduler: ResultStage 0 (start at <unknown>:0) finished in 4.928 s
[2025-05-12T18:04:55.804+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-12T18:04:55.810+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2025-05-12T18:04:55.812+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO DAGScheduler: Job 0 finished: start at <unknown>:0, took 4.995075 s
[2025-05-12T18:04:55.908+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO CodeGenerator: Code generated in 19.317061 ms
[2025-05-12T18:04:55.938+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2025-05-12T18:04:55.940+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO DAGScheduler: Got job 1 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2025-05-12T18:04:55.941+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO DAGScheduler: Final stage: ResultStage 1 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2025-05-12T18:04:55.941+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO DAGScheduler: Parents of final stage: List()
[2025-05-12T18:04:55.942+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO DAGScheduler: Missing parents: List()
[2025-05-12T18:04:55.946+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2025-05-12T18:04:55.952+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 42.3 KiB, free 434.3 MiB)
[2025-05-12T18:04:55.968+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 16.0 KiB, free 434.3 MiB)
[2025-05-12T18:04:55.969+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on dedf70ba0687:40903 (size: 16.0 KiB, free: 434.4 MiB)
[2025-05-12T18:04:55.970+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[2025-05-12T18:04:55.981+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2025-05-12T18:04:55.983+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2025-05-12T18:04:55.983+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (dedf70ba0687, executor driver, partition 0, PROCESS_LOCAL, 13812 bytes)
[2025-05-12T18:04:55.984+0000] {subprocess.py:93} INFO - 25/05/12 18:04:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2025-05-12T18:04:56.027+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO CodeGenerator: Code generated in 18.643464 ms
[2025-05-12T18:04:56.030+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=gold-news-0 fromOffset=0 untilOffset=90, for query queryId=c7b9f37f-0369-4636-b6a9-f6c520208c62 batchId=0 taskId=1 partitionId=0
[2025-05-12T18:04:56.089+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1, groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor] Seeking to offset 0 for partition gold-news-0
[2025-05-12T18:04:56.103+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1, groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor] Seeking to earliest offset of partition gold-news-0
[2025-05-12T18:04:56.114+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO BlockManagerInfo: Removed broadcast_0_piece0 on dedf70ba0687:40903 in memory (size: 15.6 KiB, free: 434.4 MiB)
[2025-05-12T18:04:56.606+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1, groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor] Resetting offset for partition gold-news-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-05-12T18:04:56.607+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1, groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor] Seeking to latest offset of partition gold-news-0
[2025-05-12T18:04:56.609+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1, groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor] Resetting offset for partition gold-news-0 to position FetchPosition{offset=90, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-05-12T18:04:56.655+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO KafkaDataConsumer: From Kafka topicPartition=gold-news-0 groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor read 90 records through 1 polls (polled  out 90 records), taking 521836740 nanos, during time span of 567295194 nanos.
[2025-05-12T18:04:56.659+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 14357 bytes result sent to driver
[2025-05-12T18:04:56.667+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 691 ms on dedf70ba0687 (executor driver) (1/1)
[2025-05-12T18:04:56.668+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-05-12T18:04:56.669+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO DAGScheduler: ResultStage 1 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.721 s
[2025-05-12T18:04:56.670+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-12T18:04:56.671+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2025-05-12T18:04:56.671+0000] {subprocess.py:93} INFO - 25/05/12 18:04:56 INFO DAGScheduler: Job 1 finished: call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.732279 s
[2025-05-12T18:04:56.733+0000] {subprocess.py:93} INFO - Traitement du batch 0 avec 90 descriptions
[2025-05-12T18:05:32.035+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.036+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T18:05:32.038+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.042+0000] {subprocess.py:93} INFO -   "description_number": "1",
[2025-05-12T18:05:32.044+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.045+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's price surge due to easing US-China trade tensions could reduce safe-haven demand for gold, potentially decreasing its price. However, the impact might be limited if investors remain concerned about broader economic uncertainties.",
[2025-05-12T18:05:32.046+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.046+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.047+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.047+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T18:05:32.048+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.048+0000] {subprocess.py:93} INFO -   "description_number": "2",
[2025-05-12T18:05:32.049+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.049+0000] {subprocess.py:93} INFO -   "impact_explanation": "This legal settlement is unlikely to have a direct impact on the gold market.  It's a company-specific event and doesn't reflect broader economic trends that influence gold prices.",
[2025-05-12T18:05:32.050+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.050+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.051+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.051+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T18:05:32.051+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.052+0000] {subprocess.py:93} INFO -   "description_number": "3",
[2025-05-12T18:05:32.057+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T18:05:32.059+0000] {subprocess.py:93} INFO -   "impact_explanation": "The article highlights gold as a safe haven asset during market volatility. This positive sentiment towards gold suggests increased demand and potentially higher prices.",
[2025-05-12T18:05:32.060+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.062+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.063+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.064+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T18:05:32.064+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.064+0000] {subprocess.py:93} INFO -   "description_number": "4",
[2025-05-12T18:05:32.065+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.065+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is irrelevant to the gold market; it discusses SEO strategies for bloggers.",
[2025-05-12T18:05:32.066+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.066+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.067+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.067+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T18:05:32.069+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.071+0000] {subprocess.py:93} INFO -   "description_number": "5",
[2025-05-12T18:05:32.072+0000] {subprocess.py:93} INFO -   "sentiment": "Negative",
[2025-05-12T18:05:32.072+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically strengthens the price of gold, as it's priced in USD. The statement suggests potential future weakness in the dollar, which would be positive for gold.",
[2025-05-12T18:05:32.073+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.074+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.074+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.075+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T18:05:32.075+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.076+0000] {subprocess.py:93} INFO -   "description_number": "6",
[2025-05-12T18:05:32.076+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.077+0000] {subprocess.py:93} INFO -   "impact_explanation": "This news about Trump's ventures might indirectly impact the market through uncertainty and investor sentiment, but it doesn't directly affect gold's value.",
[2025-05-12T18:05:32.077+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.078+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.078+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.079+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T18:05:32.079+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.080+0000] {subprocess.py:93} INFO -   "description_number": "7",
[2025-05-12T18:05:32.080+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.081+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description focuses on Web3 investing and has no direct relevance to the gold market.",
[2025-05-12T18:05:32.081+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.082+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.082+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.083+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T18:05:32.084+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.089+0000] {subprocess.py:93} INFO -   "description_number": "8",
[2025-05-12T18:05:32.090+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.091+0000] {subprocess.py:93} INFO -   "impact_explanation": "Information about a GitHub repository for cybersecurity research is not directly relevant to gold pricing.",
[2025-05-12T18:05:32.091+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.092+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.093+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.094+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T18:05:32.094+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.095+0000] {subprocess.py:93} INFO -   "description_number": "9",
[2025-05-12T18:05:32.096+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.096+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about a hotel's renovation in California is irrelevant to the gold market.",
[2025-05-12T18:05:32.097+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.098+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.100+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.103+0000] {subprocess.py:93} INFO - Analyse pour l'article : What Is An XRP Spot ETF?...
[2025-05-12T18:05:32.104+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.106+0000] {subprocess.py:93} INFO -   "description_number": "10",
[2025-05-12T18:05:32.108+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.110+0000] {subprocess.py:93} INFO -   "impact_explanation": "While the potential launch of an XRP spot ETF could increase the demand for cryptocurrencies, it's unlikely to significantly impact the gold market in the short term.",
[2025-05-12T18:05:32.111+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.117+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.119+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.120+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T18:05:32.122+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.123+0000] {subprocess.py:93} INFO -   "description_number": "11",
[2025-05-12T18:05:32.124+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.125+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's price surge due to easing US-China trade tensions could reduce safe-haven demand for gold, potentially decreasing its price. However, the impact might be limited if investors remain concerned about broader economic uncertainties.",
[2025-05-12T18:05:32.125+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.126+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.127+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.128+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T18:05:32.133+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.135+0000] {subprocess.py:93} INFO -   "description_number": "12",
[2025-05-12T18:05:32.136+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.138+0000] {subprocess.py:93} INFO -   "impact_explanation": "This legal settlement is unlikely to have a direct impact on the gold market.  It's a company-specific event and doesn't reflect broader economic trends that influence gold prices.",
[2025-05-12T18:05:32.140+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.141+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.142+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.143+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T18:05:32.143+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.144+0000] {subprocess.py:93} INFO -   "description_number": "13",
[2025-05-12T18:05:32.147+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T18:05:32.149+0000] {subprocess.py:93} INFO -   "impact_explanation": "The article highlights gold as a safe haven asset during market volatility. This positive sentiment towards gold suggests increased demand and potentially higher prices.",
[2025-05-12T18:05:32.150+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.151+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.151+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.152+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T18:05:32.153+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.153+0000] {subprocess.py:93} INFO -   "description_number": "14",
[2025-05-12T18:05:32.154+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.154+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is irrelevant to the gold market; it discusses SEO strategies for bloggers.",
[2025-05-12T18:05:32.155+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.155+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.156+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.156+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T18:05:32.157+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.157+0000] {subprocess.py:93} INFO -   "description_number": "15",
[2025-05-12T18:05:32.158+0000] {subprocess.py:93} INFO -   "sentiment": "Negative",
[2025-05-12T18:05:32.158+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically strengthens the price of gold, as it's priced in USD. The statement suggests potential future weakness in the dollar, which would be positive for gold.",
[2025-05-12T18:05:32.159+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.160+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.163+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.165+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T18:05:32.166+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.166+0000] {subprocess.py:93} INFO -   "description_number": "16",
[2025-05-12T18:05:32.167+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.167+0000] {subprocess.py:93} INFO -   "impact_explanation": "This news about Trump's ventures might indirectly impact the market through uncertainty and investor sentiment, but it doesn't directly affect gold's value.",
[2025-05-12T18:05:32.168+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.169+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.169+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.170+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T18:05:32.170+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.172+0000] {subprocess.py:93} INFO -   "description_number": "17",
[2025-05-12T18:05:32.173+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.173+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description focuses on Web3 investing and has no direct relevance to the gold market.",
[2025-05-12T18:05:32.174+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.174+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.177+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.178+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T18:05:32.179+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.180+0000] {subprocess.py:93} INFO -   "description_number": "18",
[2025-05-12T18:05:32.180+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.181+0000] {subprocess.py:93} INFO -   "impact_explanation": "Information about a GitHub repository for cybersecurity research is not directly relevant to gold pricing.",
[2025-05-12T18:05:32.181+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.182+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.182+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.183+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T18:05:32.183+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.184+0000] {subprocess.py:93} INFO -   "description_number": "19",
[2025-05-12T18:05:32.184+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.184+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about a hotel's renovation in California is irrelevant to the gold market.",
[2025-05-12T18:05:32.185+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.185+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.185+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.186+0000] {subprocess.py:93} INFO - Analyse pour l'article : What Is An XRP Spot ETF?...
[2025-05-12T18:05:32.186+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.187+0000] {subprocess.py:93} INFO -   "description_number": "20",
[2025-05-12T18:05:32.187+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.188+0000] {subprocess.py:93} INFO -   "impact_explanation": "While the potential launch of an XRP spot ETF could increase the demand for cryptocurrencies, it's unlikely to significantly impact the gold market in the short term.",
[2025-05-12T18:05:32.188+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.188+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.189+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.189+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T18:05:32.190+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.193+0000] {subprocess.py:93} INFO -   "description_number": "21",
[2025-05-12T18:05:32.195+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.195+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's price surge due to easing US-China trade tensions could reduce safe-haven demand for gold, potentially decreasing its price. However, the impact might be limited if investors remain concerned about broader economic uncertainties.",
[2025-05-12T18:05:32.196+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.196+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.197+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.198+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T18:05:32.198+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.199+0000] {subprocess.py:93} INFO -   "description_number": "22",
[2025-05-12T18:05:32.199+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.200+0000] {subprocess.py:93} INFO -   "impact_explanation": "This legal settlement is unlikely to have a direct impact on the gold market.  It's a company-specific event and doesn't reflect broader economic trends that influence gold prices.",
[2025-05-12T18:05:32.200+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.200+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.201+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.201+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T18:05:32.202+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.202+0000] {subprocess.py:93} INFO -   "description_number": "23",
[2025-05-12T18:05:32.203+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T18:05:32.203+0000] {subprocess.py:93} INFO -   "impact_explanation": "The article highlights gold as a safe haven asset during market volatility. This positive sentiment towards gold suggests increased demand and potentially higher prices.",
[2025-05-12T18:05:32.204+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.204+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.205+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.206+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T18:05:32.209+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.210+0000] {subprocess.py:93} INFO -   "description_number": "24",
[2025-05-12T18:05:32.211+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.211+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is irrelevant to the gold market; it discusses SEO strategies for bloggers.",
[2025-05-12T18:05:32.212+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.212+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.213+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.213+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T18:05:32.214+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.214+0000] {subprocess.py:93} INFO -   "description_number": "25",
[2025-05-12T18:05:32.217+0000] {subprocess.py:93} INFO -   "sentiment": "Negative",
[2025-05-12T18:05:32.218+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically strengthens the price of gold, as it's priced in USD. The statement suggests potential future weakness in the dollar, which would be positive for gold.",
[2025-05-12T18:05:32.219+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.219+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.220+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.221+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T18:05:32.222+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.224+0000] {subprocess.py:93} INFO -   "description_number": "26",
[2025-05-12T18:05:32.225+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.226+0000] {subprocess.py:93} INFO -   "impact_explanation": "This news about Trump's ventures might indirectly impact the market through uncertainty and investor sentiment, but it doesn't directly affect gold's value.",
[2025-05-12T18:05:32.226+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.227+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.227+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.228+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T18:05:32.228+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.229+0000] {subprocess.py:93} INFO -   "description_number": "27",
[2025-05-12T18:05:32.229+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.230+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description focuses on Web3 investing and has no direct relevance to the gold market.",
[2025-05-12T18:05:32.230+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.231+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.231+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.232+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T18:05:32.232+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.233+0000] {subprocess.py:93} INFO -   "description_number": "28",
[2025-05-12T18:05:32.233+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.233+0000] {subprocess.py:93} INFO -   "impact_explanation": "Information about a GitHub repository for cybersecurity research is not directly relevant to gold pricing.",
[2025-05-12T18:05:32.234+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.235+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.235+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.236+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T18:05:32.241+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.242+0000] {subprocess.py:93} INFO -   "description_number": "29",
[2025-05-12T18:05:32.243+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.243+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about a hotel's renovation in California is irrelevant to the gold market.",
[2025-05-12T18:05:32.244+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.245+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.246+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.249+0000] {subprocess.py:93} INFO - Analyse pour l'article : What Is An XRP Spot ETF?...
[2025-05-12T18:05:32.250+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.253+0000] {subprocess.py:93} INFO -   "description_number": "30",
[2025-05-12T18:05:32.254+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.256+0000] {subprocess.py:93} INFO -   "impact_explanation": "While the potential launch of an XRP spot ETF could increase the demand for cryptocurrencies, it's unlikely to significantly impact the gold market in the short term.",
[2025-05-12T18:05:32.256+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.257+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.257+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.258+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T18:05:32.259+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.259+0000] {subprocess.py:93} INFO -   "description_number": "31",
[2025-05-12T18:05:32.260+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.260+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's price surge due to easing US-China trade tensions could reduce safe-haven demand for gold, potentially decreasing its price. However, the impact might be limited if investors remain concerned about broader economic uncertainties.",
[2025-05-12T18:05:32.261+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.261+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.262+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.262+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T18:05:32.263+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.263+0000] {subprocess.py:93} INFO -   "description_number": "32",
[2025-05-12T18:05:32.264+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.265+0000] {subprocess.py:93} INFO -   "impact_explanation": "This legal settlement is unlikely to have a direct impact on the gold market.  It's a company-specific event and doesn't reflect broader economic trends that influence gold prices.",
[2025-05-12T18:05:32.265+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.266+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.266+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.271+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T18:05:32.272+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.273+0000] {subprocess.py:93} INFO -   "description_number": "33",
[2025-05-12T18:05:32.273+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T18:05:32.274+0000] {subprocess.py:93} INFO -   "impact_explanation": "The article highlights gold as a safe haven asset during market volatility. This positive sentiment towards gold suggests increased demand and potentially higher prices.",
[2025-05-12T18:05:32.275+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.276+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.277+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.280+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T18:05:32.281+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.285+0000] {subprocess.py:93} INFO -   "description_number": "34",
[2025-05-12T18:05:32.286+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.287+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is irrelevant to the gold market; it discusses SEO strategies for bloggers.",
[2025-05-12T18:05:32.287+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.288+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.288+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.289+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T18:05:32.289+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.290+0000] {subprocess.py:93} INFO -   "description_number": "35",
[2025-05-12T18:05:32.290+0000] {subprocess.py:93} INFO -   "sentiment": "Negative",
[2025-05-12T18:05:32.291+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically strengthens the price of gold, as it's priced in USD. The statement suggests potential future weakness in the dollar, which would be positive for gold.",
[2025-05-12T18:05:32.292+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.292+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.293+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.293+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T18:05:32.294+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.294+0000] {subprocess.py:93} INFO -   "description_number": "36",
[2025-05-12T18:05:32.295+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.296+0000] {subprocess.py:93} INFO -   "impact_explanation": "This news about Trump's ventures might indirectly impact the market through uncertainty and investor sentiment, but it doesn't directly affect gold's value.",
[2025-05-12T18:05:32.297+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.301+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.302+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.303+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T18:05:32.304+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.305+0000] {subprocess.py:93} INFO -   "description_number": "37",
[2025-05-12T18:05:32.306+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.306+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description focuses on Web3 investing and has no direct relevance to the gold market.",
[2025-05-12T18:05:32.307+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.307+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.308+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.308+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T18:05:32.309+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.310+0000] {subprocess.py:93} INFO -   "description_number": "38",
[2025-05-12T18:05:32.310+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.311+0000] {subprocess.py:93} INFO -   "impact_explanation": "Information about a GitHub repository for cybersecurity research is not directly relevant to gold pricing.",
[2025-05-12T18:05:32.311+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.312+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.316+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.320+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T18:05:32.321+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.322+0000] {subprocess.py:93} INFO -   "description_number": "39",
[2025-05-12T18:05:32.323+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.323+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about a hotel's renovation in California is irrelevant to the gold market.",
[2025-05-12T18:05:32.324+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.324+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.324+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.325+0000] {subprocess.py:93} INFO - Analyse pour l'article : What Is An XRP Spot ETF?...
[2025-05-12T18:05:32.325+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.326+0000] {subprocess.py:93} INFO -   "description_number": "40",
[2025-05-12T18:05:32.326+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.327+0000] {subprocess.py:93} INFO -   "impact_explanation": "While the potential launch of an XRP spot ETF could increase the demand for cryptocurrencies, it's unlikely to significantly impact the gold market in the short term.",
[2025-05-12T18:05:32.328+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.330+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.332+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.332+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T18:05:32.333+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.334+0000] {subprocess.py:93} INFO -   "description_number": "41",
[2025-05-12T18:05:32.334+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.335+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's price surge due to easing US-China trade tensions could reduce safe-haven demand for gold, potentially decreasing its price. However, the impact might be limited if investors remain concerned about broader economic uncertainties.",
[2025-05-12T18:05:32.336+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.336+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.337+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.341+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T18:05:32.342+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.352+0000] {subprocess.py:93} INFO -   "description_number": "42",
[2025-05-12T18:05:32.353+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.354+0000] {subprocess.py:93} INFO -   "impact_explanation": "This legal settlement is unlikely to have a direct impact on the gold market.  It's a company-specific event and doesn't reflect broader economic trends that influence gold prices.",
[2025-05-12T18:05:32.354+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.355+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.355+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.355+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T18:05:32.356+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.357+0000] {subprocess.py:93} INFO -   "description_number": "43",
[2025-05-12T18:05:32.357+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T18:05:32.361+0000] {subprocess.py:93} INFO -   "impact_explanation": "The article highlights gold as a safe haven asset during market volatility. This positive sentiment towards gold suggests increased demand and potentially higher prices.",
[2025-05-12T18:05:32.362+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.363+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.363+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.364+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T18:05:32.364+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.365+0000] {subprocess.py:93} INFO -   "description_number": "44",
[2025-05-12T18:05:32.365+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.366+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is irrelevant to the gold market; it discusses SEO strategies for bloggers.",
[2025-05-12T18:05:32.366+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.367+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.367+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.368+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T18:05:32.368+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.369+0000] {subprocess.py:93} INFO -   "description_number": "45",
[2025-05-12T18:05:32.369+0000] {subprocess.py:93} INFO -   "sentiment": "Negative",
[2025-05-12T18:05:32.370+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically strengthens the price of gold, as it's priced in USD. The statement suggests potential future weakness in the dollar, which would be positive for gold.",
[2025-05-12T18:05:32.370+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.371+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.371+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.372+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T18:05:32.373+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.377+0000] {subprocess.py:93} INFO -   "description_number": "46",
[2025-05-12T18:05:32.378+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.379+0000] {subprocess.py:93} INFO -   "impact_explanation": "This news about Trump's ventures might indirectly impact the market through uncertainty and investor sentiment, but it doesn't directly affect gold's value.",
[2025-05-12T18:05:32.380+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.380+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.381+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.381+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T18:05:32.382+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.382+0000] {subprocess.py:93} INFO -   "description_number": "47",
[2025-05-12T18:05:32.383+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.383+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description focuses on Web3 investing and has no direct relevance to the gold market.",
[2025-05-12T18:05:32.384+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.384+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.385+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.385+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T18:05:32.386+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.388+0000] {subprocess.py:93} INFO -   "description_number": "48",
[2025-05-12T18:05:32.392+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.394+0000] {subprocess.py:93} INFO -   "impact_explanation": "Information about a GitHub repository for cybersecurity research is not directly relevant to gold pricing.",
[2025-05-12T18:05:32.394+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.395+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.395+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.396+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T18:05:32.396+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.397+0000] {subprocess.py:93} INFO -   "description_number": "49",
[2025-05-12T18:05:32.397+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.398+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about a hotel's renovation in California is irrelevant to the gold market.",
[2025-05-12T18:05:32.398+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.398+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.399+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.399+0000] {subprocess.py:93} INFO - Analyse pour l'article : What Is An XRP Spot ETF?...
[2025-05-12T18:05:32.400+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.400+0000] {subprocess.py:93} INFO -   "description_number": "50",
[2025-05-12T18:05:32.400+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.401+0000] {subprocess.py:93} INFO -   "impact_explanation": "While the potential launch of an XRP spot ETF could increase the demand for cryptocurrencies, it's unlikely to significantly impact the gold market in the short term.",
[2025-05-12T18:05:32.401+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.402+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.402+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.402+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T18:05:32.403+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.404+0000] {subprocess.py:93} INFO -   "description_number": "51",
[2025-05-12T18:05:32.406+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.408+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's price surge due to easing US-China trade tensions could reduce safe-haven demand for gold, potentially decreasing its price. However, the impact might be limited if investors remain concerned about broader economic uncertainties.",
[2025-05-12T18:05:32.409+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.410+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.410+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.411+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T18:05:32.411+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.412+0000] {subprocess.py:93} INFO -   "description_number": "52",
[2025-05-12T18:05:32.412+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.412+0000] {subprocess.py:93} INFO -   "impact_explanation": "This legal settlement is unlikely to have a direct impact on the gold market.  It's a company-specific event and doesn't reflect broader economic trends that influence gold prices.",
[2025-05-12T18:05:32.413+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.413+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.414+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.414+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T18:05:32.415+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.415+0000] {subprocess.py:93} INFO -   "description_number": "53",
[2025-05-12T18:05:32.416+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T18:05:32.416+0000] {subprocess.py:93} INFO -   "impact_explanation": "The article highlights gold as a safe haven asset during market volatility. This positive sentiment towards gold suggests increased demand and potentially higher prices.",
[2025-05-12T18:05:32.417+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.418+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.419+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.421+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T18:05:32.424+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.424+0000] {subprocess.py:93} INFO -   "description_number": "54",
[2025-05-12T18:05:32.430+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.431+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is irrelevant to the gold market; it discusses SEO strategies for bloggers.",
[2025-05-12T18:05:32.432+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.433+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.433+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.434+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T18:05:32.435+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.439+0000] {subprocess.py:93} INFO -   "description_number": "55",
[2025-05-12T18:05:32.443+0000] {subprocess.py:93} INFO -   "sentiment": "Negative",
[2025-05-12T18:05:32.445+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically strengthens the price of gold, as it's priced in USD. The statement suggests potential future weakness in the dollar, which would be positive for gold.",
[2025-05-12T18:05:32.446+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.448+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.449+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.451+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T18:05:32.455+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.457+0000] {subprocess.py:93} INFO -   "description_number": "56",
[2025-05-12T18:05:32.459+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.460+0000] {subprocess.py:93} INFO -   "impact_explanation": "This news about Trump's ventures might indirectly impact the market through uncertainty and investor sentiment, but it doesn't directly affect gold's value.",
[2025-05-12T18:05:32.461+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.461+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.462+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.463+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T18:05:32.463+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.463+0000] {subprocess.py:93} INFO -   "description_number": "57",
[2025-05-12T18:05:32.464+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.465+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description focuses on Web3 investing and has no direct relevance to the gold market.",
[2025-05-12T18:05:32.466+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.466+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.468+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.468+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T18:05:32.469+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.470+0000] {subprocess.py:93} INFO -   "description_number": "58",
[2025-05-12T18:05:32.471+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.471+0000] {subprocess.py:93} INFO -   "impact_explanation": "Information about a GitHub repository for cybersecurity research is not directly relevant to gold pricing.",
[2025-05-12T18:05:32.472+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.473+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.473+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.473+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T18:05:32.474+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.474+0000] {subprocess.py:93} INFO -   "description_number": "59",
[2025-05-12T18:05:32.474+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.475+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about a hotel's renovation in California is irrelevant to the gold market.",
[2025-05-12T18:05:32.475+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.476+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.476+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.477+0000] {subprocess.py:93} INFO - Analyse pour l'article : What Is An XRP Spot ETF?...
[2025-05-12T18:05:32.478+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.480+0000] {subprocess.py:93} INFO -   "description_number": "60",
[2025-05-12T18:05:32.483+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.485+0000] {subprocess.py:93} INFO -   "impact_explanation": "While the potential launch of an XRP spot ETF could increase the demand for cryptocurrencies, it's unlikely to significantly impact the gold market in the short term.",
[2025-05-12T18:05:32.486+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.487+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.488+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.489+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T18:05:32.489+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.490+0000] {subprocess.py:93} INFO -   "description_number": "61",
[2025-05-12T18:05:32.491+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.492+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's price surge due to easing US-China trade tensions could reduce safe-haven demand for gold, potentially decreasing its price. However, the impact might be limited if investors remain concerned about broader economic uncertainties.",
[2025-05-12T18:05:32.492+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.493+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.493+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.494+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T18:05:32.495+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.495+0000] {subprocess.py:93} INFO -   "description_number": "62",
[2025-05-12T18:05:32.502+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.504+0000] {subprocess.py:93} INFO -   "impact_explanation": "This legal settlement is unlikely to have a direct impact on the gold market.  It's a company-specific event and doesn't reflect broader economic trends that influence gold prices.",
[2025-05-12T18:05:32.505+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.506+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.507+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.508+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T18:05:32.508+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.509+0000] {subprocess.py:93} INFO -   "description_number": "63",
[2025-05-12T18:05:32.509+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T18:05:32.510+0000] {subprocess.py:93} INFO -   "impact_explanation": "The article highlights gold as a safe haven asset during market volatility. This positive sentiment towards gold suggests increased demand and potentially higher prices.",
[2025-05-12T18:05:32.510+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.510+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.511+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.512+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T18:05:32.513+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.514+0000] {subprocess.py:93} INFO -   "description_number": "64",
[2025-05-12T18:05:32.514+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.515+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is irrelevant to the gold market; it discusses SEO strategies for bloggers.",
[2025-05-12T18:05:32.515+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.515+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.516+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.516+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T18:05:32.517+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.517+0000] {subprocess.py:93} INFO -   "description_number": "65",
[2025-05-12T18:05:32.517+0000] {subprocess.py:93} INFO -   "sentiment": "Negative",
[2025-05-12T18:05:32.518+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically strengthens the price of gold, as it's priced in USD. The statement suggests potential future weakness in the dollar, which would be positive for gold.",
[2025-05-12T18:05:32.518+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.519+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.519+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.519+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T18:05:32.520+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.521+0000] {subprocess.py:93} INFO -   "description_number": "66",
[2025-05-12T18:05:32.521+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.522+0000] {subprocess.py:93} INFO -   "impact_explanation": "This news about Trump's ventures might indirectly impact the market through uncertainty and investor sentiment, but it doesn't directly affect gold's value.",
[2025-05-12T18:05:32.522+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.522+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.523+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.523+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T18:05:32.524+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.524+0000] {subprocess.py:93} INFO -   "description_number": "67",
[2025-05-12T18:05:32.524+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.525+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description focuses on Web3 investing and has no direct relevance to the gold market.",
[2025-05-12T18:05:32.525+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.526+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.527+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.528+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T18:05:32.530+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.530+0000] {subprocess.py:93} INFO -   "description_number": "68",
[2025-05-12T18:05:32.531+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.531+0000] {subprocess.py:93} INFO -   "impact_explanation": "Information about a GitHub repository for cybersecurity research is not directly relevant to gold pricing.",
[2025-05-12T18:05:32.531+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.532+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.532+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.533+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T18:05:32.534+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.534+0000] {subprocess.py:93} INFO -   "description_number": "69",
[2025-05-12T18:05:32.535+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.535+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about a hotel's renovation in California is irrelevant to the gold market.",
[2025-05-12T18:05:32.536+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.536+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.537+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.537+0000] {subprocess.py:93} INFO - Analyse pour l'article : What Is An XRP Spot ETF?...
[2025-05-12T18:05:32.537+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.538+0000] {subprocess.py:93} INFO -   "description_number": "70",
[2025-05-12T18:05:32.538+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.539+0000] {subprocess.py:93} INFO -   "impact_explanation": "While the potential launch of an XRP spot ETF could increase the demand for cryptocurrencies, it's unlikely to significantly impact the gold market in the short term.",
[2025-05-12T18:05:32.539+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.539+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.540+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.540+0000] {subprocess.py:93} INFO - Analyse pour l'article : Crypto Analyst Predicts Bitcoin To Hit $200,000 At...
[2025-05-12T18:05:32.541+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.542+0000] {subprocess.py:93} INFO -   "description_number": "71",
[2025-05-12T18:05:32.542+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.543+0000] {subprocess.py:93} INFO -   "impact_explanation": "A significant rise in Bitcoin's price might shift some investor interest away from gold, a traditional safe haven asset.  However, the overall impact depends on other market factors.",
[2025-05-12T18:05:32.544+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.544+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.545+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.545+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T18:05:32.546+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.546+0000] {subprocess.py:93} INFO -   "description_number": "72",
[2025-05-12T18:05:32.547+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.547+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's price surge due to easing US-China trade tensions could reduce safe-haven demand for gold, potentially decreasing its price. However, the impact might be limited if investors remain concerned about broader economic uncertainties.",
[2025-05-12T18:05:32.548+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.548+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.549+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.549+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T18:05:32.550+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.551+0000] {subprocess.py:93} INFO -   "description_number": "73",
[2025-05-12T18:05:32.551+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.552+0000] {subprocess.py:93} INFO -   "impact_explanation": "This legal settlement is unlikely to have a direct impact on the gold market.  It's a company-specific event and doesn't reflect broader economic trends that influence gold prices.",
[2025-05-12T18:05:32.553+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.554+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.554+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.555+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T18:05:32.555+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.556+0000] {subprocess.py:93} INFO -   "description_number": "74",
[2025-05-12T18:05:32.556+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T18:05:32.560+0000] {subprocess.py:93} INFO -   "impact_explanation": "The article highlights gold as a safe haven asset during market volatility. This positive sentiment towards gold suggests increased demand and potentially higher prices.",
[2025-05-12T18:05:32.561+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.562+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.562+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.563+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T18:05:32.564+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.564+0000] {subprocess.py:93} INFO -   "description_number": "75",
[2025-05-12T18:05:32.564+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.565+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is irrelevant to the gold market; it discusses SEO strategies for bloggers.",
[2025-05-12T18:05:32.565+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.565+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.566+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.566+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T18:05:32.566+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.567+0000] {subprocess.py:93} INFO -   "description_number": "76",
[2025-05-12T18:05:32.567+0000] {subprocess.py:93} INFO -   "sentiment": "Negative",
[2025-05-12T18:05:32.568+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically strengthens the price of gold, as it's priced in USD. The statement suggests potential future weakness in the dollar, which would be positive for gold.",
[2025-05-12T18:05:32.568+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.568+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.569+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.569+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T18:05:32.569+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.569+0000] {subprocess.py:93} INFO -   "description_number": "77",
[2025-05-12T18:05:32.570+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.570+0000] {subprocess.py:93} INFO -   "impact_explanation": "This news about Trump's ventures might indirectly impact the market through uncertainty and investor sentiment, but it doesn't directly affect gold's value.",
[2025-05-12T18:05:32.571+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.571+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.573+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.576+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T18:05:32.577+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.578+0000] {subprocess.py:93} INFO -   "description_number": "78",
[2025-05-12T18:05:32.578+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.579+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description focuses on Web3 investing and has no direct relevance to the gold market.",
[2025-05-12T18:05:32.579+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.580+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.580+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.580+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T18:05:32.581+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.581+0000] {subprocess.py:93} INFO -   "description_number": "79",
[2025-05-12T18:05:32.582+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.582+0000] {subprocess.py:93} INFO -   "impact_explanation": "Information about a GitHub repository for cybersecurity research is not directly relevant to gold pricing.",
[2025-05-12T18:05:32.583+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.583+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.584+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.584+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T18:05:32.585+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.585+0000] {subprocess.py:93} INFO -   "description_number": "80",
[2025-05-12T18:05:32.586+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.587+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about a hotel's renovation in California is irrelevant to the gold market.",
[2025-05-12T18:05:32.596+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.597+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.598+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.600+0000] {subprocess.py:93} INFO - Analyse pour l'article : Crypto Analyst Predicts Bitcoin To Hit $200,000 At...
[2025-05-12T18:05:32.600+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.601+0000] {subprocess.py:93} INFO -   "description_number": "81",
[2025-05-12T18:05:32.601+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.602+0000] {subprocess.py:93} INFO -   "impact_explanation": "A significant rise in Bitcoin's price might shift some investor interest away from gold, a traditional safe haven asset.  However, the overall impact depends on other market factors.",
[2025-05-12T18:05:32.605+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.607+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.607+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.608+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T18:05:32.608+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.609+0000] {subprocess.py:93} INFO -   "description_number": "82",
[2025-05-12T18:05:32.609+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.610+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's price surge due to easing US-China trade tensions could reduce safe-haven demand for gold, potentially decreasing its price. However, the impact might be limited if investors remain concerned about broader economic uncertainties.",
[2025-05-12T18:05:32.611+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.611+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.612+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.613+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T18:05:32.613+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.614+0000] {subprocess.py:93} INFO -   "description_number": "83",
[2025-05-12T18:05:32.614+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.615+0000] {subprocess.py:93} INFO -   "impact_explanation": "This legal settlement is unlikely to have a direct impact on the gold market.  It's a company-specific event and doesn't reflect broader economic trends that influence gold prices.",
[2025-05-12T18:05:32.615+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.615+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.616+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.616+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T18:05:32.617+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.618+0000] {subprocess.py:93} INFO -   "description_number": "84",
[2025-05-12T18:05:32.620+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T18:05:32.621+0000] {subprocess.py:93} INFO -   "impact_explanation": "The article highlights gold as a safe haven asset during market volatility. This positive sentiment towards gold suggests increased demand and potentially higher prices.",
[2025-05-12T18:05:32.622+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.623+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.623+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.624+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T18:05:32.624+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.624+0000] {subprocess.py:93} INFO -   "description_number": "85",
[2025-05-12T18:05:32.625+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.625+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is irrelevant to the gold market; it discusses SEO strategies for bloggers.",
[2025-05-12T18:05:32.626+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.626+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.627+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.627+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T18:05:32.628+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.628+0000] {subprocess.py:93} INFO -   "description_number": "86",
[2025-05-12T18:05:32.629+0000] {subprocess.py:93} INFO -   "sentiment": "Negative",
[2025-05-12T18:05:32.629+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically strengthens the price of gold, as it's priced in USD. The statement suggests potential future weakness in the dollar, which would be positive for gold.",
[2025-05-12T18:05:32.629+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T18:05:32.630+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.630+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.630+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T18:05:32.631+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.631+0000] {subprocess.py:93} INFO -   "description_number": "87",
[2025-05-12T18:05:32.632+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.632+0000] {subprocess.py:93} INFO -   "impact_explanation": "This news about Trump's ventures might indirectly impact the market through uncertainty and investor sentiment, but it doesn't directly affect gold's value.",
[2025-05-12T18:05:32.633+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.634+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.636+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.637+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T18:05:32.637+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.638+0000] {subprocess.py:93} INFO -   "description_number": "88",
[2025-05-12T18:05:32.639+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.639+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description focuses on Web3 investing and has no direct relevance to the gold market.",
[2025-05-12T18:05:32.640+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.640+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.641+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.641+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T18:05:32.642+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.642+0000] {subprocess.py:93} INFO -   "description_number": "89",
[2025-05-12T18:05:32.643+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.643+0000] {subprocess.py:93} INFO -   "impact_explanation": "Information about a GitHub repository for cybersecurity research is not directly relevant to gold pricing.",
[2025-05-12T18:05:32.644+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.644+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.644+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:32.645+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T18:05:32.645+0000] {subprocess.py:93} INFO - {
[2025-05-12T18:05:32.646+0000] {subprocess.py:93} INFO -   "description_number": "90",
[2025-05-12T18:05:32.646+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T18:05:32.647+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about a hotel's renovation in California is irrelevant to the gold market.",
[2025-05-12T18:05:32.647+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T18:05:32.648+0000] {subprocess.py:93} INFO - }
[2025-05-12T18:05:32.652+0000] {subprocess.py:93} INFO - 25/05/12 18:05:32 INFO BlockManagerInfo: Removed broadcast_1_piece0 on dedf70ba0687:40903 in memory (size: 16.0 KiB, free: 434.4 MiB)
[2025-05-12T18:05:35.086+0000] {subprocess.py:93} INFO - 25/05/12 18:05:35 INFO DefaultMavenCoordinates: DataStax Java driver for Apache Cassandra(R) (com.datastax.oss:java-driver-core-shaded) version 4.13.0
[2025-05-12T18:05:35.402+0000] {subprocess.py:93} INFO - 25/05/12 18:05:35 INFO Native: Unable to load JNR native implementation. This could be normal if JNR is excluded from the classpath
[2025-05-12T18:05:35.403+0000] {subprocess.py:93} INFO - java.lang.NoClassDefFoundError: jnr/posix/POSIXHandler
[2025-05-12T18:05:35.404+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.os.Native$LibcLoader.load(Native.java:42)
[2025-05-12T18:05:35.405+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.os.Native.<clinit>(Native.java:59)
[2025-05-12T18:05:35.405+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.time.Clock.getInstance(Clock.java:41)
[2025-05-12T18:05:35.406+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.time.MonotonicTimestampGenerator.buildClock(MonotonicTimestampGenerator.java:109)
[2025-05-12T18:05:35.406+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.time.MonotonicTimestampGenerator.<init>(MonotonicTimestampGenerator.java:43)
[2025-05-12T18:05:35.407+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.time.AtomicTimestampGenerator.<init>(AtomicTimestampGenerator.java:52)
[2025-05-12T18:05:35.407+0000] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-05-12T18:05:35.408+0000] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)
[2025-05-12T18:05:35.408+0000] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)
[2025-05-12T18:05:35.408+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)
[2025-05-12T18:05:35.409+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.util.Reflection.resolveClass(Reflection.java:329)
[2025-05-12T18:05:35.409+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.util.Reflection.buildFromConfig(Reflection.java:235)
[2025-05-12T18:05:35.410+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.util.Reflection.buildFromConfig(Reflection.java:110)
[2025-05-12T18:05:35.410+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.context.DefaultDriverContext.buildTimestampGenerator(DefaultDriverContext.java:377)
[2025-05-12T18:05:35.411+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.util.concurrent.LazyReference.get(LazyReference.java:55)
[2025-05-12T18:05:35.412+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.context.DefaultDriverContext.getTimestampGenerator(DefaultDriverContext.java:773)
[2025-05-12T18:05:35.414+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.session.DefaultSession$SingleThreaded.init(DefaultSession.java:349)
[2025-05-12T18:05:35.415+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.session.DefaultSession$SingleThreaded.access$1100(DefaultSession.java:300)
[2025-05-12T18:05:35.415+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.session.DefaultSession.lambda$init$0(DefaultSession.java:146)
[2025-05-12T18:05:35.416+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.util.concurrent.PromiseTask.runTask(PromiseTask.java:98)
[2025-05-12T18:05:35.417+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.util.concurrent.PromiseTask.run(PromiseTask.java:106)
[2025-05-12T18:05:35.418+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.channel.DefaultEventLoop.run(DefaultEventLoop.java:54)
[2025-05-12T18:05:35.419+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
[2025-05-12T18:05:35.419+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2025-05-12T18:05:35.420+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2025-05-12T18:05:35.421+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Unknown Source)
[2025-05-12T18:05:35.421+0000] {subprocess.py:93} INFO - Caused by: java.lang.ClassNotFoundException: jnr.posix.POSIXHandler
[2025-05-12T18:05:35.422+0000] {subprocess.py:93} INFO - 	at java.base/java.net.URLClassLoader.findClass(Unknown Source)
[2025-05-12T18:05:35.423+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.ClassLoader.loadClass(Unknown Source)
[2025-05-12T18:05:35.423+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.ClassLoader.loadClass(Unknown Source)
[2025-05-12T18:05:35.424+0000] {subprocess.py:93} INFO - 	... 26 more
[2025-05-12T18:05:35.424+0000] {subprocess.py:93} INFO - 25/05/12 18:05:35 INFO Clock: Could not access native clock (see debug logs for details), falling back to Java system clock
[2025-05-12T18:05:36.657+0000] {subprocess.py:93} INFO - 25/05/12 18:05:36 INFO CassandraConnector: Connected to Cassandra cluster.
[2025-05-12T18:05:36.950+0000] {subprocess.py:93} INFO - 25/05/12 18:05:36 INFO CodeGenerator: Code generated in 25.811774 ms
[2025-05-12T18:05:36.973+0000] {subprocess.py:93} INFO - 25/05/12 18:05:36 INFO AppendDataExec: Start processing data source write support: CassandraBulkWrite(org.apache.spark.sql.SparkSession@62a2b641,com.datastax.spark.connector.cql.CassandraConnector@2615682c,TableDef(gold_news,articles,ArrayBuffer(ColumnDef(id,PartitionKeyColumn,VarCharType)),ArrayBuffer(),Stream(ColumnDef(description,RegularColumn,VarCharType), ColumnDef(ingestion_time,RegularColumn,VarCharType), ColumnDef(published_at,RegularColumn,VarCharType), ColumnDef(recommendation,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(source,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType), ColumnDef(url,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(BytesInBatch(1024),1000,Partition,ONE,false,false,5,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(description,StringType,true),StructField(id,StringType,true),StructField(ingestion_time,StringType,true),StructField(published_at,StringType,true),StructField(recommendation,StringType,true),StructField(sentiment,StringType,true),StructField(source,StringType,true),StructField(title,StringType,true),StructField(url,StringType,true)),org.apache.spark.SparkConf@2d338954). The input RDD has 8 partitions.
[2025-05-12T18:05:37.036+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO SparkContext: Starting job: save at <unknown>:0
[2025-05-12T18:05:37.038+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO DAGScheduler: Got job 2 (save at <unknown>:0) with 8 output partitions
[2025-05-12T18:05:37.039+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO DAGScheduler: Final stage: ResultStage 2 (save at <unknown>:0)
[2025-05-12T18:05:37.040+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO DAGScheduler: Parents of final stage: List()
[2025-05-12T18:05:37.041+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO DAGScheduler: Missing parents: List()
[2025-05-12T18:05:37.043+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at save at <unknown>:0), which has no missing parents
[2025-05-12T18:05:37.063+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 21.8 KiB, free 434.4 MiB)
[2025-05-12T18:05:37.079+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 434.4 MiB)
[2025-05-12T18:05:37.080+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on dedf70ba0687:40903 (size: 10.7 KiB, free: 434.4 MiB)
[2025-05-12T18:05:37.082+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
[2025-05-12T18:05:37.083+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at save at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
[2025-05-12T18:05:37.084+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 8 tasks resource profile 0
[2025-05-12T18:05:37.096+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (dedf70ba0687, executor driver, partition 0, PROCESS_LOCAL, 18258 bytes)
[2025-05-12T18:05:37.097+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3) (dedf70ba0687, executor driver, partition 1, PROCESS_LOCAL, 18265 bytes)
[2025-05-12T18:05:37.098+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 4) (dedf70ba0687, executor driver, partition 2, PROCESS_LOCAL, 18143 bytes)
[2025-05-12T18:05:37.099+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 5) (dedf70ba0687, executor driver, partition 3, PROCESS_LOCAL, 18150 bytes)
[2025-05-12T18:05:37.103+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 6) (dedf70ba0687, executor driver, partition 4, PROCESS_LOCAL, 18012 bytes)
[2025-05-12T18:05:37.109+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 7) (dedf70ba0687, executor driver, partition 5, PROCESS_LOCAL, 18154 bytes)
[2025-05-12T18:05:37.111+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 8) (dedf70ba0687, executor driver, partition 6, PROCESS_LOCAL, 18199 bytes)
[2025-05-12T18:05:37.112+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 9) (dedf70ba0687, executor driver, partition 7, PROCESS_LOCAL, 19243 bytes)
[2025-05-12T18:05:37.127+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
[2025-05-12T18:05:37.128+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
[2025-05-12T18:05:37.129+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO Executor: Running task 2.0 in stage 2.0 (TID 4)
[2025-05-12T18:05:37.130+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO Executor: Running task 4.0 in stage 2.0 (TID 6)
[2025-05-12T18:05:37.132+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO Executor: Running task 5.0 in stage 2.0 (TID 7)
[2025-05-12T18:05:37.132+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO Executor: Running task 6.0 in stage 2.0 (TID 8)
[2025-05-12T18:05:37.137+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO Executor: Running task 7.0 in stage 2.0 (TID 9)
[2025-05-12T18:05:37.157+0000] {subprocess.py:93} INFO - 25/05/12 18:05:37 INFO Executor: Running task 3.0 in stage 2.0 (TID 5)
[2025-05-12T18:05:38.293+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO CodeGenerator: Code generated in 27.641431 ms
[2025-05-12T18:05:38.879+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO PythonRunner: Times: total = 933, boot = 870, init = 62, finish = 1
[2025-05-12T18:05:38.881+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO PythonRunner: Times: total = 955, boot = 883, init = 71, finish = 1
[2025-05-12T18:05:38.881+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO PythonRunner: Times: total = 924, boot = 859, init = 64, finish = 1
[2025-05-12T18:05:38.884+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO PythonRunner: Times: total = 921, boot = 860, init = 60, finish = 1
[2025-05-12T18:05:38.885+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO PythonRunner: Times: total = 949, boot = 891, init = 57, finish = 1
[2025-05-12T18:05:38.886+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO PythonRunner: Times: total = 917, boot = 863, init = 53, finish = 1
[2025-05-12T18:05:38.887+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO PythonRunner: Times: total = 924, boot = 876, init = 47, finish = 1
[2025-05-12T18:05:38.889+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO PythonRunner: Times: total = 961, boot = 899, init = 60, finish = 2
[2025-05-12T18:05:38.896+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 8, attempt 0, stage 2.0)
[2025-05-12T18:05:38.898+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 6, attempt 0, stage 2.0)
[2025-05-12T18:05:38.900+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 7, attempt 0, stage 2.0)
[2025-05-12T18:05:38.901+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 9, attempt 0, stage 2.0)
[2025-05-12T18:05:38.902+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 5, attempt 0, stage 2.0)
[2025-05-12T18:05:38.902+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 2, attempt 0, stage 2.0)
[2025-05-12T18:05:38.903+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 4, attempt 0, stage 2.0)
[2025-05-12T18:05:38.903+0000] {subprocess.py:93} INFO - 25/05/12 18:05:38 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 3, attempt 0, stage 2.0)
[2025-05-12T18:05:39.108+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DataWritingSparkTask: Committed partition 0 (task 2, attempt 0, stage 2.0)
[2025-05-12T18:05:39.133+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DataWritingSparkTask: Committed partition 1 (task 3, attempt 0, stage 2.0)
[2025-05-12T18:05:39.139+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DataWritingSparkTask: Committed partition 6 (task 8, attempt 0, stage 2.0)
[2025-05-12T18:05:39.141+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DataWritingSparkTask: Committed partition 4 (task 6, attempt 0, stage 2.0)
[2025-05-12T18:05:39.142+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DataWritingSparkTask: Committed partition 5 (task 7, attempt 0, stage 2.0)
[2025-05-12T18:05:39.142+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DataWritingSparkTask: Committed partition 7 (task 9, attempt 0, stage 2.0)
[2025-05-12T18:05:39.143+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DataWritingSparkTask: Committed partition 3 (task 5, attempt 0, stage 2.0)
[2025-05-12T18:05:39.144+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DataWritingSparkTask: Committed partition 2 (task 4, attempt 0, stage 2.0)
[2025-05-12T18:05:39.144+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Finished task 5.0 in stage 2.0 (TID 7). 1896 bytes result sent to driver
[2025-05-12T18:05:39.145+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 1896 bytes result sent to driver
[2025-05-12T18:05:39.145+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Finished task 7.0 in stage 2.0 (TID 9). 1896 bytes result sent to driver
[2025-05-12T18:05:39.146+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Finished task 3.0 in stage 2.0 (TID 5). 1896 bytes result sent to driver
[2025-05-12T18:05:39.146+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1939 bytes result sent to driver
[2025-05-12T18:05:39.147+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Finished task 2.0 in stage 2.0 (TID 4). 1896 bytes result sent to driver
[2025-05-12T18:05:39.147+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Finished task 6.0 in stage 2.0 (TID 8). 1896 bytes result sent to driver
[2025-05-12T18:05:39.148+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Finished task 4.0 in stage 2.0 (TID 6). 1896 bytes result sent to driver
[2025-05-12T18:05:39.148+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 7) in 2045 ms on dedf70ba0687 (executor driver) (1/8)
[2025-05-12T18:05:39.149+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 5) in 2053 ms on dedf70ba0687 (executor driver) (2/8)
[2025-05-12T18:05:39.155+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 48959
[2025-05-12T18:05:39.157+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 4) in 2058 ms on dedf70ba0687 (executor driver) (3/8)
[2025-05-12T18:05:39.158+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 9) in 2048 ms on dedf70ba0687 (executor driver) (4/8)
[2025-05-12T18:05:39.159+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 2065 ms on dedf70ba0687 (executor driver) (5/8)
[2025-05-12T18:05:39.159+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 2071 ms on dedf70ba0687 (executor driver) (6/8)
[2025-05-12T18:05:39.160+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 6) in 2058 ms on dedf70ba0687 (executor driver) (7/8)
[2025-05-12T18:05:39.160+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 8) in 2053 ms on dedf70ba0687 (executor driver) (8/8)
[2025-05-12T18:05:39.161+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-05-12T18:05:39.174+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DAGScheduler: ResultStage 2 (save at <unknown>:0) finished in 2.125 s
[2025-05-12T18:05:39.175+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-12T18:05:39.176+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-05-12T18:05:39.176+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DAGScheduler: Job 2 finished: save at <unknown>:0, took 2.139004 s
[2025-05-12T18:05:39.178+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@62a2b641,com.datastax.spark.connector.cql.CassandraConnector@2615682c,TableDef(gold_news,articles,ArrayBuffer(ColumnDef(id,PartitionKeyColumn,VarCharType)),ArrayBuffer(),Stream(ColumnDef(description,RegularColumn,VarCharType), ColumnDef(ingestion_time,RegularColumn,VarCharType), ColumnDef(published_at,RegularColumn,VarCharType), ColumnDef(recommendation,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(source,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType), ColumnDef(url,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(BytesInBatch(1024),1000,Partition,ONE,false,false,5,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(description,StringType,true),StructField(id,StringType,true),StructField(ingestion_time,StringType,true),StructField(published_at,StringType,true),StructField(recommendation,StringType,true),StructField(sentiment,StringType,true),StructField(source,StringType,true),StructField(title,StringType,true),StructField(url,StringType,true)),org.apache.spark.SparkConf@2d338954) is committing.
[2025-05-12T18:05:39.179+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@62a2b641,com.datastax.spark.connector.cql.CassandraConnector@2615682c,TableDef(gold_news,articles,ArrayBuffer(ColumnDef(id,PartitionKeyColumn,VarCharType)),ArrayBuffer(),Stream(ColumnDef(description,RegularColumn,VarCharType), ColumnDef(ingestion_time,RegularColumn,VarCharType), ColumnDef(published_at,RegularColumn,VarCharType), ColumnDef(recommendation,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(source,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType), ColumnDef(url,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(BytesInBatch(1024),1000,Partition,ONE,false,false,5,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(description,StringType,true),StructField(id,StringType,true),StructField(ingestion_time,StringType,true),StructField(published_at,StringType,true),StructField(recommendation,StringType,true),StructField(sentiment,StringType,true),StructField(source,StringType,true),StructField(title,StringType,true),StructField(url,StringType,true)),org.apache.spark.SparkConf@2d338954) committed.
[2025-05-12T18:05:39.797+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO CodeGenerator: Code generated in 36.235694 ms
[2025-05-12T18:05:39.841+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DAGScheduler: Registering RDD 16 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) as input to shuffle 0
[2025-05-12T18:05:39.848+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DAGScheduler: Got map stage job 3 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 8 output partitions
[2025-05-12T18:05:39.849+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2025-05-12T18:05:39.850+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DAGScheduler: Parents of final stage: List()
[2025-05-12T18:05:39.851+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DAGScheduler: Missing parents: List()
[2025-05-12T18:05:39.855+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2025-05-12T18:05:39.879+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 25.9 KiB, free 434.3 MiB)
[2025-05-12T18:05:39.893+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.6 KiB, free 434.3 MiB)
[2025-05-12T18:05:39.894+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on dedf70ba0687:40903 (size: 11.6 KiB, free: 434.4 MiB)
[2025-05-12T18:05:39.896+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
[2025-05-12T18:05:39.903+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
[2025-05-12T18:05:39.904+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSchedulerImpl: Adding task set 3.0 with 8 tasks resource profile 0
[2025-05-12T18:05:39.908+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 10) (dedf70ba0687, executor driver, partition 0, PROCESS_LOCAL, 18247 bytes)
[2025-05-12T18:05:39.909+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 11) (dedf70ba0687, executor driver, partition 1, PROCESS_LOCAL, 18254 bytes)
[2025-05-12T18:05:39.910+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 12) (dedf70ba0687, executor driver, partition 2, PROCESS_LOCAL, 18132 bytes)
[2025-05-12T18:05:39.912+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 13) (dedf70ba0687, executor driver, partition 3, PROCESS_LOCAL, 18139 bytes)
[2025-05-12T18:05:39.919+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 14) (dedf70ba0687, executor driver, partition 4, PROCESS_LOCAL, 18001 bytes)
[2025-05-12T18:05:39.920+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 15) (dedf70ba0687, executor driver, partition 5, PROCESS_LOCAL, 18143 bytes)
[2025-05-12T18:05:39.922+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 16) (dedf70ba0687, executor driver, partition 6, PROCESS_LOCAL, 18188 bytes)
[2025-05-12T18:05:39.927+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 17) (dedf70ba0687, executor driver, partition 7, PROCESS_LOCAL, 19232 bytes)
[2025-05-12T18:05:39.930+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Running task 1.0 in stage 3.0 (TID 11)
[2025-05-12T18:05:39.936+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Running task 0.0 in stage 3.0 (TID 10)
[2025-05-12T18:05:39.940+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Running task 2.0 in stage 3.0 (TID 12)
[2025-05-12T18:05:39.941+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Running task 3.0 in stage 3.0 (TID 13)
[2025-05-12T18:05:39.951+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Running task 6.0 in stage 3.0 (TID 16)
[2025-05-12T18:05:39.952+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Running task 5.0 in stage 3.0 (TID 15)
[2025-05-12T18:05:39.955+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Running task 4.0 in stage 3.0 (TID 14)
[2025-05-12T18:05:39.968+0000] {subprocess.py:93} INFO - 25/05/12 18:05:39 INFO Executor: Running task 7.0 in stage 3.0 (TID 17)
[2025-05-12T18:05:42.821+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO BlockManagerInfo: Removed broadcast_2_piece0 on dedf70ba0687:40903 in memory (size: 10.7 KiB, free: 434.4 MiB)
[2025-05-12T18:05:42.835+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO CodeGenerator: Code generated in 108.139215 ms
[2025-05-12T18:05:42.867+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO PythonRunner: Times: total = 2794, boot = -1637, init = 4431, finish = 0
[2025-05-12T18:05:42.868+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO PythonRunner: Times: total = 2788, boot = -1637, init = 4425, finish = 0
[2025-05-12T18:05:42.872+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO PythonRunner: Times: total = 2786, boot = -1666, init = 4452, finish = 0
[2025-05-12T18:05:42.873+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO PythonRunner: Times: total = 2775, boot = -1627, init = 4402, finish = 0
[2025-05-12T18:05:42.874+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO PythonRunner: Times: total = 2792, boot = -1649, init = 4440, finish = 1
[2025-05-12T18:05:42.875+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO PythonRunner: Times: total = 2778, boot = -1639, init = 4417, finish = 0
[2025-05-12T18:05:42.875+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO PythonRunner: Times: total = 2776, boot = -1652, init = 4428, finish = 0
[2025-05-12T18:05:42.876+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO PythonRunner: Times: total = 2786, boot = -1667, init = 4453, finish = 0
[2025-05-12T18:05:42.970+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO Executor: Finished task 2.0 in stage 3.0 (TID 12). 2362 bytes result sent to driver
[2025-05-12T18:05:42.971+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO Executor: Finished task 3.0 in stage 3.0 (TID 13). 2319 bytes result sent to driver
[2025-05-12T18:05:42.972+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO Executor: Finished task 4.0 in stage 3.0 (TID 14). 2362 bytes result sent to driver
[2025-05-12T18:05:42.973+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO Executor: Finished task 5.0 in stage 3.0 (TID 15). 2362 bytes result sent to driver
[2025-05-12T18:05:42.973+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO Executor: Finished task 1.0 in stage 3.0 (TID 11). 2362 bytes result sent to driver
[2025-05-12T18:05:42.974+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO Executor: Finished task 7.0 in stage 3.0 (TID 17). 2362 bytes result sent to driver
[2025-05-12T18:05:42.984+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 13) in 3068 ms on dedf70ba0687 (executor driver) (1/8)
[2025-05-12T18:05:42.986+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO Executor: Finished task 6.0 in stage 3.0 (TID 16). 2362 bytes result sent to driver
[2025-05-12T18:05:42.987+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO Executor: Finished task 0.0 in stage 3.0 (TID 10). 2362 bytes result sent to driver
[2025-05-12T18:05:42.988+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 12) in 3071 ms on dedf70ba0687 (executor driver) (2/8)
[2025-05-12T18:05:42.988+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 15) in 3069 ms on dedf70ba0687 (executor driver) (3/8)
[2025-05-12T18:05:42.995+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 17) in 3062 ms on dedf70ba0687 (executor driver) (4/8)
[2025-05-12T18:05:42.998+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 14) in 3072 ms on dedf70ba0687 (executor driver) (5/8)
[2025-05-12T18:05:42.999+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 11) in 3079 ms on dedf70ba0687 (executor driver) (6/8)
[2025-05-12T18:05:43.001+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 16) in 3076 ms on dedf70ba0687 (executor driver) (7/8)
[2025-05-12T18:05:43.002+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 10) in 3094 ms on dedf70ba0687 (executor driver) (8/8)
[2025-05-12T18:05:43.003+0000] {subprocess.py:93} INFO - 25/05/12 18:05:42 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-05-12T18:05:43.026+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: ShuffleMapStage 3 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 3.159 s
[2025-05-12T18:05:43.028+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: looking for newly runnable stages
[2025-05-12T18:05:43.029+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: running: Set()
[2025-05-12T18:05:43.030+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: waiting: Set()
[2025-05-12T18:05:43.031+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: failed: Set()
[2025-05-12T18:05:43.163+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO CodeGenerator: Code generated in 28.735388 ms
[2025-05-12T18:05:43.228+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2025-05-12T18:05:43.232+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: Got job 4 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2025-05-12T18:05:43.233+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: Final stage: ResultStage 5 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2025-05-12T18:05:43.234+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-05-12T18:05:43.238+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: Missing parents: List()
[2025-05-12T18:05:43.239+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[19] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2025-05-12T18:05:43.261+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 18.1 KiB, free 434.3 MiB)
[2025-05-12T18:05:43.279+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.3 MiB)
[2025-05-12T18:05:43.284+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on dedf70ba0687:40903 (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-12T18:05:43.286+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
[2025-05-12T18:05:43.287+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[19] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2025-05-12T18:05:43.288+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-05-12T18:05:43.288+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO BlockManagerInfo: Removed broadcast_3_piece0 on dedf70ba0687:40903 in memory (size: 11.6 KiB, free: 434.4 MiB)
[2025-05-12T18:05:43.301+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 18) (dedf70ba0687, executor driver, partition 0, NODE_LOCAL, 12874 bytes)
[2025-05-12T18:05:43.302+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO Executor: Running task 0.0 in stage 5.0 (TID 18)
[2025-05-12T18:05:43.426+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO ShuffleBlockFetcherIterator: Getting 8 (592.0 B) non-empty blocks including 8 (592.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-12T18:05:43.442+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 85 ms
[2025-05-12T18:05:43.516+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO CodeGenerator: Code generated in 45.008958 ms
[2025-05-12T18:05:43.537+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO Executor: Finished task 0.0 in stage 5.0 (TID 18). 4005 bytes result sent to driver
[2025-05-12T18:05:43.539+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 18) in 245 ms on dedf70ba0687 (executor driver) (1/1)
[2025-05-12T18:05:43.544+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-05-12T18:05:43.547+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: ResultStage 5 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.281 s
[2025-05-12T18:05:43.548+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-12T18:05:43.548+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-05-12T18:05:43.549+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: Job 4 finished: call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.314518 s
[2025-05-12T18:05:43.778+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO CodeGenerator: Code generated in 90.493284 ms
[2025-05-12T18:05:43.838+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: Registering RDD 21 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) as input to shuffle 1
[2025-05-12T18:05:43.840+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: Got map stage job 5 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 8 output partitions
[2025-05-12T18:05:43.842+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2025-05-12T18:05:43.844+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: Parents of final stage: List()
[2025-05-12T18:05:43.849+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: Missing parents: List()
[2025-05-12T18:05:43.851+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[21] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2025-05-12T18:05:43.870+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 38.3 KiB, free 434.3 MiB)
[2025-05-12T18:05:43.881+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 18.4 KiB, free 434.3 MiB)
[2025-05-12T18:05:43.883+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on dedf70ba0687:40903 (size: 18.4 KiB, free: 434.4 MiB)
[2025-05-12T18:05:43.884+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
[2025-05-12T18:05:43.885+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[21] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
[2025-05-12T18:05:43.885+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO TaskSchedulerImpl: Adding task set 6.0 with 8 tasks resource profile 0
[2025-05-12T18:05:43.897+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 19) (dedf70ba0687, executor driver, partition 0, PROCESS_LOCAL, 18247 bytes)
[2025-05-12T18:05:43.899+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 20) (dedf70ba0687, executor driver, partition 1, PROCESS_LOCAL, 18254 bytes)
[2025-05-12T18:05:43.900+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 21) (dedf70ba0687, executor driver, partition 2, PROCESS_LOCAL, 18132 bytes)
[2025-05-12T18:05:43.901+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 22) (dedf70ba0687, executor driver, partition 3, PROCESS_LOCAL, 18139 bytes)
[2025-05-12T18:05:43.904+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 23) (dedf70ba0687, executor driver, partition 4, PROCESS_LOCAL, 18001 bytes)
[2025-05-12T18:05:43.912+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO TaskSetManager: Starting task 5.0 in stage 6.0 (TID 24) (dedf70ba0687, executor driver, partition 5, PROCESS_LOCAL, 18143 bytes)
[2025-05-12T18:05:43.917+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO TaskSetManager: Starting task 6.0 in stage 6.0 (TID 25) (dedf70ba0687, executor driver, partition 6, PROCESS_LOCAL, 18188 bytes)
[2025-05-12T18:05:43.918+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO TaskSetManager: Starting task 7.0 in stage 6.0 (TID 26) (dedf70ba0687, executor driver, partition 7, PROCESS_LOCAL, 19232 bytes)
[2025-05-12T18:05:43.919+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO Executor: Running task 1.0 in stage 6.0 (TID 20)
[2025-05-12T18:05:43.920+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO Executor: Running task 0.0 in stage 6.0 (TID 19)
[2025-05-12T18:05:43.933+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO Executor: Running task 2.0 in stage 6.0 (TID 21)
[2025-05-12T18:05:43.951+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO Executor: Running task 4.0 in stage 6.0 (TID 23)
[2025-05-12T18:05:43.956+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO Executor: Running task 3.0 in stage 6.0 (TID 22)
[2025-05-12T18:05:43.957+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO Executor: Running task 5.0 in stage 6.0 (TID 24)
[2025-05-12T18:05:43.971+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO Executor: Running task 7.0 in stage 6.0 (TID 26)
[2025-05-12T18:05:43.972+0000] {subprocess.py:93} INFO - 25/05/12 18:05:43 INFO Executor: Running task 6.0 in stage 6.0 (TID 25)
[2025-05-12T18:05:44.117+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO BlockManagerInfo: Removed broadcast_4_piece0 on dedf70ba0687:40903 in memory (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-12T18:05:44.217+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO CodeGenerator: Code generated in 199.935277 ms
[2025-05-12T18:05:44.248+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO CodeGenerator: Code generated in 18.832665 ms
[2025-05-12T18:05:44.280+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO CodeGenerator: Code generated in 15.316971 ms
[2025-05-12T18:05:44.348+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO CodeGenerator: Code generated in 44.673125 ms
[2025-05-12T18:05:44.392+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO CodeGenerator: Code generated in 27.483235 ms
[2025-05-12T18:05:44.423+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO PythonRunner: Times: total = 115, boot = -1199, init = 1314, finish = 0
[2025-05-12T18:05:44.435+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO PythonRunner: Times: total = 101, boot = -1147, init = 1248, finish = 0
[2025-05-12T18:05:44.436+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO PythonRunner: Times: total = 117, boot = -1210, init = 1326, finish = 1
[2025-05-12T18:05:44.437+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO PythonRunner: Times: total = 105, boot = -1232, init = 1337, finish = 0
[2025-05-12T18:05:44.445+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO PythonRunner: Times: total = 85, boot = -1206, init = 1291, finish = 0
[2025-05-12T18:05:44.446+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO PythonRunner: Times: total = 105, boot = -1198, init = 1303, finish = 0
[2025-05-12T18:05:44.448+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO PythonRunner: Times: total = 113, boot = -1234, init = 1346, finish = 1
[2025-05-12T18:05:44.453+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO PythonRunner: Times: total = 104, boot = -1233, init = 1337, finish = 0
[2025-05-12T18:05:44.574+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO Executor: Finished task 5.0 in stage 6.0 (TID 24). 2882 bytes result sent to driver
[2025-05-12T18:05:44.583+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO Executor: Finished task 2.0 in stage 6.0 (TID 21). 2882 bytes result sent to driver
[2025-05-12T18:05:44.603+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO Executor: Finished task 3.0 in stage 6.0 (TID 22). 2882 bytes result sent to driver
[2025-05-12T18:05:44.604+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO Executor: Finished task 7.0 in stage 6.0 (TID 26). 2925 bytes result sent to driver
[2025-05-12T18:05:44.605+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO Executor: Finished task 6.0 in stage 6.0 (TID 25). 2882 bytes result sent to driver
[2025-05-12T18:05:44.605+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO TaskSetManager: Finished task 5.0 in stage 6.0 (TID 24) in 698 ms on dedf70ba0687 (executor driver) (1/8)
[2025-05-12T18:05:44.606+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO Executor: Finished task 0.0 in stage 6.0 (TID 19). 2882 bytes result sent to driver
[2025-05-12T18:05:44.606+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO Executor: Finished task 1.0 in stage 6.0 (TID 20). 2882 bytes result sent to driver
[2025-05-12T18:05:44.607+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO Executor: Finished task 4.0 in stage 6.0 (TID 23). 2882 bytes result sent to driver
[2025-05-12T18:05:44.615+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 21) in 717 ms on dedf70ba0687 (executor driver) (2/8)
[2025-05-12T18:05:44.619+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 22) in 722 ms on dedf70ba0687 (executor driver) (3/8)
[2025-05-12T18:05:44.621+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO TaskSetManager: Finished task 6.0 in stage 6.0 (TID 25) in 720 ms on dedf70ba0687 (executor driver) (4/8)
[2025-05-12T18:05:44.621+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO TaskSetManager: Finished task 7.0 in stage 6.0 (TID 26) in 708 ms on dedf70ba0687 (executor driver) (5/8)
[2025-05-12T18:05:44.628+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 19) in 736 ms on dedf70ba0687 (executor driver) (6/8)
[2025-05-12T18:05:44.636+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 20) in 744 ms on dedf70ba0687 (executor driver) (7/8)
[2025-05-12T18:05:44.637+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 23) in 741 ms on dedf70ba0687 (executor driver) (8/8)
[2025-05-12T18:05:44.637+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-05-12T18:05:44.645+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO DAGScheduler: ShuffleMapStage 6 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.791 s
[2025-05-12T18:05:44.647+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO DAGScheduler: looking for newly runnable stages
[2025-05-12T18:05:44.647+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO DAGScheduler: running: Set()
[2025-05-12T18:05:44.648+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO DAGScheduler: waiting: Set()
[2025-05-12T18:05:44.649+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO DAGScheduler: failed: Set()
[2025-05-12T18:05:44.667+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-12T18:05:44.709+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-12T18:05:44.783+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO CodeGenerator: Code generated in 53.975571 ms
[2025-05-12T18:05:44.858+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2025-05-12T18:05:44.860+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO DAGScheduler: Got job 6 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2025-05-12T18:05:44.861+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO DAGScheduler: Final stage: ResultStage 8 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2025-05-12T18:05:44.862+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2025-05-12T18:05:44.863+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO DAGScheduler: Missing parents: List()
[2025-05-12T18:05:44.864+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[24] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2025-05-12T18:05:44.878+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 40.5 KiB, free 434.3 MiB)
[2025-05-12T18:05:44.920+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 19.4 KiB, free 434.3 MiB)
[2025-05-12T18:05:44.934+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on dedf70ba0687:40903 (size: 19.4 KiB, free: 434.4 MiB)
[2025-05-12T18:05:44.943+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
[2025-05-12T18:05:44.945+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[24] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2025-05-12T18:05:44.948+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2025-05-12T18:05:44.953+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 27) (dedf70ba0687, executor driver, partition 0, NODE_LOCAL, 12874 bytes)
[2025-05-12T18:05:44.954+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO Executor: Running task 0.0 in stage 8.0 (TID 27)
[2025-05-12T18:05:44.979+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO ShuffleBlockFetcherIterator: Getting 8 (1152.0 B) non-empty blocks including 8 (1152.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-12T18:05:44.980+0000] {subprocess.py:93} INFO - 25/05/12 18:05:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
[2025-05-12T18:05:45.014+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO CodeGenerator: Code generated in 29.32082 ms
[2025-05-12T18:05:45.090+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO BlockManagerInfo: Removed broadcast_5_piece0 on dedf70ba0687:40903 in memory (size: 18.4 KiB, free: 434.4 MiB)
[2025-05-12T18:05:45.091+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO Executor: Finished task 0.0 in stage 8.0 (TID 27). 5262 bytes result sent to driver
[2025-05-12T18:05:45.093+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 27) in 142 ms on dedf70ba0687 (executor driver) (1/1)
[2025-05-12T18:05:45.094+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-05-12T18:05:45.095+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO DAGScheduler: ResultStage 8 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.223 s
[2025-05-12T18:05:45.096+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-12T18:05:45.099+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2025-05-12T18:05:45.101+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO DAGScheduler: Job 6 finished: call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.238275 s
[2025-05-12T18:05:45.124+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 ERROR MicroBatchExecution: Query [id = c7b9f37f-0369-4636-b6a9-f6c520208c62, runId = 47574864-13b8-4cb4-8d6d-60d890e71de5] terminated with error
[2025-05-12T18:05:45.125+0000] {subprocess.py:93} INFO - py4j.Py4JException: An exception was raised by the Python Proxy. Return Message: Traceback (most recent call last):
[2025-05-12T18:05:45.126+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
[2025-05-12T18:05:45.126+0000] {subprocess.py:93} INFO -     return_value = getattr(self.pool[obj_id], method)(*params)
[2025-05-12T18:05:45.128+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 120, in call
[2025-05-12T18:05:45.129+0000] {subprocess.py:93} INFO -     raise e
[2025-05-12T18:05:45.131+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in call
[2025-05-12T18:05:45.132+0000] {subprocess.py:93} INFO -     self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
[2025-05-12T18:05:45.132+0000] {subprocess.py:93} INFO -   File "/scripts/spark_news.py", line 183, in process_batch
[2025-05-12T18:05:45.133+0000] {subprocess.py:93} INFO -     dominant_recommendation = max(recommendation_counts, key=lambda x: x["count"])["recommendation"]
[2025-05-12T18:05:45.133+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 174, in wrapped
[2025-05-12T18:05:45.134+0000] {subprocess.py:93} INFO -     return f(*args, **kwargs)
[2025-05-12T18:05:45.134+0000] {subprocess.py:93} INFO - TypeError: max() got an unexpected keyword argument 'key'
[2025-05-12T18:05:45.135+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:45.135+0000] {subprocess.py:93} INFO - 	at py4j.Protocol.getReturnValue(Protocol.java:476)
[2025-05-12T18:05:45.136+0000] {subprocess.py:93} INFO - 	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:108)
[2025-05-12T18:05:45.136+0000] {subprocess.py:93} INFO - 	at com.sun.proxy.$Proxy30.call(Unknown Source)
[2025-05-12T18:05:45.137+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)
[2025-05-12T18:05:45.137+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)
[2025-05-12T18:05:45.138+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)
[2025-05-12T18:05:45.138+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)
[2025-05-12T18:05:45.139+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
[2025-05-12T18:05:45.139+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
[2025-05-12T18:05:45.140+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
[2025-05-12T18:05:45.140+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-05-12T18:05:45.141+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
[2025-05-12T18:05:45.141+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)
[2025-05-12T18:05:45.141+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
[2025-05-12T18:05:45.142+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
[2025-05-12T18:05:45.142+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
[2025-05-12T18:05:45.144+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)
[2025-05-12T18:05:45.146+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)
[2025-05-12T18:05:45.147+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-12T18:05:45.147+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
[2025-05-12T18:05:45.148+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
[2025-05-12T18:05:45.148+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
[2025-05-12T18:05:45.149+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
[2025-05-12T18:05:45.149+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.SingleBatchExecutor.execute(TriggerExecutor.scala:39)
[2025-05-12T18:05:45.150+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
[2025-05-12T18:05:45.150+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
[2025-05-12T18:05:45.151+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-12T18:05:45.151+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-05-12T18:05:45.151+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
[2025-05-12T18:05:45.152+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
[2025-05-12T18:05:45.152+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-12T18:05:45.153+0000] {subprocess.py:93} INFO - 	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
[2025-05-12T18:05:45.153+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
[2025-05-12T18:05:45.153+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO AppInfoParser: App info kafka.admin.client for adminclient-1 unregistered
[2025-05-12T18:05:45.154+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO Metrics: Metrics scheduler closed
[2025-05-12T18:05:45.154+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-05-12T18:05:45.155+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO Metrics: Metrics reporters closed
[2025-05-12T18:05:45.155+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO MicroBatchExecution: Async log purge executor pool for query [id = c7b9f37f-0369-4636-b6a9-f6c520208c62, runId = 47574864-13b8-4cb4-8d6d-60d890e71de5] has been shutdown
[2025-05-12T18:05:45.223+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-05-12T18:05:45.224+0000] {subprocess.py:93} INFO -   File "/scripts/spark_news.py", line 229, in <module>
[2025-05-12T18:05:45.226+0000] {subprocess.py:93} INFO -     analysis_query.awaitTermination()
[2025-05-12T18:05:45.227+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/streaming/query.py", line 221, in awaitTermination
[2025-05-12T18:05:45.228+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
[2025-05-12T18:05:45.228+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 185, in deco
[2025-05-12T18:05:45.240+0000] {subprocess.py:93} INFO - pyspark.errors.exceptions.captured.StreamingQueryException: [STREAM_FAILED] Query [id = c7b9f37f-0369-4636-b6a9-f6c520208c62, runId = 47574864-13b8-4cb4-8d6d-60d890e71de5] terminated with exception: An exception was raised by the Python Proxy. Return Message: Traceback (most recent call last):
[2025-05-12T18:05:45.241+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
[2025-05-12T18:05:45.242+0000] {subprocess.py:93} INFO -     return_value = getattr(self.pool[obj_id], method)(*params)
[2025-05-12T18:05:45.242+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 120, in call
[2025-05-12T18:05:45.243+0000] {subprocess.py:93} INFO -     raise e
[2025-05-12T18:05:45.243+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in call
[2025-05-12T18:05:45.244+0000] {subprocess.py:93} INFO -     self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
[2025-05-12T18:05:45.244+0000] {subprocess.py:93} INFO -   File "/scripts/spark_news.py", line 183, in process_batch
[2025-05-12T18:05:45.245+0000] {subprocess.py:93} INFO -     dominant_recommendation = max(recommendation_counts, key=lambda x: x["count"])["recommendation"]
[2025-05-12T18:05:45.245+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 174, in wrapped
[2025-05-12T18:05:45.246+0000] {subprocess.py:93} INFO -     return f(*args, **kwargs)
[2025-05-12T18:05:45.246+0000] {subprocess.py:93} INFO - TypeError: max() got an unexpected keyword argument 'key'
[2025-05-12T18:05:45.247+0000] {subprocess.py:93} INFO - 
[2025-05-12T18:05:45.337+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1, groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-05-12T18:05:45.338+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1, groupId=spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-05-12T18:05:45.338+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO Metrics: Metrics scheduler closed
[2025-05-12T18:05:45.339+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-05-12T18:05:45.339+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO Metrics: Metrics reporters closed
[2025-05-12T18:05:45.345+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-2514764f-392a-4c42-9af0-c3560362b14c--1462275125-executor-1 unregistered
[2025-05-12T18:05:45.347+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO SparkContext: Invoking stop() from shutdown hook
[2025-05-12T18:05:45.347+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-05-12T18:05:45.377+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO CassandraConnector: Disconnected from Cassandra cluster.
[2025-05-12T18:05:45.378+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
[2025-05-12T18:05:45.386+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO SparkUI: Stopped Spark web UI at http://dedf70ba0687:4040
[2025-05-12T18:05:45.415+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-05-12T18:05:45.443+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO MemoryStore: MemoryStore cleared
[2025-05-12T18:05:45.444+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO BlockManager: BlockManager stopped
[2025-05-12T18:05:45.452+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-05-12T18:05:45.457+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-05-12T18:05:45.469+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO SparkContext: Successfully stopped SparkContext
[2025-05-12T18:05:45.470+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO ShutdownHookManager: Shutdown hook called
[2025-05-12T18:05:45.470+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4/pyspark-fe568371-bd25-4248-9dc8-bfa720d34dfa
[2025-05-12T18:05:45.473+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-cdf504c0-8744-4eb3-a366-08e38f9ea04a
[2025-05-12T18:05:45.475+0000] {subprocess.py:93} INFO - 25/05/12 18:05:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-6686bec5-5931-464b-920a-a5d029a6ada4
[2025-05-12T18:05:45.629+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-05-12T18:05:45.650+0000] {taskinstance.py:1935} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/bash.py", line 210, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-05-12T18:05:45.657+0000] {taskinstance.py:1398} INFO - Marking task as FAILED. dag_id=gold_news_pipeline, task_id=run_consumer, execution_date=20250512T180342, start_date=20250512T180350, end_date=20250512T180545
[2025-05-12T18:05:45.683+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 98 for task run_consumer (Bash command failed. The command returned a non-zero exit code 1.; 457)
[2025-05-12T18:05:45.692+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2025-05-12T18:05:45.728+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
