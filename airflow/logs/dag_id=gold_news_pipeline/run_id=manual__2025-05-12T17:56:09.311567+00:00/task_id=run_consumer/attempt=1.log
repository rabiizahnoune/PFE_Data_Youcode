[2025-05-12T17:56:16.113+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: gold_news_pipeline.run_consumer manual__2025-05-12T17:56:09.311567+00:00 [queued]>
[2025-05-12T17:56:16.127+0000] {taskinstance.py:1157} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: gold_news_pipeline.run_consumer manual__2025-05-12T17:56:09.311567+00:00 [queued]>
[2025-05-12T17:56:16.128+0000] {taskinstance.py:1359} INFO - Starting attempt 1 of 1
[2025-05-12T17:56:16.146+0000] {taskinstance.py:1380} INFO - Executing <Task(BashOperator): run_consumer> on 2025-05-12 17:56:09.311567+00:00
[2025-05-12T17:56:16.155+0000] {standard_task_runner.py:57} INFO - Started process 5972 to run task
[2025-05-12T17:56:16.161+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'gold_news_pipeline', 'run_consumer', 'manual__2025-05-12T17:56:09.311567+00:00', '--job-id', '93', '--raw', '--subdir', 'DAGS_FOLDER/dag_news.py', '--cfg-path', '/tmp/tmp3pxkma4r']
[2025-05-12T17:56:16.166+0000] {standard_task_runner.py:85} INFO - Job 93: Subtask run_consumer
[2025-05-12T17:56:16.228+0000] {task_command.py:415} INFO - Running <TaskInstance: gold_news_pipeline.run_consumer manual__2025-05-12T17:56:09.311567+00:00 [running]> on host 51d6065cf9f5
[2025-05-12T17:56:16.326+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='gold_news_pipeline' AIRFLOW_CTX_TASK_ID='run_consumer' AIRFLOW_CTX_EXECUTION_DATE='2025-05-12T17:56:09.311567+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-12T17:56:09.311567+00:00'
[2025-05-12T17:56:16.328+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2025-05-12T17:56:16.329+0000] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'docker exec gold_price_project-spark-1 spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,com.datastax.spark:spark-cassandra-connector_2.12:3.5.0 /scripts/spark_news.py']
[2025-05-12T17:56:16.342+0000] {subprocess.py:86} INFO - Output:
[2025-05-12T17:56:20.114+0000] {subprocess.py:93} INFO - :: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2025-05-12T17:56:20.346+0000] {subprocess.py:93} INFO - Ivy Default Cache set to: /root/.ivy2/cache
[2025-05-12T17:56:20.358+0000] {subprocess.py:93} INFO - The jars for the packages stored in: /root/.ivy2/jars
[2025-05-12T17:56:20.370+0000] {subprocess.py:93} INFO - org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
[2025-05-12T17:56:20.371+0000] {subprocess.py:93} INFO - com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency
[2025-05-12T17:56:20.372+0000] {subprocess.py:93} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-9a25a85c-6faf-4b89-bc06-9477b51eed51;1.0
[2025-05-12T17:56:20.373+0000] {subprocess.py:93} INFO - 	confs: [default]
[2025-05-12T17:56:20.840+0000] {subprocess.py:93} INFO - 	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in local-m2-cache
[2025-05-12T17:56:21.076+0000] {subprocess.py:93} INFO - 	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central
[2025-05-12T17:56:21.189+0000] {subprocess.py:93} INFO - 	found org.apache.kafka#kafka-clients;3.4.1 in central
[2025-05-12T17:56:21.306+0000] {subprocess.py:93} INFO - 	found org.lz4#lz4-java;1.8.0 in central
[2025-05-12T17:56:21.388+0000] {subprocess.py:93} INFO - 	found org.xerial.snappy#snappy-java;1.1.10.3 in central
[2025-05-12T17:56:21.436+0000] {subprocess.py:93} INFO - 	found org.slf4j#slf4j-api;2.0.7 in central
[2025-05-12T17:56:21.497+0000] {subprocess.py:93} INFO - 	found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
[2025-05-12T17:56:21.549+0000] {subprocess.py:93} INFO - 	found org.apache.hadoop#hadoop-client-api;3.3.4 in central
[2025-05-12T17:56:21.620+0000] {subprocess.py:93} INFO - 	found commons-logging#commons-logging;1.1.3 in central
[2025-05-12T17:56:21.655+0000] {subprocess.py:93} INFO - 	found com.google.code.findbugs#jsr305;3.0.0 in central
[2025-05-12T17:56:21.711+0000] {subprocess.py:93} INFO - 	found org.apache.commons#commons-pool2;2.11.1 in central
[2025-05-12T17:56:21.758+0000] {subprocess.py:93} INFO - 	found com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 in central
[2025-05-12T17:56:21.786+0000] {subprocess.py:93} INFO - 	found com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 in central
[2025-05-12T17:56:21.840+0000] {subprocess.py:93} INFO - 	found org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central
[2025-05-12T17:56:21.877+0000] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-core-shaded;4.13.0 in central
[2025-05-12T17:56:21.910+0000] {subprocess.py:93} INFO - 	found com.datastax.oss#native-protocol;1.5.0 in central
[2025-05-12T17:56:21.939+0000] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central
[2025-05-12T17:56:21.967+0000] {subprocess.py:93} INFO - 	found com.typesafe#config;1.4.1 in central
[2025-05-12T17:56:22.002+0000] {subprocess.py:93} INFO - 	found io.dropwizard.metrics#metrics-core;4.1.18 in central
[2025-05-12T17:56:22.024+0000] {subprocess.py:93} INFO - 	found org.hdrhistogram#HdrHistogram;2.1.12 in central
[2025-05-12T17:56:22.045+0000] {subprocess.py:93} INFO - 	found org.reactivestreams#reactive-streams;1.0.3 in central
[2025-05-12T17:56:22.063+0000] {subprocess.py:93} INFO - 	found com.github.stephenc.jcip#jcip-annotations;1.0-1 in central
[2025-05-12T17:56:22.081+0000] {subprocess.py:93} INFO - 	found com.github.spotbugs#spotbugs-annotations;3.1.12 in central
[2025-05-12T17:56:22.102+0000] {subprocess.py:93} INFO - 	found com.google.code.findbugs#jsr305;3.0.2 in central
[2025-05-12T17:56:22.125+0000] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central
[2025-05-12T17:56:22.152+0000] {subprocess.py:93} INFO - 	found com.datastax.oss#java-driver-query-builder;4.13.0 in central
[2025-05-12T17:56:22.175+0000] {subprocess.py:93} INFO - 	found org.apache.commons#commons-lang3;3.10 in central
[2025-05-12T17:56:22.191+0000] {subprocess.py:93} INFO - 	found com.thoughtworks.paranamer#paranamer;2.8 in central
[2025-05-12T17:56:22.211+0000] {subprocess.py:93} INFO - 	found org.scala-lang#scala-reflect;2.12.11 in central
[2025-05-12T17:56:22.281+0000] {subprocess.py:93} INFO - :: resolution report :: resolve 1876ms :: artifacts dl 37ms
[2025-05-12T17:56:22.284+0000] {subprocess.py:93} INFO - 	:: modules in use:
[2025-05-12T17:56:22.285+0000] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]
[2025-05-12T17:56:22.286+0000] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]
[2025-05-12T17:56:22.287+0000] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]
[2025-05-12T17:56:22.291+0000] {subprocess.py:93} INFO - 	com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]
[2025-05-12T17:56:22.292+0000] {subprocess.py:93} INFO - 	com.datastax.oss#native-protocol;1.5.0 from central in [default]
[2025-05-12T17:56:22.292+0000] {subprocess.py:93} INFO - 	com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.0 from central in [default]
[2025-05-12T17:56:22.293+0000] {subprocess.py:93} INFO - 	com.datastax.spark#spark-cassandra-connector_2.12;3.5.0 from central in [default]
[2025-05-12T17:56:22.293+0000] {subprocess.py:93} INFO - 	com.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]
[2025-05-12T17:56:22.294+0000] {subprocess.py:93} INFO - 	com.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]
[2025-05-12T17:56:22.294+0000] {subprocess.py:93} INFO - 	com.google.code.findbugs#jsr305;3.0.2 from central in [default]
[2025-05-12T17:56:22.295+0000] {subprocess.py:93} INFO - 	com.thoughtworks.paranamer#paranamer;2.8 from central in [default]
[2025-05-12T17:56:22.295+0000] {subprocess.py:93} INFO - 	com.typesafe#config;1.4.1 from central in [default]
[2025-05-12T17:56:22.296+0000] {subprocess.py:93} INFO - 	commons-logging#commons-logging;1.1.3 from central in [default]
[2025-05-12T17:56:22.297+0000] {subprocess.py:93} INFO - 	io.dropwizard.metrics#metrics-core;4.1.18 from central in [default]
[2025-05-12T17:56:22.297+0000] {subprocess.py:93} INFO - 	org.apache.commons#commons-lang3;3.10 from central in [default]
[2025-05-12T17:56:22.298+0000] {subprocess.py:93} INFO - 	org.apache.commons#commons-pool2;2.11.1 from central in [default]
[2025-05-12T17:56:22.298+0000] {subprocess.py:93} INFO - 	org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
[2025-05-12T17:56:22.299+0000] {subprocess.py:93} INFO - 	org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
[2025-05-12T17:56:22.300+0000] {subprocess.py:93} INFO - 	org.apache.kafka#kafka-clients;3.4.1 from central in [default]
[2025-05-12T17:56:22.302+0000] {subprocess.py:93} INFO - 	org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from local-m2-cache in [default]
[2025-05-12T17:56:22.304+0000] {subprocess.py:93} INFO - 	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]
[2025-05-12T17:56:22.304+0000] {subprocess.py:93} INFO - 	org.hdrhistogram#HdrHistogram;2.1.12 from central in [default]
[2025-05-12T17:56:22.305+0000] {subprocess.py:93} INFO - 	org.lz4#lz4-java;1.8.0 from central in [default]
[2025-05-12T17:56:22.306+0000] {subprocess.py:93} INFO - 	org.reactivestreams#reactive-streams;1.0.3 from central in [default]
[2025-05-12T17:56:22.306+0000] {subprocess.py:93} INFO - 	org.scala-lang#scala-reflect;2.12.11 from central in [default]
[2025-05-12T17:56:22.307+0000] {subprocess.py:93} INFO - 	org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]
[2025-05-12T17:56:22.308+0000] {subprocess.py:93} INFO - 	org.slf4j#slf4j-api;2.0.7 from central in [default]
[2025-05-12T17:56:22.308+0000] {subprocess.py:93} INFO - 	org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
[2025-05-12T17:56:22.309+0000] {subprocess.py:93} INFO - 	:: evicted modules:
[2025-05-12T17:56:22.309+0000] {subprocess.py:93} INFO - 	com.google.code.findbugs#jsr305;3.0.0 by [com.google.code.findbugs#jsr305;3.0.2] in [default]
[2025-05-12T17:56:22.310+0000] {subprocess.py:93} INFO - 	org.slf4j#slf4j-api;1.7.26 by [org.slf4j#slf4j-api;2.0.7] in [default]
[2025-05-12T17:56:22.310+0000] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-05-12T17:56:22.310+0000] {subprocess.py:93} INFO - 	|                  |            modules            ||   artifacts   |
[2025-05-12T17:56:22.311+0000] {subprocess.py:93} INFO - 	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2025-05-12T17:56:22.311+0000] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-05-12T17:56:22.312+0000] {subprocess.py:93} INFO - 	|      default     |   30  |   0   |   0   |   2   ||   28  |   0   |
[2025-05-12T17:56:22.312+0000] {subprocess.py:93} INFO - 	---------------------------------------------------------------------
[2025-05-12T17:56:22.313+0000] {subprocess.py:93} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-9a25a85c-6faf-4b89-bc06-9477b51eed51
[2025-05-12T17:56:22.313+0000] {subprocess.py:93} INFO - 	confs: [default]
[2025-05-12T17:56:22.349+0000] {subprocess.py:93} INFO - 	0 artifacts copied, 28 already retrieved (0kB/40ms)
[2025-05-12T17:56:22.705+0000] {subprocess.py:93} INFO - 25/05/12 17:56:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-05-12T17:56:27.323+0000] {subprocess.py:93} INFO - 25/05/12 17:56:27 INFO SparkContext: Running Spark version 3.5.1
[2025-05-12T17:56:27.325+0000] {subprocess.py:93} INFO - 25/05/12 17:56:27 INFO SparkContext: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64
[2025-05-12T17:56:27.325+0000] {subprocess.py:93} INFO - 25/05/12 17:56:27 INFO SparkContext: Java version 11.0.22
[2025-05-12T17:56:27.387+0000] {subprocess.py:93} INFO - 25/05/12 17:56:27 INFO ResourceUtils: ==============================================================
[2025-05-12T17:56:27.392+0000] {subprocess.py:93} INFO - 25/05/12 17:56:27 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-05-12T17:56:27.396+0000] {subprocess.py:93} INFO - 25/05/12 17:56:27 INFO ResourceUtils: ==============================================================
[2025-05-12T17:56:27.404+0000] {subprocess.py:93} INFO - 25/05/12 17:56:27 INFO SparkContext: Submitted application: GoldNewsStreaming
[2025-05-12T17:56:27.466+0000] {subprocess.py:93} INFO - 25/05/12 17:56:27 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-05-12T17:56:27.507+0000] {subprocess.py:93} INFO - 25/05/12 17:56:27 INFO ResourceProfile: Limiting resource is cpu
[2025-05-12T17:56:27.508+0000] {subprocess.py:93} INFO - 25/05/12 17:56:27 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-05-12T17:56:27.679+0000] {subprocess.py:93} INFO - 25/05/12 17:56:27 INFO SecurityManager: Changing view acls to: root
[2025-05-12T17:56:27.680+0000] {subprocess.py:93} INFO - 25/05/12 17:56:27 INFO SecurityManager: Changing modify acls to: root
[2025-05-12T17:56:27.691+0000] {subprocess.py:93} INFO - 25/05/12 17:56:27 INFO SecurityManager: Changing view acls groups to:
[2025-05-12T17:56:27.696+0000] {subprocess.py:93} INFO - 25/05/12 17:56:27 INFO SecurityManager: Changing modify acls groups to:
[2025-05-12T17:56:27.697+0000] {subprocess.py:93} INFO - 25/05/12 17:56:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
[2025-05-12T17:56:28.121+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO Utils: Successfully started service 'sparkDriver' on port 41723.
[2025-05-12T17:56:28.164+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkEnv: Registering MapOutputTracker
[2025-05-12T17:56:28.210+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkEnv: Registering BlockManagerMaster
[2025-05-12T17:56:28.234+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-05-12T17:56:28.236+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-05-12T17:56:28.242+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-05-12T17:56:28.284+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c4ad4c84-5c2c-4013-8445-4be4f72252ee
[2025-05-12T17:56:28.315+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-05-12T17:56:28.349+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-05-12T17:56:28.688+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-05-12T17:56:28.794+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-05-12T17:56:28.871+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at spark://d4e9ca837c07:41723/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:28.881+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar at spark://d4e9ca837c07:41723/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:28.883+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at spark://d4e9ca837c07:41723/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:28.884+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at spark://d4e9ca837c07:41723/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1747072587308
[2025-05-12T17:56:28.885+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://d4e9ca837c07:41723/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1747072587308
[2025-05-12T17:56:28.892+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://d4e9ca837c07:41723/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1747072587308
[2025-05-12T17:56:28.896+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at spark://d4e9ca837c07:41723/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1747072587308
[2025-05-12T17:56:28.898+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://d4e9ca837c07:41723/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1747072587308
[2025-05-12T17:56:28.900+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://d4e9ca837c07:41723/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1747072587308
[2025-05-12T17:56:28.907+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://d4e9ca837c07:41723/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1747072587308
[2025-05-12T17:56:28.910+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://d4e9ca837c07:41723/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1747072587308
[2025-05-12T17:56:28.912+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar at spark://d4e9ca837c07:41723/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:28.913+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar at spark://d4e9ca837c07:41723/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1747072587308
[2025-05-12T17:56:28.915+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar at spark://d4e9ca837c07:41723/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1747072587308
[2025-05-12T17:56:28.925+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar at spark://d4e9ca837c07:41723/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1747072587308
[2025-05-12T17:56:28.926+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at spark://d4e9ca837c07:41723/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1747072587308
[2025-05-12T17:56:28.927+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at spark://d4e9ca837c07:41723/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1747072587308
[2025-05-12T17:56:28.927+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at spark://d4e9ca837c07:41723/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1747072587308
[2025-05-12T17:56:28.928+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at spark://d4e9ca837c07:41723/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:28.929+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at spark://d4e9ca837c07:41723/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1747072587308
[2025-05-12T17:56:28.929+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar at spark://d4e9ca837c07:41723/jars/com.typesafe_config-1.4.1.jar with timestamp 1747072587308
[2025-05-12T17:56:28.930+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at spark://d4e9ca837c07:41723/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1747072587308
[2025-05-12T17:56:28.930+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at spark://d4e9ca837c07:41723/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1747072587308
[2025-05-12T17:56:28.931+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at spark://d4e9ca837c07:41723/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1747072587308
[2025-05-12T17:56:28.931+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at spark://d4e9ca837c07:41723/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1747072587308
[2025-05-12T17:56:28.932+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at spark://d4e9ca837c07:41723/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1747072587308
[2025-05-12T17:56:28.933+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at spark://d4e9ca837c07:41723/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1747072587308
[2025-05-12T17:56:28.934+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar at spark://d4e9ca837c07:41723/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1747072587308
[2025-05-12T17:56:28.936+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:28.937+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO Utils: Copying /root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
[2025-05-12T17:56:28.946+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar at file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:28.948+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO Utils: Copying /root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-05-12T17:56:28.962+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:28.969+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO Utils: Copying /root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
[2025-05-12T17:56:28.978+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1747072587308
[2025-05-12T17:56:28.981+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO Utils: Copying /root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.kafka_kafka-clients-3.4.1.jar
[2025-05-12T17:56:29.001+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1747072587308
[2025-05-12T17:56:29.002+0000] {subprocess.py:93} INFO - 25/05/12 17:56:28 INFO Utils: Copying /root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.commons_commons-pool2-2.11.1.jar
[2025-05-12T17:56:29.009+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1747072587308
[2025-05-12T17:56:29.013+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2025-05-12T17:56:29.100+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1747072587308
[2025-05-12T17:56:29.102+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.lz4_lz4-java-1.8.0.jar
[2025-05-12T17:56:29.113+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1747072587308
[2025-05-12T17:56:29.114+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2025-05-12T17:56:29.128+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1747072587308
[2025-05-12T17:56:29.129+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.slf4j_slf4j-api-2.0.7.jar
[2025-05-12T17:56:29.138+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1747072587308
[2025-05-12T17:56:29.139+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2025-05-12T17:56:29.220+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1747072587308
[2025-05-12T17:56:29.221+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/commons-logging_commons-logging-1.1.3.jar
[2025-05-12T17:56:29.230+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar at file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:29.232+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-05-12T17:56:29.242+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar at file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1747072587308
[2025-05-12T17:56:29.243+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-05-12T17:56:29.258+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar at file:///root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1747072587308
[2025-05-12T17:56:29.259+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-05-12T17:56:29.281+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar at file:///root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1747072587308
[2025-05-12T17:56:29.282+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-05-12T17:56:29.297+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar at file:///root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1747072587308
[2025-05-12T17:56:29.298+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.commons_commons-lang3-3.10.jar
[2025-05-12T17:56:29.327+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at file:///root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1747072587308
[2025-05-12T17:56:29.345+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-05-12T17:56:29.358+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar at file:///root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1747072587308
[2025-05-12T17:56:29.359+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.scala-lang_scala-reflect-2.12.11.jar
[2025-05-12T17:56:29.426+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar at file:///root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:29.443+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_native-protocol-1.5.0.jar
[2025-05-12T17:56:29.457+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar at file:///root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1747072587308
[2025-05-12T17:56:29.473+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-05-12T17:56:29.539+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar at file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar with timestamp 1747072587308
[2025-05-12T17:56:29.543+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/com.typesafe_config-1.4.1.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.typesafe_config-1.4.1.jar
[2025-05-12T17:56:29.580+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar at file:///root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1747072587308
[2025-05-12T17:56:29.583+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-05-12T17:56:29.583+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar at file:///root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1747072587308
[2025-05-12T17:56:29.584+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-05-12T17:56:29.594+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar at file:///root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1747072587308
[2025-05-12T17:56:29.611+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-05-12T17:56:29.738+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar at file:///root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1747072587308
[2025-05-12T17:56:29.739+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-05-12T17:56:29.784+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar at file:///root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1747072587308
[2025-05-12T17:56:29.813+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-05-12T17:56:29.814+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar at file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1747072587308
[2025-05-12T17:56:29.815+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-05-12T17:56:29.829+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO SparkContext: Added file file:///root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar at file:///root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1747072587308
[2025-05-12T17:56:29.844+0000] {subprocess.py:93} INFO - 25/05/12 17:56:29 INFO Utils: Copying /root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-05-12T17:56:30.270+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Starting executor ID driver on host d4e9ca837c07
[2025-05-12T17:56:30.296+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64
[2025-05-12T17:56:30.302+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Java version 11.0.22
[2025-05-12T17:56:30.346+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-05-12T17:56:30.378+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@2fef754 for default.
[2025-05-12T17:56:30.394+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:30.470+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
[2025-05-12T17:56:30.486+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1747072587308
[2025-05-12T17:56:30.488+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/org.apache.commons_commons-lang3-3.10.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.commons_commons-lang3-3.10.jar
[2025-05-12T17:56:30.501+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1747072587308
[2025-05-12T17:56:30.546+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2025-05-12T17:56:30.557+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1747072587308
[2025-05-12T17:56:30.622+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2025-05-12T17:56:30.626+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1747072587308
[2025-05-12T17:56:30.634+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-05-12T17:56:30.652+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1747072587308
[2025-05-12T17:56:30.653+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-05-12T17:56:30.654+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1747072587308
[2025-05-12T17:56:30.656+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-05-12T17:56:30.666+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1747072587308
[2025-05-12T17:56:30.672+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-05-12T17:56:30.682+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/com.typesafe_config-1.4.1.jar with timestamp 1747072587308
[2025-05-12T17:56:30.683+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/com.typesafe_config-1.4.1.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.typesafe_config-1.4.1.jar
[2025-05-12T17:56:30.692+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1747072587308
[2025-05-12T17:56:30.702+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2025-05-12T17:56:30.715+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1747072587308
[2025-05-12T17:56:30.733+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/org.reactivestreams_reactive-streams-1.0.3.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-05-12T17:56:30.744+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:30.747+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
[2025-05-12T17:56:30.756+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1747072587308
[2025-05-12T17:56:30.760+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.slf4j_slf4j-api-2.0.7.jar
[2025-05-12T17:56:30.762+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1747072587308
[2025-05-12T17:56:30.763+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-05-12T17:56:30.764+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1747072587308
[2025-05-12T17:56:30.773+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-05-12T17:56:30.779+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1747072587308
[2025-05-12T17:56:30.787+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.commons_commons-pool2-2.11.1.jar
[2025-05-12T17:56:30.788+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:30.816+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/com.datastax.oss_native-protocol-1.5.0.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_native-protocol-1.5.0.jar
[2025-05-12T17:56:30.846+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1747072587308
[2025-05-12T17:56:30.850+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/commons-logging_commons-logging-1.1.3.jar
[2025-05-12T17:56:30.863+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1747072587308
[2025-05-12T17:56:30.870+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-05-12T17:56:30.876+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1747072587308
[2025-05-12T17:56:30.880+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.2.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-05-12T17:56:30.899+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1747072587308
[2025-05-12T17:56:30.906+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/org.scala-lang_scala-reflect-2.12.11.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.scala-lang_scala-reflect-2.12.11.jar
[2025-05-12T17:56:30.911+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:30.913+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-05-12T17:56:30.915+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1747072587308
[2025-05-12T17:56:30.916+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-05-12T17:56:30.924+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1747072587308
[2025-05-12T17:56:30.928+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-05-12T17:56:30.929+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1747072587308
[2025-05-12T17:56:30.930+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-05-12T17:56:30.939+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:30.941+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-05-12T17:56:30.945+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1747072587308
[2025-05-12T17:56:30.956+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.lz4_lz4-java-1.8.0.jar
[2025-05-12T17:56:30.962+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1747072587308
[2025-05-12T17:56:30.967+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Utils: /root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.kafka_kafka-clients-3.4.1.jar
[2025-05-12T17:56:30.978+0000] {subprocess.py:93} INFO - 25/05/12 17:56:30 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar with timestamp 1747072587308
[2025-05-12T17:56:31.115+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO TransportClientFactory: Successfully created connection to d4e9ca837c07/172.18.0.9:41723 after 105 ms (0 ms spent in bootstraps)
[2025-05-12T17:56:31.130+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp12228158184618521303.tmp
[2025-05-12T17:56:31.180+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp12228158184618521303.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar
[2025-05-12T17:56:31.186+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.scala-lang.modules_scala-collection-compat_2.12-2.11.0.jar to class loader default
[2025-05-12T17:56:31.187+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar with timestamp 1747072587308
[2025-05-12T17:56:31.188+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp12937566035951143063.tmp
[2025-05-12T17:56:31.342+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp12937566035951143063.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-core-shaded-4.13.0.jar
[2025-05-12T17:56:31.381+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-core-shaded-4.13.0.jar to class loader default
[2025-05-12T17:56:31.395+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:31.397+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp9818310676741957170.tmp
[2025-05-12T17:56:31.399+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp9818310676741957170.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
[2025-05-12T17:56:31.420+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to class loader default
[2025-05-12T17:56:31.426+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1747072587308
[2025-05-12T17:56:31.427+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp16734880286054321462.tmp
[2025-05-12T17:56:31.431+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp16734880286054321462.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.lz4_lz4-java-1.8.0.jar
[2025-05-12T17:56:31.446+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.lz4_lz4-java-1.8.0.jar to class loader default
[2025-05-12T17:56:31.448+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/com.typesafe_config-1.4.1.jar with timestamp 1747072587308
[2025-05-12T17:56:31.450+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/com.typesafe_config-1.4.1.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp6599114630688471576.tmp
[2025-05-12T17:56:31.463+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp6599114630688471576.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.typesafe_config-1.4.1.jar
[2025-05-12T17:56:31.466+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.typesafe_config-1.4.1.jar to class loader default
[2025-05-12T17:56:31.471+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1747072587308
[2025-05-12T17:56:31.474+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp7057325563250714792.tmp
[2025-05-12T17:56:31.476+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp7057325563250714792.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/commons-logging_commons-logging-1.1.3.jar
[2025-05-12T17:56:31.479+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/commons-logging_commons-logging-1.1.3.jar to class loader default
[2025-05-12T17:56:31.480+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar with timestamp 1747072587308
[2025-05-12T17:56:31.481+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/com.datastax.oss_java-driver-query-builder-4.13.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp8999875402267681296.tmp
[2025-05-12T17:56:31.487+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp8999875402267681296.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-query-builder-4.13.0.jar
[2025-05-12T17:56:31.494+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-query-builder-4.13.0.jar to class loader default
[2025-05-12T17:56:31.495+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1747072587308
[2025-05-12T17:56:31.496+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp2140763049008397134.tmp
[2025-05-12T17:56:31.588+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp2140763049008397134.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.kafka_kafka-clients-3.4.1.jar
[2025-05-12T17:56:31.628+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.kafka_kafka-clients-3.4.1.jar to class loader default
[2025-05-12T17:56:31.629+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1747072587308
[2025-05-12T17:56:31.630+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp2421777823214976329.tmp
[2025-05-12T17:56:31.633+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp2421777823214976329.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.thoughtworks.paranamer_paranamer-2.8.jar
[2025-05-12T17:56:31.636+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.thoughtworks.paranamer_paranamer-2.8.jar to class loader default
[2025-05-12T17:56:31.641+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1747072587308
[2025-05-12T17:56:31.644+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp14173993095482291208.tmp
[2025-05-12T17:56:31.741+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp14173993095482291208.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.xerial.snappy_snappy-java-1.1.10.3.jar
[2025-05-12T17:56:31.764+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.xerial.snappy_snappy-java-1.1.10.3.jar to class loader default
[2025-05-12T17:56:31.773+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar with timestamp 1747072587308
[2025-05-12T17:56:31.784+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp17416601609646823182.tmp
[2025-05-12T17:56:31.789+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp17416601609646823182.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar
[2025-05-12T17:56:31.795+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.github.stephenc.jcip_jcip-annotations-1.0-1.jar to class loader default
[2025-05-12T17:56:31.801+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:31.802+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp10913374967106480083.tmp
[2025-05-12T17:56:31.824+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp10913374967106480083.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar
[2025-05-12T17:56:31.842+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.spark_spark-cassandra-connector_2.12-3.5.0.jar to class loader default
[2025-05-12T17:56:31.844+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/org.scala-lang_scala-reflect-2.12.11.jar with timestamp 1747072587308
[2025-05-12T17:56:31.845+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/org.scala-lang_scala-reflect-2.12.11.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp1882479513890535551.tmp
[2025-05-12T17:56:31.968+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp1882479513890535551.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.scala-lang_scala-reflect-2.12.11.jar
[2025-05-12T17:56:31.984+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.scala-lang_scala-reflect-2.12.11.jar to class loader default
[2025-05-12T17:56:31.997+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1747072587308
[2025-05-12T17:56:32.005+0000] {subprocess.py:93} INFO - 25/05/12 17:56:31 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp6783942327372796490.tmp
[2025-05-12T17:56:32.396+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp6783942327372796490.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.hadoop_hadoop-client-api-3.3.4.jar
[2025-05-12T17:56:32.406+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.hadoop_hadoop-client-api-3.3.4.jar to class loader default
[2025-05-12T17:56:32.407+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/com.datastax.oss_native-protocol-1.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:32.409+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/com.datastax.oss_native-protocol-1.5.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp14097828443730670681.tmp
[2025-05-12T17:56:32.418+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp14097828443730670681.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_native-protocol-1.5.0.jar
[2025-05-12T17:56:32.421+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_native-protocol-1.5.0.jar to class loader default
[2025-05-12T17:56:32.422+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar with timestamp 1747072587308
[2025-05-12T17:56:32.423+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/org.hdrhistogram_HdrHistogram-2.1.12.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp7046307961929970433.tmp
[2025-05-12T17:56:32.424+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp7046307961929970433.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.hdrhistogram_HdrHistogram-2.1.12.jar
[2025-05-12T17:56:32.434+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.hdrhistogram_HdrHistogram-2.1.12.jar to class loader default
[2025-05-12T17:56:32.436+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/org.reactivestreams_reactive-streams-1.0.3.jar with timestamp 1747072587308
[2025-05-12T17:56:32.437+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/org.reactivestreams_reactive-streams-1.0.3.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp5385205691824370911.tmp
[2025-05-12T17:56:32.438+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp5385205691824370911.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.reactivestreams_reactive-streams-1.0.3.jar
[2025-05-12T17:56:32.443+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.reactivestreams_reactive-streams-1.0.3.jar to class loader default
[2025-05-12T17:56:32.451+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/com.google.code.findbugs_jsr305-3.0.2.jar with timestamp 1747072587308
[2025-05-12T17:56:32.454+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/com.google.code.findbugs_jsr305-3.0.2.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp2427044313506717643.tmp
[2025-05-12T17:56:32.455+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp2427044313506717643.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.google.code.findbugs_jsr305-3.0.2.jar
[2025-05-12T17:56:32.456+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.google.code.findbugs_jsr305-3.0.2.jar to class loader default
[2025-05-12T17:56:32.465+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/org.apache.commons_commons-lang3-3.10.jar with timestamp 1747072587308
[2025-05-12T17:56:32.466+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/org.apache.commons_commons-lang3-3.10.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp6921391555507748680.tmp
[2025-05-12T17:56:32.473+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp6921391555507748680.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.commons_commons-lang3-3.10.jar
[2025-05-12T17:56:32.484+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.commons_commons-lang3-3.10.jar to class loader default
[2025-05-12T17:56:32.486+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1747072587308
[2025-05-12T17:56:32.488+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp18014013863704930895.tmp
[2025-05-12T17:56:32.494+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp18014013863704930895.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.commons_commons-pool2-2.11.1.jar
[2025-05-12T17:56:32.501+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.commons_commons-pool2-2.11.1.jar to class loader default
[2025-05-12T17:56:32.502+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:32.503+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp11440650073337358492.tmp
[2025-05-12T17:56:32.514+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp11440650073337358492.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
[2025-05-12T17:56:32.526+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to class loader default
[2025-05-12T17:56:32.527+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1747072587308
[2025-05-12T17:56:32.528+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp3163156086704602199.tmp
[2025-05-12T17:56:32.535+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp3163156086704602199.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.slf4j_slf4j-api-2.0.7.jar
[2025-05-12T17:56:32.547+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.slf4j_slf4j-api-2.0.7.jar to class loader default
[2025-05-12T17:56:32.554+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar with timestamp 1747072587308
[2025-05-12T17:56:32.556+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp3316890545007226442.tmp
[2025-05-12T17:56:32.574+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp3316890545007226442.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar
[2025-05-12T17:56:32.591+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-shaded-guava-25.1-jre-graal-sub-1.jar to class loader default
[2025-05-12T17:56:32.594+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1747072587308
[2025-05-12T17:56:32.597+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp10529891540369327150.tmp
[2025-05-12T17:56:32.927+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp10529891540369327150.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
[2025-05-12T17:56:32.937+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to class loader default
[2025-05-12T17:56:32.938+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar with timestamp 1747072587308
[2025-05-12T17:56:32.941+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp14194818054380058842.tmp
[2025-05-12T17:56:32.943+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp14194818054380058842.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.github.spotbugs_spotbugs-annotations-3.1.12.jar
[2025-05-12T17:56:32.951+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.github.spotbugs_spotbugs-annotations-3.1.12.jar to class loader default
[2025-05-12T17:56:32.952+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar with timestamp 1747072587308
[2025-05-12T17:56:32.953+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/io.dropwizard.metrics_metrics-core-4.1.18.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp16272043936750671967.tmp
[2025-05-12T17:56:32.955+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp16272043936750671967.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/io.dropwizard.metrics_metrics-core-4.1.18.jar
[2025-05-12T17:56:32.960+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/io.dropwizard.metrics_metrics-core-4.1.18.jar to class loader default
[2025-05-12T17:56:32.961+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar with timestamp 1747072587308
[2025-05-12T17:56:32.968+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp9895354498788662675.tmp
[2025-05-12T17:56:32.976+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp9895354498788662675.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar
[2025-05-12T17:56:32.984+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.spark_spark-cassandra-connector-driver_2.12-3.5.0.jar to class loader default
[2025-05-12T17:56:32.985+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Fetching spark://d4e9ca837c07:41723/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar with timestamp 1747072587308
[2025-05-12T17:56:32.986+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: Fetching spark://d4e9ca837c07:41723/jars/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp2323038745644675911.tmp
[2025-05-12T17:56:32.987+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Utils: /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/fetchFileTemp2323038745644675911.tmp has been previously copied to /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar
[2025-05-12T17:56:32.997+0000] {subprocess.py:93} INFO - 25/05/12 17:56:32 INFO Executor: Adding file:/tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/userFiles-8a59688b-c074-4c7f-9db8-ffc449aa72a3/com.datastax.oss_java-driver-mapper-runtime-4.13.0.jar to class loader default
[2025-05-12T17:56:33.018+0000] {subprocess.py:93} INFO - 25/05/12 17:56:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42539.
[2025-05-12T17:56:33.019+0000] {subprocess.py:93} INFO - 25/05/12 17:56:33 INFO NettyBlockTransferService: Server created on d4e9ca837c07:42539
[2025-05-12T17:56:33.022+0000] {subprocess.py:93} INFO - 25/05/12 17:56:33 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-05-12T17:56:33.037+0000] {subprocess.py:93} INFO - 25/05/12 17:56:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, d4e9ca837c07, 42539, None)
[2025-05-12T17:56:33.046+0000] {subprocess.py:93} INFO - 25/05/12 17:56:33 INFO BlockManagerMasterEndpoint: Registering block manager d4e9ca837c07:42539 with 434.4 MiB RAM, BlockManagerId(driver, d4e9ca837c07, 42539, None)
[2025-05-12T17:56:33.052+0000] {subprocess.py:93} INFO - 25/05/12 17:56:33 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, d4e9ca837c07, 42539, None)
[2025-05-12T17:56:33.054+0000] {subprocess.py:93} INFO - 25/05/12 17:56:33 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, d4e9ca837c07, 42539, None)
[2025-05-12T17:56:34.381+0000] {subprocess.py:93} INFO - 25/05/12 17:56:34 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-05-12T17:56:34.410+0000] {subprocess.py:93} INFO - 25/05/12 17:56:34 INFO SharedState: Warehouse path is 'file:/opt/spark-apps/spark-warehouse'.
[2025-05-12T17:56:41.042+0000] {subprocess.py:93} INFO - 25/05/12 17:56:41 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
[2025-05-12T17:56:41.370+0000] {subprocess.py:93} INFO - 25/05/12 17:56:41 INFO ResolveWriteToStream: Checkpoint root /tmp/spark-checkpoint/b183f5ab-639d-4b3a-8a99-2c5ed0648759 resolved to file:/tmp/spark-checkpoint/b183f5ab-639d-4b3a-8a99-2c5ed0648759.
[2025-05-12T17:56:41.371+0000] {subprocess.py:93} INFO - 25/05/12 17:56:41 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[2025-05-12T17:56:41.684+0000] {subprocess.py:93} INFO - 25/05/12 17:56:41 INFO CheckpointFileManager: Writing atomically to file:/tmp/spark-checkpoint/b183f5ab-639d-4b3a-8a99-2c5ed0648759/metadata using temp file file:/tmp/spark-checkpoint/b183f5ab-639d-4b3a-8a99-2c5ed0648759/.metadata.36305112-f87d-42fc-84e2-5e6d7cc43aaa.tmp
[2025-05-12T17:56:42.083+0000] {subprocess.py:93} INFO - 25/05/12 17:56:42 INFO CheckpointFileManager: Renamed temp file file:/tmp/spark-checkpoint/b183f5ab-639d-4b3a-8a99-2c5ed0648759/.metadata.36305112-f87d-42fc-84e2-5e6d7cc43aaa.tmp to file:/tmp/spark-checkpoint/b183f5ab-639d-4b3a-8a99-2c5ed0648759/metadata
[2025-05-12T17:56:42.313+0000] {subprocess.py:93} INFO - 25/05/12 17:56:42 INFO MicroBatchExecution: Starting [id = 5c17ed8c-6e3d-4e32-a5cf-66a76eb428c1, runId = ec79e0d6-348c-4b85-9665-b45e7836a80a]. Use file:/tmp/spark-checkpoint/b183f5ab-639d-4b3a-8a99-2c5ed0648759 to store the query checkpoint.
[2025-05-12T17:56:42.359+0000] {subprocess.py:93} INFO - 25/05/12 17:56:42 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@5c2320f6] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@4a08a608]
[2025-05-12T17:56:42.499+0000] {subprocess.py:93} INFO - 25/05/12 17:56:42 WARN MicroBatchExecution: The read limit MaxRows: 100 for KafkaV2[Subscribe[gold-news]] is ignored when Trigger.Once is used.
[2025-05-12T17:56:42.528+0000] {subprocess.py:93} INFO - 25/05/12 17:56:42 INFO OffsetSeqLog: BatchIds found from listing:
[2025-05-12T17:56:42.540+0000] {subprocess.py:93} INFO - 25/05/12 17:56:42 INFO OffsetSeqLog: BatchIds found from listing:
[2025-05-12T17:56:42.543+0000] {subprocess.py:93} INFO - 25/05/12 17:56:42 INFO MicroBatchExecution: Starting new streaming query.
[2025-05-12T17:56:42.559+0000] {subprocess.py:93} INFO - 25/05/12 17:56:42 INFO MicroBatchExecution: Stream started from {}
[2025-05-12T17:56:43.346+0000] {subprocess.py:93} INFO - 25/05/12 17:56:43 INFO AdminClientConfig: AdminClientConfig values:
[2025-05-12T17:56:43.347+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-05-12T17:56:43.348+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-05-12T17:56:43.349+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-05-12T17:56:43.350+0000] {subprocess.py:93} INFO - 	client.id =
[2025-05-12T17:56:43.351+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 300000
[2025-05-12T17:56:43.353+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-05-12T17:56:43.354+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-05-12T17:56:43.355+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-05-12T17:56:43.356+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-05-12T17:56:43.360+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-05-12T17:56:43.363+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-05-12T17:56:43.364+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-05-12T17:56:43.366+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-05-12T17:56:43.367+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-05-12T17:56:43.370+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-05-12T17:56:43.371+0000] {subprocess.py:93} INFO - 	retries = 2147483647
[2025-05-12T17:56:43.372+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-05-12T17:56:43.373+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-05-12T17:56:43.382+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-05-12T17:56:43.383+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-05-12T17:56:43.384+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-05-12T17:56:43.386+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-05-12T17:56:43.392+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-05-12T17:56:43.392+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-05-12T17:56:43.394+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-05-12T17:56:43.396+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-05-12T17:56:43.400+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-05-12T17:56:43.409+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-05-12T17:56:43.410+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-05-12T17:56:43.411+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-05-12T17:56:43.411+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-05-12T17:56:43.412+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-05-12T17:56:43.412+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-05-12T17:56:43.416+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-05-12T17:56:43.431+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-05-12T17:56:43.432+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-05-12T17:56:43.437+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-05-12T17:56:43.438+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-05-12T17:56:43.438+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-05-12T17:56:43.439+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-05-12T17:56:43.440+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-05-12T17:56:43.440+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-05-12T17:56:43.441+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-05-12T17:56:43.441+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-05-12T17:56:43.442+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-05-12T17:56:43.443+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-05-12T17:56:43.443+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-05-12T17:56:43.444+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-05-12T17:56:43.444+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-05-12T17:56:43.445+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-05-12T17:56:43.445+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-05-12T17:56:43.446+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-05-12T17:56:43.447+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-05-12T17:56:43.448+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-05-12T17:56:43.454+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-05-12T17:56:43.455+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-05-12T17:56:43.457+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-05-12T17:56:43.458+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-05-12T17:56:43.459+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-05-12T17:56:43.460+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-05-12T17:56:43.460+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-05-12T17:56:43.461+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-05-12T17:56:43.461+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-05-12T17:56:43.462+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-05-12T17:56:43.463+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-05-12T17:56:43.473+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-05-12T17:56:43.475+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-05-12T17:56:43.476+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-05-12T17:56:43.477+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-05-12T17:56:43.478+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:56:43.706+0000] {subprocess.py:93} INFO - 25/05/12 17:56:43 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
[2025-05-12T17:56:43.717+0000] {subprocess.py:93} INFO - 25/05/12 17:56:43 INFO AppInfoParser: Kafka version: 3.4.1
[2025-05-12T17:56:43.719+0000] {subprocess.py:93} INFO - 25/05/12 17:56:43 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89
[2025-05-12T17:56:43.719+0000] {subprocess.py:93} INFO - 25/05/12 17:56:43 INFO AppInfoParser: Kafka startTimeMs: 1747072603703
[2025-05-12T17:56:44.907+0000] {subprocess.py:93} INFO - 25/05/12 17:56:44 INFO CheckpointFileManager: Writing atomically to file:/tmp/spark-checkpoint/b183f5ab-639d-4b3a-8a99-2c5ed0648759/sources/0/0 using temp file file:/tmp/spark-checkpoint/b183f5ab-639d-4b3a-8a99-2c5ed0648759/sources/0/.0.608db494-6fe0-466c-b9c4-154f17b6ec94.tmp
[2025-05-12T17:56:44.956+0000] {subprocess.py:93} INFO - 25/05/12 17:56:44 INFO CheckpointFileManager: Renamed temp file file:/tmp/spark-checkpoint/b183f5ab-639d-4b3a-8a99-2c5ed0648759/sources/0/.0.608db494-6fe0-466c-b9c4-154f17b6ec94.tmp to file:/tmp/spark-checkpoint/b183f5ab-639d-4b3a-8a99-2c5ed0648759/sources/0/0
[2025-05-12T17:56:44.958+0000] {subprocess.py:93} INFO - 25/05/12 17:56:44 INFO KafkaMicroBatchStream: Initial offsets: {"gold-news":{"0":0}}
[2025-05-12T17:56:45.076+0000] {subprocess.py:93} INFO - 25/05/12 17:56:45 INFO CheckpointFileManager: Writing atomically to file:/tmp/spark-checkpoint/b183f5ab-639d-4b3a-8a99-2c5ed0648759/offsets/0 using temp file file:/tmp/spark-checkpoint/b183f5ab-639d-4b3a-8a99-2c5ed0648759/offsets/.0.62534c99-022b-4322-aeda-e6e6ab91ea4a.tmp
[2025-05-12T17:56:45.185+0000] {subprocess.py:93} INFO - 25/05/12 17:56:45 INFO CheckpointFileManager: Renamed temp file file:/tmp/spark-checkpoint/b183f5ab-639d-4b3a-8a99-2c5ed0648759/offsets/.0.62534c99-022b-4322-aeda-e6e6ab91ea4a.tmp to file:/tmp/spark-checkpoint/b183f5ab-639d-4b3a-8a99-2c5ed0648759/offsets/0
[2025-05-12T17:56:45.188+0000] {subprocess.py:93} INFO - 25/05/12 17:56:45 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1747072605029,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
[2025-05-12T17:56:46.348+0000] {subprocess.py:93} INFO - 25/05/12 17:56:46 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-12T17:56:46.478+0000] {subprocess.py:93} INFO - 25/05/12 17:56:46 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-12T17:56:46.575+0000] {subprocess.py:93} INFO - 25/05/12 17:56:46 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-12T17:56:46.580+0000] {subprocess.py:93} INFO - 25/05/12 17:56:46 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
[2025-05-12T17:56:47.593+0000] {subprocess.py:93} INFO - 25/05/12 17:56:47 INFO CodeGenerator: Code generated in 599.143154 ms
[2025-05-12T17:56:48.000+0000] {subprocess.py:93} INFO - 25/05/12 17:56:47 INFO CodeGenerator: Code generated in 11.318887 ms
[2025-05-12T17:56:48.038+0000] {subprocess.py:93} INFO - 25/05/12 17:56:48 INFO SparkContext: Starting job: start at <unknown>:0
[2025-05-12T17:56:48.086+0000] {subprocess.py:93} INFO - 25/05/12 17:56:48 INFO DAGScheduler: Got job 0 (start at <unknown>:0) with 1 output partitions
[2025-05-12T17:56:48.088+0000] {subprocess.py:93} INFO - 25/05/12 17:56:48 INFO DAGScheduler: Final stage: ResultStage 0 (start at <unknown>:0)
[2025-05-12T17:56:48.090+0000] {subprocess.py:93} INFO - 25/05/12 17:56:48 INFO DAGScheduler: Parents of final stage: List()
[2025-05-12T17:56:48.100+0000] {subprocess.py:93} INFO - 25/05/12 17:56:48 INFO DAGScheduler: Missing parents: List()
[2025-05-12T17:56:48.114+0000] {subprocess.py:93} INFO - 25/05/12 17:56:48 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at start at <unknown>:0), which has no missing parents
[2025-05-12T17:56:48.604+0000] {subprocess.py:93} INFO - 25/05/12 17:56:48 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 40.5 KiB, free 434.4 MiB)
[2025-05-12T17:56:48.681+0000] {subprocess.py:93} INFO - 25/05/12 17:56:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 434.3 MiB)
[2025-05-12T17:56:48.683+0000] {subprocess.py:93} INFO - 25/05/12 17:56:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on d4e9ca837c07:42539 (size: 15.6 KiB, free: 434.4 MiB)
[2025-05-12T17:56:48.696+0000] {subprocess.py:93} INFO - 25/05/12 17:56:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
[2025-05-12T17:56:48.741+0000] {subprocess.py:93} INFO - 25/05/12 17:56:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-05-12T17:56:48.744+0000] {subprocess.py:93} INFO - 25/05/12 17:56:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-05-12T17:56:48.903+0000] {subprocess.py:93} INFO - 25/05/12 17:56:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (d4e9ca837c07, executor driver, partition 0, PROCESS_LOCAL, 13811 bytes)
[2025-05-12T17:56:48.943+0000] {subprocess.py:93} INFO - 25/05/12 17:56:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-05-12T17:56:49.344+0000] {subprocess.py:93} INFO - 25/05/12 17:56:49 INFO CodeGenerator: Code generated in 83.980513 ms
[2025-05-12T17:56:49.415+0000] {subprocess.py:93} INFO - 25/05/12 17:56:49 INFO CodeGenerator: Code generated in 69.181873 ms
[2025-05-12T17:56:49.453+0000] {subprocess.py:93} INFO - 25/05/12 17:56:49 INFO CodeGenerator: Code generated in 21.036619 ms
[2025-05-12T17:56:49.466+0000] {subprocess.py:93} INFO - 25/05/12 17:56:49 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=gold-news-0 fromOffset=0 untilOffset=70, for query queryId=5c17ed8c-6e3d-4e32-a5cf-66a76eb428c1 batchId=0 taskId=0 partitionId=0
[2025-05-12T17:56:49.670+0000] {subprocess.py:93} INFO - 25/05/12 17:56:49 INFO CodeGenerator: Code generated in 45.649744 ms
[2025-05-12T17:56:49.742+0000] {subprocess.py:93} INFO - 25/05/12 17:56:49 INFO CodeGenerator: Code generated in 45.328785 ms
[2025-05-12T17:56:49.811+0000] {subprocess.py:93} INFO - 25/05/12 17:56:49 INFO ConsumerConfig: ConsumerConfig values:
[2025-05-12T17:56:49.812+0000] {subprocess.py:93} INFO - 	allow.auto.create.topics = true
[2025-05-12T17:56:49.812+0000] {subprocess.py:93} INFO - 	auto.commit.interval.ms = 5000
[2025-05-12T17:56:49.813+0000] {subprocess.py:93} INFO - 	auto.include.jmx.reporter = true
[2025-05-12T17:56:49.822+0000] {subprocess.py:93} INFO - 	auto.offset.reset = none
[2025-05-12T17:56:49.823+0000] {subprocess.py:93} INFO - 	bootstrap.servers = [kafka:9092]
[2025-05-12T17:56:49.824+0000] {subprocess.py:93} INFO - 	check.crcs = true
[2025-05-12T17:56:49.826+0000] {subprocess.py:93} INFO - 	client.dns.lookup = use_all_dns_ips
[2025-05-12T17:56:49.827+0000] {subprocess.py:93} INFO - 	client.id = consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1
[2025-05-12T17:56:49.828+0000] {subprocess.py:93} INFO - 	client.rack =
[2025-05-12T17:56:49.829+0000] {subprocess.py:93} INFO - 	connections.max.idle.ms = 540000
[2025-05-12T17:56:49.833+0000] {subprocess.py:93} INFO - 	default.api.timeout.ms = 60000
[2025-05-12T17:56:49.834+0000] {subprocess.py:93} INFO - 	enable.auto.commit = false
[2025-05-12T17:56:49.836+0000] {subprocess.py:93} INFO - 	exclude.internal.topics = true
[2025-05-12T17:56:49.837+0000] {subprocess.py:93} INFO - 	fetch.max.bytes = 52428800
[2025-05-12T17:56:49.839+0000] {subprocess.py:93} INFO - 	fetch.max.wait.ms = 500
[2025-05-12T17:56:49.842+0000] {subprocess.py:93} INFO - 	fetch.min.bytes = 1
[2025-05-12T17:56:49.843+0000] {subprocess.py:93} INFO - 	group.id = spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor
[2025-05-12T17:56:49.848+0000] {subprocess.py:93} INFO - 	group.instance.id = null
[2025-05-12T17:56:49.850+0000] {subprocess.py:93} INFO - 	heartbeat.interval.ms = 3000
[2025-05-12T17:56:49.854+0000] {subprocess.py:93} INFO - 	interceptor.classes = []
[2025-05-12T17:56:49.855+0000] {subprocess.py:93} INFO - 	internal.leave.group.on.close = true
[2025-05-12T17:56:49.857+0000] {subprocess.py:93} INFO - 	internal.throw.on.fetch.stable.offset.unsupported = false
[2025-05-12T17:56:49.858+0000] {subprocess.py:93} INFO - 	isolation.level = read_uncommitted
[2025-05-12T17:56:49.860+0000] {subprocess.py:93} INFO - 	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-05-12T17:56:49.861+0000] {subprocess.py:93} INFO - 	max.partition.fetch.bytes = 1048576
[2025-05-12T17:56:49.864+0000] {subprocess.py:93} INFO - 	max.poll.interval.ms = 300000
[2025-05-12T17:56:49.872+0000] {subprocess.py:93} INFO - 	max.poll.records = 500
[2025-05-12T17:56:49.876+0000] {subprocess.py:93} INFO - 	metadata.max.age.ms = 300000
[2025-05-12T17:56:49.878+0000] {subprocess.py:93} INFO - 	metric.reporters = []
[2025-05-12T17:56:49.879+0000] {subprocess.py:93} INFO - 	metrics.num.samples = 2
[2025-05-12T17:56:49.881+0000] {subprocess.py:93} INFO - 	metrics.recording.level = INFO
[2025-05-12T17:56:49.882+0000] {subprocess.py:93} INFO - 	metrics.sample.window.ms = 30000
[2025-05-12T17:56:49.885+0000] {subprocess.py:93} INFO - 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
[2025-05-12T17:56:49.887+0000] {subprocess.py:93} INFO - 	receive.buffer.bytes = 65536
[2025-05-12T17:56:49.892+0000] {subprocess.py:93} INFO - 	reconnect.backoff.max.ms = 1000
[2025-05-12T17:56:49.893+0000] {subprocess.py:93} INFO - 	reconnect.backoff.ms = 50
[2025-05-12T17:56:49.894+0000] {subprocess.py:93} INFO - 	request.timeout.ms = 30000
[2025-05-12T17:56:49.895+0000] {subprocess.py:93} INFO - 	retry.backoff.ms = 100
[2025-05-12T17:56:49.896+0000] {subprocess.py:93} INFO - 	sasl.client.callback.handler.class = null
[2025-05-12T17:56:49.896+0000] {subprocess.py:93} INFO - 	sasl.jaas.config = null
[2025-05-12T17:56:49.897+0000] {subprocess.py:93} INFO - 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[2025-05-12T17:56:49.897+0000] {subprocess.py:93} INFO - 	sasl.kerberos.min.time.before.relogin = 60000
[2025-05-12T17:56:49.898+0000] {subprocess.py:93} INFO - 	sasl.kerberos.service.name = null
[2025-05-12T17:56:49.899+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.jitter = 0.05
[2025-05-12T17:56:49.900+0000] {subprocess.py:93} INFO - 	sasl.kerberos.ticket.renew.window.factor = 0.8
[2025-05-12T17:56:49.902+0000] {subprocess.py:93} INFO - 	sasl.login.callback.handler.class = null
[2025-05-12T17:56:49.903+0000] {subprocess.py:93} INFO - 	sasl.login.class = null
[2025-05-12T17:56:49.904+0000] {subprocess.py:93} INFO - 	sasl.login.connect.timeout.ms = null
[2025-05-12T17:56:49.909+0000] {subprocess.py:93} INFO - 	sasl.login.read.timeout.ms = null
[2025-05-12T17:56:49.910+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.buffer.seconds = 300
[2025-05-12T17:56:49.911+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.min.period.seconds = 60
[2025-05-12T17:56:49.912+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.factor = 0.8
[2025-05-12T17:56:49.913+0000] {subprocess.py:93} INFO - 	sasl.login.refresh.window.jitter = 0.05
[2025-05-12T17:56:49.915+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.max.ms = 10000
[2025-05-12T17:56:49.916+0000] {subprocess.py:93} INFO - 	sasl.login.retry.backoff.ms = 100
[2025-05-12T17:56:49.917+0000] {subprocess.py:93} INFO - 	sasl.mechanism = GSSAPI
[2025-05-12T17:56:49.918+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.clock.skew.seconds = 30
[2025-05-12T17:56:49.923+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.audience = null
[2025-05-12T17:56:49.925+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.expected.issuer = null
[2025-05-12T17:56:49.926+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
[2025-05-12T17:56:49.927+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
[2025-05-12T17:56:49.927+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
[2025-05-12T17:56:49.928+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.jwks.endpoint.url = null
[2025-05-12T17:56:49.928+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.scope.claim.name = scope
[2025-05-12T17:56:49.929+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.sub.claim.name = sub
[2025-05-12T17:56:49.929+0000] {subprocess.py:93} INFO - 	sasl.oauthbearer.token.endpoint.url = null
[2025-05-12T17:56:49.930+0000] {subprocess.py:93} INFO - 	security.protocol = PLAINTEXT
[2025-05-12T17:56:49.930+0000] {subprocess.py:93} INFO - 	security.providers = null
[2025-05-12T17:56:49.931+0000] {subprocess.py:93} INFO - 	send.buffer.bytes = 131072
[2025-05-12T17:56:49.932+0000] {subprocess.py:93} INFO - 	session.timeout.ms = 45000
[2025-05-12T17:56:49.932+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.max.ms = 30000
[2025-05-12T17:56:49.933+0000] {subprocess.py:93} INFO - 	socket.connection.setup.timeout.ms = 10000
[2025-05-12T17:56:49.934+0000] {subprocess.py:93} INFO - 	ssl.cipher.suites = null
[2025-05-12T17:56:49.934+0000] {subprocess.py:93} INFO - 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
[2025-05-12T17:56:49.935+0000] {subprocess.py:93} INFO - 	ssl.endpoint.identification.algorithm = https
[2025-05-12T17:56:49.941+0000] {subprocess.py:93} INFO - 	ssl.engine.factory.class = null
[2025-05-12T17:56:49.947+0000] {subprocess.py:93} INFO - 	ssl.key.password = null
[2025-05-12T17:56:49.948+0000] {subprocess.py:93} INFO - 	ssl.keymanager.algorithm = SunX509
[2025-05-12T17:56:49.949+0000] {subprocess.py:93} INFO - 	ssl.keystore.certificate.chain = null
[2025-05-12T17:56:49.951+0000] {subprocess.py:93} INFO - 	ssl.keystore.key = null
[2025-05-12T17:56:49.954+0000] {subprocess.py:93} INFO - 	ssl.keystore.location = null
[2025-05-12T17:56:49.956+0000] {subprocess.py:93} INFO - 	ssl.keystore.password = null
[2025-05-12T17:56:49.956+0000] {subprocess.py:93} INFO - 	ssl.keystore.type = JKS
[2025-05-12T17:56:49.956+0000] {subprocess.py:93} INFO - 	ssl.protocol = TLSv1.3
[2025-05-12T17:56:49.957+0000] {subprocess.py:93} INFO - 	ssl.provider = null
[2025-05-12T17:56:49.957+0000] {subprocess.py:93} INFO - 	ssl.secure.random.implementation = null
[2025-05-12T17:56:49.958+0000] {subprocess.py:93} INFO - 	ssl.trustmanager.algorithm = PKIX
[2025-05-12T17:56:49.958+0000] {subprocess.py:93} INFO - 	ssl.truststore.certificates = null
[2025-05-12T17:56:49.959+0000] {subprocess.py:93} INFO - 	ssl.truststore.location = null
[2025-05-12T17:56:49.959+0000] {subprocess.py:93} INFO - 	ssl.truststore.password = null
[2025-05-12T17:56:49.959+0000] {subprocess.py:93} INFO - 	ssl.truststore.type = JKS
[2025-05-12T17:56:49.960+0000] {subprocess.py:93} INFO - 	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
[2025-05-12T17:56:49.960+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:56:50.001+0000] {subprocess.py:93} INFO - 25/05/12 17:56:49 INFO AppInfoParser: Kafka version: 3.4.1
[2025-05-12T17:56:50.004+0000] {subprocess.py:93} INFO - 25/05/12 17:56:49 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89
[2025-05-12T17:56:50.005+0000] {subprocess.py:93} INFO - 25/05/12 17:56:50 INFO AppInfoParser: Kafka startTimeMs: 1747072609994
[2025-05-12T17:56:50.017+0000] {subprocess.py:93} INFO - 25/05/12 17:56:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1, groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor] Assigned to partition(s): gold-news-0
[2025-05-12T17:56:50.037+0000] {subprocess.py:93} INFO - 25/05/12 17:56:50 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1, groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor] Seeking to offset 0 for partition gold-news-0
[2025-05-12T17:56:50.072+0000] {subprocess.py:93} INFO - 25/05/12 17:56:50 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1, groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor] Resetting the last seen epoch of partition gold-news-0 to 0 since the associated topicId changed from null to EyFovrTXQQOm3GPuq8IGNA
[2025-05-12T17:56:50.079+0000] {subprocess.py:93} INFO - 25/05/12 17:56:50 INFO Metadata: [Consumer clientId=consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1, groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor] Cluster ID: HTSY0p8VS7eCaEFoyzBH3g
[2025-05-12T17:56:50.247+0000] {subprocess.py:93} INFO - 25/05/12 17:56:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1, groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor] Seeking to earliest offset of partition gold-news-0
[2025-05-12T17:56:50.743+0000] {subprocess.py:93} INFO - 25/05/12 17:56:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1, groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor] Resetting offset for partition gold-news-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-05-12T17:56:50.744+0000] {subprocess.py:93} INFO - 25/05/12 17:56:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1, groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor] Seeking to latest offset of partition gold-news-0
[2025-05-12T17:56:50.747+0000] {subprocess.py:93} INFO - 25/05/12 17:56:50 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1, groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor] Resetting offset for partition gold-news-0 to position FetchPosition{offset=70, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-05-12T17:56:50.939+0000] {subprocess.py:93} INFO - 25/05/12 17:56:50 INFO KafkaDataConsumer: From Kafka topicPartition=gold-news-0 groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor read 1 records through 1 polls (polled  out 70 records), taking 710341381 nanos, during time span of 913847495 nanos.
[2025-05-12T17:56:50.967+0000] {subprocess.py:93} INFO - 25/05/12 17:56:50 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1957 bytes result sent to driver
[2025-05-12T17:56:50.984+0000] {subprocess.py:93} INFO - 25/05/12 17:56:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2161 ms on d4e9ca837c07 (executor driver) (1/1)
[2025-05-12T17:56:50.989+0000] {subprocess.py:93} INFO - 25/05/12 17:56:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-05-12T17:56:50.999+0000] {subprocess.py:93} INFO - 25/05/12 17:56:50 INFO DAGScheduler: ResultStage 0 (start at <unknown>:0) finished in 2.821 s
[2025-05-12T17:56:51.010+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-12T17:56:51.011+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2025-05-12T17:56:51.014+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO DAGScheduler: Job 0 finished: start at <unknown>:0, took 2.974928 s
[2025-05-12T17:56:51.112+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO CodeGenerator: Code generated in 23.744946 ms
[2025-05-12T17:56:51.147+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2025-05-12T17:56:51.149+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO DAGScheduler: Got job 1 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2025-05-12T17:56:51.150+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO DAGScheduler: Final stage: ResultStage 1 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2025-05-12T17:56:51.151+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO DAGScheduler: Parents of final stage: List()
[2025-05-12T17:56:51.151+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO DAGScheduler: Missing parents: List()
[2025-05-12T17:56:51.152+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2025-05-12T17:56:51.161+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 42.3 KiB, free 434.3 MiB)
[2025-05-12T17:56:51.196+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 16.1 KiB, free 434.3 MiB)
[2025-05-12T17:56:51.198+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on d4e9ca837c07:42539 (size: 16.1 KiB, free: 434.4 MiB)
[2025-05-12T17:56:51.200+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1585
[2025-05-12T17:56:51.201+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2025-05-12T17:56:51.205+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2025-05-12T17:56:51.207+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (d4e9ca837c07, executor driver, partition 0, PROCESS_LOCAL, 13811 bytes)
[2025-05-12T17:56:51.208+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2025-05-12T17:56:51.281+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO CodeGenerator: Code generated in 39.671846 ms
[2025-05-12T17:56:51.284+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO KafkaBatchReaderFactory: Creating Kafka reader topicPartition=gold-news-0 fromOffset=0 untilOffset=70, for query queryId=5c17ed8c-6e3d-4e32-a5cf-66a76eb428c1 batchId=0 taskId=1 partitionId=0
[2025-05-12T17:56:51.308+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO BlockManagerInfo: Removed broadcast_0_piece0 on d4e9ca837c07:42539 in memory (size: 15.6 KiB, free: 434.4 MiB)
[2025-05-12T17:56:51.314+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO KafkaConsumer: [Consumer clientId=consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1, groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor] Seeking to offset 0 for partition gold-news-0
[2025-05-12T17:56:51.321+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1, groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor] Seeking to earliest offset of partition gold-news-0
[2025-05-12T17:56:51.828+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1, groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor] Resetting offset for partition gold-news-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-05-12T17:56:51.829+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1, groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor] Seeking to latest offset of partition gold-news-0
[2025-05-12T17:56:51.832+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO SubscriptionState: [Consumer clientId=consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1, groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor] Resetting offset for partition gold-news-0 to position FetchPosition{offset=70, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafka:9092 (id: 1 rack: null)], epoch=0}}.
[2025-05-12T17:56:51.879+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO KafkaDataConsumer: From Kafka topicPartition=gold-news-0 groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor read 70 records through 1 polls (polled  out 70 records), taking 517520696 nanos, during time span of 565441286 nanos.
[2025-05-12T17:56:51.884+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 12180 bytes result sent to driver
[2025-05-12T17:56:51.887+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 682 ms on d4e9ca837c07 (executor driver) (1/1)
[2025-05-12T17:56:51.891+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-05-12T17:56:51.893+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO DAGScheduler: ResultStage 1 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.734 s
[2025-05-12T17:56:51.894+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-12T17:56:51.895+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2025-05-12T17:56:51.896+0000] {subprocess.py:93} INFO - 25/05/12 17:56:51 INFO DAGScheduler: Job 1 finished: call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.743781 s
[2025-05-12T17:56:52.003+0000] {subprocess.py:93} INFO - Traitement du batch 0 avec 70 descriptions
[2025-05-12T17:57:16.794+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.796+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T17:57:16.798+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.799+0000] {subprocess.py:93} INFO -   "description_number": "1",
[2025-05-12T17:57:16.799+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.800+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's rise due to easing trade tensions could reduce safe-haven demand for gold, but it's not directly impacting the gold market.",
[2025-05-12T17:57:16.800+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.801+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.801+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.802+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T17:57:16.803+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.803+0000] {subprocess.py:93} INFO -   "description_number": "2",
[2025-05-12T17:57:16.804+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.804+0000] {subprocess.py:93} INFO -   "impact_explanation": "A legal settlement between Google and Texas is unlikely to have a significant direct impact on gold prices.",
[2025-05-12T17:57:16.805+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.805+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.806+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.806+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T17:57:16.807+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.807+0000] {subprocess.py:93} INFO -   "description_number": "3",
[2025-05-12T17:57:16.808+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T17:57:16.808+0000] {subprocess.py:93} INFO -   "impact_explanation": "Volatile markets often drive investors towards safe-haven assets like gold.",
[2025-05-12T17:57:16.809+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T17:57:16.810+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.810+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.811+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T17:57:16.812+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.813+0000] {subprocess.py:93} INFO -   "description_number": "4",
[2025-05-12T17:57:16.814+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.814+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is about blogging and SEO and has no direct relevance to gold prices.",
[2025-05-12T17:57:16.815+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.815+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.816+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.816+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T17:57:16.817+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.817+0000] {subprocess.py:93} INFO -   "description_number": "5",
[2025-05-12T17:57:16.818+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T17:57:16.818+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically increases the demand for dollar-denominated assets like gold.",
[2025-05-12T17:57:16.819+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T17:57:16.820+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.820+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.820+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T17:57:16.821+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.822+0000] {subprocess.py:93} INFO -   "description_number": "6",
[2025-05-12T17:57:16.822+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.823+0000] {subprocess.py:93} INFO -   "impact_explanation": "Political news and financial dealings may indirectly affect market sentiment but have no direct impact on gold prices.",
[2025-05-12T17:57:16.823+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.823+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.824+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.824+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T17:57:16.825+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.825+0000] {subprocess.py:93} INFO -   "description_number": "7",
[2025-05-12T17:57:16.826+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.827+0000] {subprocess.py:93} INFO -   "impact_explanation": "An article about Web3 investment in 2025 has no direct relevance to the current gold market.",
[2025-05-12T17:57:16.828+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.828+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.829+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.830+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T17:57:16.830+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.831+0000] {subprocess.py:93} INFO -   "description_number": "8",
[2025-05-12T17:57:16.831+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.832+0000] {subprocess.py:93} INFO -   "impact_explanation": "A GitHub repository about cybersecurity tools is unrelated to gold prices.",
[2025-05-12T17:57:16.833+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.833+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.834+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.834+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T17:57:16.835+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.835+0000] {subprocess.py:93} INFO -   "description_number": "9",
[2025-05-12T17:57:16.836+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.836+0000] {subprocess.py:93} INFO -   "impact_explanation": "Tourism news in Northern California has no direct impact on the gold market.",
[2025-05-12T17:57:16.837+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.837+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.838+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.838+0000] {subprocess.py:93} INFO - Analyse pour l'article : What Is An XRP Spot ETF?...
[2025-05-12T17:57:16.839+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.839+0000] {subprocess.py:93} INFO -   "description_number": "10",
[2025-05-12T17:57:16.840+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.841+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about an XRP ETF could impact the crypto market but has limited direct influence on gold prices.",
[2025-05-12T17:57:16.841+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.843+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.844+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.845+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T17:57:16.845+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.846+0000] {subprocess.py:93} INFO -   "description_number": "11",
[2025-05-12T17:57:16.846+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.847+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's rise due to easing trade tensions could reduce safe-haven demand for gold, but it's not directly impacting the gold market.",
[2025-05-12T17:57:16.847+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.848+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.848+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.848+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T17:57:16.849+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.849+0000] {subprocess.py:93} INFO -   "description_number": "12",
[2025-05-12T17:57:16.850+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.850+0000] {subprocess.py:93} INFO -   "impact_explanation": "A legal settlement between Google and Texas is unlikely to have a significant direct impact on gold prices.",
[2025-05-12T17:57:16.851+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.851+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.851+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.852+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T17:57:16.852+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.853+0000] {subprocess.py:93} INFO -   "description_number": "13",
[2025-05-12T17:57:16.853+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T17:57:16.854+0000] {subprocess.py:93} INFO -   "impact_explanation": "Volatile markets often drive investors towards safe-haven assets like gold.",
[2025-05-12T17:57:16.854+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T17:57:16.855+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.855+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.856+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T17:57:16.857+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.858+0000] {subprocess.py:93} INFO -   "description_number": "14",
[2025-05-12T17:57:16.859+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.859+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is about blogging and SEO and has no direct relevance to gold prices.",
[2025-05-12T17:57:16.860+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.860+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.861+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.862+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T17:57:16.862+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.863+0000] {subprocess.py:93} INFO -   "description_number": "15",
[2025-05-12T17:57:16.863+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T17:57:16.864+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically increases the demand for dollar-denominated assets like gold.",
[2025-05-12T17:57:16.865+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T17:57:16.866+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.866+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.867+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T17:57:16.868+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.868+0000] {subprocess.py:93} INFO -   "description_number": "16",
[2025-05-12T17:57:16.869+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.869+0000] {subprocess.py:93} INFO -   "impact_explanation": "Political news and financial dealings may indirectly affect market sentiment but have no direct impact on gold prices.",
[2025-05-12T17:57:16.870+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.874+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.875+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.876+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T17:57:16.876+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.876+0000] {subprocess.py:93} INFO -   "description_number": "17",
[2025-05-12T17:57:16.877+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.877+0000] {subprocess.py:93} INFO -   "impact_explanation": "An article about Web3 investment in 2025 has no direct relevance to the current gold market.",
[2025-05-12T17:57:16.878+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.878+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.879+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.880+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T17:57:16.880+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.881+0000] {subprocess.py:93} INFO -   "description_number": "18",
[2025-05-12T17:57:16.881+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.882+0000] {subprocess.py:93} INFO -   "impact_explanation": "A GitHub repository about cybersecurity tools is unrelated to gold prices.",
[2025-05-12T17:57:16.882+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.883+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.883+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.884+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T17:57:16.884+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.885+0000] {subprocess.py:93} INFO -   "description_number": "19",
[2025-05-12T17:57:16.885+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.886+0000] {subprocess.py:93} INFO -   "impact_explanation": "Tourism news in Northern California has no direct impact on the gold market.",
[2025-05-12T17:57:16.886+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.887+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.889+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.890+0000] {subprocess.py:93} INFO - Analyse pour l'article : What Is An XRP Spot ETF?...
[2025-05-12T17:57:16.890+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.891+0000] {subprocess.py:93} INFO -   "description_number": "20",
[2025-05-12T17:57:16.891+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.892+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about an XRP ETF could impact the crypto market but has limited direct influence on gold prices.",
[2025-05-12T17:57:16.892+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.892+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.893+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.893+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T17:57:16.893+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.894+0000] {subprocess.py:93} INFO -   "description_number": "21",
[2025-05-12T17:57:16.894+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.895+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's rise due to easing trade tensions could reduce safe-haven demand for gold, but it's not directly impacting the gold market.",
[2025-05-12T17:57:16.895+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.895+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.896+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.896+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T17:57:16.897+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.897+0000] {subprocess.py:93} INFO -   "description_number": "22",
[2025-05-12T17:57:16.898+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.898+0000] {subprocess.py:93} INFO -   "impact_explanation": "A legal settlement between Google and Texas is unlikely to have a significant direct impact on gold prices.",
[2025-05-12T17:57:16.899+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.899+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.900+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.900+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T17:57:16.901+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.901+0000] {subprocess.py:93} INFO -   "description_number": "23",
[2025-05-12T17:57:16.902+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T17:57:16.902+0000] {subprocess.py:93} INFO -   "impact_explanation": "Volatile markets often drive investors towards safe-haven assets like gold.",
[2025-05-12T17:57:16.903+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T17:57:16.904+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.904+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.905+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T17:57:16.905+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.905+0000] {subprocess.py:93} INFO -   "description_number": "24",
[2025-05-12T17:57:16.906+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.906+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is about blogging and SEO and has no direct relevance to gold prices.",
[2025-05-12T17:57:16.906+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.907+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.907+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.908+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T17:57:16.908+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.909+0000] {subprocess.py:93} INFO -   "description_number": "25",
[2025-05-12T17:57:16.909+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T17:57:16.910+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically increases the demand for dollar-denominated assets like gold.",
[2025-05-12T17:57:16.910+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T17:57:16.911+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.912+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.913+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T17:57:16.913+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.914+0000] {subprocess.py:93} INFO -   "description_number": "26",
[2025-05-12T17:57:16.914+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.915+0000] {subprocess.py:93} INFO -   "impact_explanation": "Political news and financial dealings may indirectly affect market sentiment but have no direct impact on gold prices.",
[2025-05-12T17:57:16.915+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.916+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.916+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.917+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T17:57:16.918+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.918+0000] {subprocess.py:93} INFO -   "description_number": "27",
[2025-05-12T17:57:16.919+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.920+0000] {subprocess.py:93} INFO -   "impact_explanation": "An article about Web3 investment in 2025 has no direct relevance to the current gold market.",
[2025-05-12T17:57:16.920+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.921+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.921+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.922+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T17:57:16.922+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.922+0000] {subprocess.py:93} INFO -   "description_number": "28",
[2025-05-12T17:57:16.923+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.923+0000] {subprocess.py:93} INFO -   "impact_explanation": "A GitHub repository about cybersecurity tools is unrelated to gold prices.",
[2025-05-12T17:57:16.924+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.924+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.925+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.925+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T17:57:16.925+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.926+0000] {subprocess.py:93} INFO -   "description_number": "29",
[2025-05-12T17:57:16.926+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.927+0000] {subprocess.py:93} INFO -   "impact_explanation": "Tourism news in Northern California has no direct impact on the gold market.",
[2025-05-12T17:57:16.927+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.928+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.928+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.929+0000] {subprocess.py:93} INFO - Analyse pour l'article : What Is An XRP Spot ETF?...
[2025-05-12T17:57:16.929+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.930+0000] {subprocess.py:93} INFO -   "description_number": "30",
[2025-05-12T17:57:16.930+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.931+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about an XRP ETF could impact the crypto market but has limited direct influence on gold prices.",
[2025-05-12T17:57:16.933+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.935+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.936+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.937+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T17:57:16.938+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.939+0000] {subprocess.py:93} INFO -   "description_number": "31",
[2025-05-12T17:57:16.940+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.941+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's rise due to easing trade tensions could reduce safe-haven demand for gold, but it's not directly impacting the gold market.",
[2025-05-12T17:57:16.942+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.942+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.943+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.943+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T17:57:16.944+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.945+0000] {subprocess.py:93} INFO -   "description_number": "32",
[2025-05-12T17:57:16.946+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.946+0000] {subprocess.py:93} INFO -   "impact_explanation": "A legal settlement between Google and Texas is unlikely to have a significant direct impact on gold prices.",
[2025-05-12T17:57:16.949+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.952+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.953+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.953+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T17:57:16.954+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.954+0000] {subprocess.py:93} INFO -   "description_number": "33",
[2025-05-12T17:57:16.955+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T17:57:16.956+0000] {subprocess.py:93} INFO -   "impact_explanation": "Volatile markets often drive investors towards safe-haven assets like gold.",
[2025-05-12T17:57:16.956+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T17:57:16.957+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.957+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.958+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T17:57:16.958+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.959+0000] {subprocess.py:93} INFO -   "description_number": "34",
[2025-05-12T17:57:16.959+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.960+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is about blogging and SEO and has no direct relevance to gold prices.",
[2025-05-12T17:57:16.960+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.961+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.962+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.964+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T17:57:16.966+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.967+0000] {subprocess.py:93} INFO -   "description_number": "35",
[2025-05-12T17:57:16.967+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T17:57:16.968+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically increases the demand for dollar-denominated assets like gold.",
[2025-05-12T17:57:16.969+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T17:57:16.969+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.970+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.971+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T17:57:16.972+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.973+0000] {subprocess.py:93} INFO -   "description_number": "36",
[2025-05-12T17:57:16.973+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.974+0000] {subprocess.py:93} INFO -   "impact_explanation": "Political news and financial dealings may indirectly affect market sentiment but have no direct impact on gold prices.",
[2025-05-12T17:57:16.974+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.975+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.976+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.976+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T17:57:16.977+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.977+0000] {subprocess.py:93} INFO -   "description_number": "37",
[2025-05-12T17:57:16.978+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.978+0000] {subprocess.py:93} INFO -   "impact_explanation": "An article about Web3 investment in 2025 has no direct relevance to the current gold market.",
[2025-05-12T17:57:16.979+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.982+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.982+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.983+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T17:57:16.984+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.984+0000] {subprocess.py:93} INFO -   "description_number": "38",
[2025-05-12T17:57:16.985+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.986+0000] {subprocess.py:93} INFO -   "impact_explanation": "A GitHub repository about cybersecurity tools is unrelated to gold prices.",
[2025-05-12T17:57:16.986+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.987+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.987+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.988+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T17:57:16.988+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.989+0000] {subprocess.py:93} INFO -   "description_number": "39",
[2025-05-12T17:57:16.989+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.990+0000] {subprocess.py:93} INFO -   "impact_explanation": "Tourism news in Northern California has no direct impact on the gold market.",
[2025-05-12T17:57:16.991+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.991+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.992+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:16.992+0000] {subprocess.py:93} INFO - Analyse pour l'article : What Is An XRP Spot ETF?...
[2025-05-12T17:57:16.994+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:16.996+0000] {subprocess.py:93} INFO -   "description_number": "40",
[2025-05-12T17:57:16.997+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:16.997+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about an XRP ETF could impact the crypto market but has limited direct influence on gold prices.",
[2025-05-12T17:57:16.998+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:16.998+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:16.999+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.000+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T17:57:17.000+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.001+0000] {subprocess.py:93} INFO -   "description_number": "41",
[2025-05-12T17:57:17.001+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.002+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's rise due to easing trade tensions could reduce safe-haven demand for gold, but it's not directly impacting the gold market.",
[2025-05-12T17:57:17.002+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.003+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.003+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.004+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T17:57:17.005+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.005+0000] {subprocess.py:93} INFO -   "description_number": "42",
[2025-05-12T17:57:17.006+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.006+0000] {subprocess.py:93} INFO -   "impact_explanation": "A legal settlement between Google and Texas is unlikely to have a significant direct impact on gold prices.",
[2025-05-12T17:57:17.007+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.007+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.008+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.010+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T17:57:17.012+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.013+0000] {subprocess.py:93} INFO -   "description_number": "43",
[2025-05-12T17:57:17.014+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T17:57:17.015+0000] {subprocess.py:93} INFO -   "impact_explanation": "Volatile markets often drive investors towards safe-haven assets like gold.",
[2025-05-12T17:57:17.015+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T17:57:17.016+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.017+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.018+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T17:57:17.019+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.019+0000] {subprocess.py:93} INFO -   "description_number": "44",
[2025-05-12T17:57:17.020+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.020+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is about blogging and SEO and has no direct relevance to gold prices.",
[2025-05-12T17:57:17.021+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.021+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.022+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.022+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T17:57:17.023+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.023+0000] {subprocess.py:93} INFO -   "description_number": "45",
[2025-05-12T17:57:17.024+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T17:57:17.025+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically increases the demand for dollar-denominated assets like gold.",
[2025-05-12T17:57:17.026+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T17:57:17.027+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.028+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.028+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T17:57:17.029+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.029+0000] {subprocess.py:93} INFO -   "description_number": "46",
[2025-05-12T17:57:17.030+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.030+0000] {subprocess.py:93} INFO -   "impact_explanation": "Political news and financial dealings may indirectly affect market sentiment but have no direct impact on gold prices.",
[2025-05-12T17:57:17.031+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.031+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.032+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.032+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T17:57:17.033+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.034+0000] {subprocess.py:93} INFO -   "description_number": "47",
[2025-05-12T17:57:17.034+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.035+0000] {subprocess.py:93} INFO -   "impact_explanation": "An article about Web3 investment in 2025 has no direct relevance to the current gold market.",
[2025-05-12T17:57:17.035+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.036+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.036+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.037+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T17:57:17.037+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.038+0000] {subprocess.py:93} INFO -   "description_number": "48",
[2025-05-12T17:57:17.038+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.041+0000] {subprocess.py:93} INFO -   "impact_explanation": "A GitHub repository about cybersecurity tools is unrelated to gold prices.",
[2025-05-12T17:57:17.042+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.043+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.043+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.044+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T17:57:17.045+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.045+0000] {subprocess.py:93} INFO -   "description_number": "49",
[2025-05-12T17:57:17.046+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.046+0000] {subprocess.py:93} INFO -   "impact_explanation": "Tourism news in Northern California has no direct impact on the gold market.",
[2025-05-12T17:57:17.047+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.047+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.048+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.048+0000] {subprocess.py:93} INFO - Analyse pour l'article : What Is An XRP Spot ETF?...
[2025-05-12T17:57:17.048+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.049+0000] {subprocess.py:93} INFO -   "description_number": "50",
[2025-05-12T17:57:17.050+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.050+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about an XRP ETF could impact the crypto market but has limited direct influence on gold prices.",
[2025-05-12T17:57:17.051+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.051+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.052+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.052+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T17:57:17.052+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.053+0000] {subprocess.py:93} INFO -   "description_number": "51",
[2025-05-12T17:57:17.054+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.054+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's rise due to easing trade tensions could reduce safe-haven demand for gold, but it's not directly impacting the gold market.",
[2025-05-12T17:57:17.056+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.058+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.059+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.059+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T17:57:17.060+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.060+0000] {subprocess.py:93} INFO -   "description_number": "52",
[2025-05-12T17:57:17.061+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.061+0000] {subprocess.py:93} INFO -   "impact_explanation": "A legal settlement between Google and Texas is unlikely to have a significant direct impact on gold prices.",
[2025-05-12T17:57:17.062+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.062+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.062+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.063+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T17:57:17.063+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.064+0000] {subprocess.py:93} INFO -   "description_number": "53",
[2025-05-12T17:57:17.064+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T17:57:17.065+0000] {subprocess.py:93} INFO -   "impact_explanation": "Volatile markets often drive investors towards safe-haven assets like gold.",
[2025-05-12T17:57:17.065+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T17:57:17.066+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.066+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.067+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T17:57:17.067+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.068+0000] {subprocess.py:93} INFO -   "description_number": "54",
[2025-05-12T17:57:17.068+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.069+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is about blogging and SEO and has no direct relevance to gold prices.",
[2025-05-12T17:57:17.069+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.070+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.070+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.072+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T17:57:17.073+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.074+0000] {subprocess.py:93} INFO -   "description_number": "55",
[2025-05-12T17:57:17.074+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T17:57:17.075+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically increases the demand for dollar-denominated assets like gold.",
[2025-05-12T17:57:17.075+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T17:57:17.076+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.076+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.077+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T17:57:17.077+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.078+0000] {subprocess.py:93} INFO -   "description_number": "56",
[2025-05-12T17:57:17.078+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.078+0000] {subprocess.py:93} INFO -   "impact_explanation": "Political news and financial dealings may indirectly affect market sentiment but have no direct impact on gold prices.",
[2025-05-12T17:57:17.079+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.079+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.080+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.080+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T17:57:17.081+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.081+0000] {subprocess.py:93} INFO -   "description_number": "57",
[2025-05-12T17:57:17.082+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.082+0000] {subprocess.py:93} INFO -   "impact_explanation": "An article about Web3 investment in 2025 has no direct relevance to the current gold market.",
[2025-05-12T17:57:17.083+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.083+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.084+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.084+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T17:57:17.085+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.086+0000] {subprocess.py:93} INFO -   "description_number": "58",
[2025-05-12T17:57:17.087+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.088+0000] {subprocess.py:93} INFO -   "impact_explanation": "A GitHub repository about cybersecurity tools is unrelated to gold prices.",
[2025-05-12T17:57:17.088+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.089+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.089+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.089+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T17:57:17.090+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.090+0000] {subprocess.py:93} INFO -   "description_number": "59",
[2025-05-12T17:57:17.091+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.092+0000] {subprocess.py:93} INFO -   "impact_explanation": "Tourism news in Northern California has no direct impact on the gold market.",
[2025-05-12T17:57:17.093+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.094+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.094+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.095+0000] {subprocess.py:93} INFO - Analyse pour l'article : What Is An XRP Spot ETF?...
[2025-05-12T17:57:17.095+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.096+0000] {subprocess.py:93} INFO -   "description_number": "60",
[2025-05-12T17:57:17.096+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.097+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about an XRP ETF could impact the crypto market but has limited direct influence on gold prices.",
[2025-05-12T17:57:17.097+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.098+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.098+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.099+0000] {subprocess.py:93} INFO - Analyse pour l'article : Best Altcoins to Buy as Bitcoin Nears All-Time Hig...
[2025-05-12T17:57:17.100+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.100+0000] {subprocess.py:93} INFO -   "description_number": "61",
[2025-05-12T17:57:17.102+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.103+0000] {subprocess.py:93} INFO -   "impact_explanation": "Bitcoin's rise due to easing trade tensions could reduce safe-haven demand for gold, but it's not directly impacting the gold market.",
[2025-05-12T17:57:17.104+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.104+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.105+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.106+0000] {subprocess.py:93} INFO - Analyse pour l'article : Google will pay Texas $1.4 billion over its locati...
[2025-05-12T17:57:17.106+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.108+0000] {subprocess.py:93} INFO -   "description_number": "62",
[2025-05-12T17:57:17.108+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.109+0000] {subprocess.py:93} INFO -   "impact_explanation": "A legal settlement between Google and Texas is unlikely to have a significant direct impact on gold prices.",
[2025-05-12T17:57:17.110+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.110+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.111+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.111+0000] {subprocess.py:93} INFO - Analyse pour l'article : In Volatile Markets, RWAs Like Gold Are A Lifeline...
[2025-05-12T17:57:17.112+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.112+0000] {subprocess.py:93} INFO -   "description_number": "63",
[2025-05-12T17:57:17.113+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T17:57:17.114+0000] {subprocess.py:93} INFO -   "impact_explanation": "Volatile markets often drive investors towards safe-haven assets like gold.",
[2025-05-12T17:57:17.114+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T17:57:17.115+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.116+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.118+0000] {subprocess.py:93} INFO - Analyse pour l'article : Top Blog SEO Tips for Higher Search Rankings | Sim...
[2025-05-12T17:57:17.119+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.119+0000] {subprocess.py:93} INFO -   "description_number": "64",
[2025-05-12T17:57:17.120+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.120+0000] {subprocess.py:93} INFO -   "impact_explanation": "This description is about blogging and SEO and has no direct relevance to gold prices.",
[2025-05-12T17:57:17.121+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.121+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.122+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.123+0000] {subprocess.py:93} INFO - Analyse pour l'article : George W. Bush Lit The Dollar Fire On Which Trump ...
[2025-05-12T17:57:17.123+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.124+0000] {subprocess.py:93} INFO -   "description_number": "65",
[2025-05-12T17:57:17.124+0000] {subprocess.py:93} INFO -   "sentiment": "Positive",
[2025-05-12T17:57:17.125+0000] {subprocess.py:93} INFO -   "impact_explanation": "A weak dollar typically increases the demand for dollar-denominated assets like gold.",
[2025-05-12T17:57:17.125+0000] {subprocess.py:93} INFO -   "recommendation": "Buy"
[2025-05-12T17:57:17.126+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.126+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.127+0000] {subprocess.py:93} INFO - Analyse pour l'article : The 3 Easy New Ways Anyone Can Funnel Money Direct...
[2025-05-12T17:57:17.127+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.128+0000] {subprocess.py:93} INFO -   "description_number": "66",
[2025-05-12T17:57:17.128+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.129+0000] {subprocess.py:93} INFO -   "impact_explanation": "Political news and financial dealings may indirectly affect market sentiment but have no direct impact on gold prices.",
[2025-05-12T17:57:17.129+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.129+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.130+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.131+0000] {subprocess.py:93} INFO - Analyse pour l'article : How To Invest In Web3 In 2025...
[2025-05-12T17:57:17.132+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.134+0000] {subprocess.py:93} INFO -   "description_number": "67",
[2025-05-12T17:57:17.134+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.135+0000] {subprocess.py:93} INFO -   "impact_explanation": "An article about Web3 investment in 2025 has no direct relevance to the current gold market.",
[2025-05-12T17:57:17.136+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.136+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.137+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.137+0000] {subprocess.py:93} INFO - Analyse pour l'article : Shodan-Dorks - Dorks for Shodan; a powerful tool u...
[2025-05-12T17:57:17.138+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.138+0000] {subprocess.py:93} INFO -   "description_number": "68",
[2025-05-12T17:57:17.139+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.139+0000] {subprocess.py:93} INFO -   "impact_explanation": "A GitHub repository about cybersecurity tools is unrelated to gold prices.",
[2025-05-12T17:57:17.140+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.141+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.141+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.142+0000] {subprocess.py:93} INFO - Analyse pour l'article : A historic hotel might be the spark a California c...
[2025-05-12T17:57:17.142+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.143+0000] {subprocess.py:93} INFO -   "description_number": "69",
[2025-05-12T17:57:17.143+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.144+0000] {subprocess.py:93} INFO -   "impact_explanation": "Tourism news in Northern California has no direct impact on the gold market.",
[2025-05-12T17:57:17.144+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.144+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.145+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:17.146+0000] {subprocess.py:93} INFO - Analyse pour l'article : What Is An XRP Spot ETF?...
[2025-05-12T17:57:17.146+0000] {subprocess.py:93} INFO - {
[2025-05-12T17:57:17.147+0000] {subprocess.py:93} INFO -   "description_number": "70",
[2025-05-12T17:57:17.147+0000] {subprocess.py:93} INFO -   "sentiment": "Neutral",
[2025-05-12T17:57:17.149+0000] {subprocess.py:93} INFO -   "impact_explanation": "News about an XRP ETF could impact the crypto market but has limited direct influence on gold prices.",
[2025-05-12T17:57:17.150+0000] {subprocess.py:93} INFO -   "recommendation": "Hold"
[2025-05-12T17:57:17.150+0000] {subprocess.py:93} INFO - }
[2025-05-12T17:57:17.460+0000] {subprocess.py:93} INFO - 25/05/12 17:57:17 INFO BlockManagerInfo: Removed broadcast_1_piece0 on d4e9ca837c07:42539 in memory (size: 16.1 KiB, free: 434.4 MiB)
[2025-05-12T17:57:19.206+0000] {subprocess.py:93} INFO - 25/05/12 17:57:19 INFO DefaultMavenCoordinates: DataStax Java driver for Apache Cassandra(R) (com.datastax.oss:java-driver-core-shaded) version 4.13.0
[2025-05-12T17:57:19.508+0000] {subprocess.py:93} INFO - 25/05/12 17:57:19 INFO Native: Unable to load JNR native implementation. This could be normal if JNR is excluded from the classpath
[2025-05-12T17:57:19.509+0000] {subprocess.py:93} INFO - java.lang.NoClassDefFoundError: jnr/posix/POSIXHandler
[2025-05-12T17:57:19.510+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.os.Native$LibcLoader.load(Native.java:42)
[2025-05-12T17:57:19.510+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.os.Native.<clinit>(Native.java:59)
[2025-05-12T17:57:19.511+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.time.Clock.getInstance(Clock.java:41)
[2025-05-12T17:57:19.512+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.time.MonotonicTimestampGenerator.buildClock(MonotonicTimestampGenerator.java:109)
[2025-05-12T17:57:19.513+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.time.MonotonicTimestampGenerator.<init>(MonotonicTimestampGenerator.java:43)
[2025-05-12T17:57:19.514+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.time.AtomicTimestampGenerator.<init>(AtomicTimestampGenerator.java:52)
[2025-05-12T17:57:19.515+0000] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2025-05-12T17:57:19.516+0000] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(Unknown Source)
[2025-05-12T17:57:19.516+0000] {subprocess.py:93} INFO - 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(Unknown Source)
[2025-05-12T17:57:19.517+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.reflect.Constructor.newInstance(Unknown Source)
[2025-05-12T17:57:19.517+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.util.Reflection.resolveClass(Reflection.java:329)
[2025-05-12T17:57:19.518+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.util.Reflection.buildFromConfig(Reflection.java:235)
[2025-05-12T17:57:19.518+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.util.Reflection.buildFromConfig(Reflection.java:110)
[2025-05-12T17:57:19.519+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.context.DefaultDriverContext.buildTimestampGenerator(DefaultDriverContext.java:377)
[2025-05-12T17:57:19.520+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.util.concurrent.LazyReference.get(LazyReference.java:55)
[2025-05-12T17:57:19.520+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.context.DefaultDriverContext.getTimestampGenerator(DefaultDriverContext.java:773)
[2025-05-12T17:57:19.521+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.session.DefaultSession$SingleThreaded.init(DefaultSession.java:349)
[2025-05-12T17:57:19.521+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.session.DefaultSession$SingleThreaded.access$1100(DefaultSession.java:300)
[2025-05-12T17:57:19.522+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.internal.core.session.DefaultSession.lambda$init$0(DefaultSession.java:146)
[2025-05-12T17:57:19.522+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.util.concurrent.PromiseTask.runTask(PromiseTask.java:98)
[2025-05-12T17:57:19.523+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.util.concurrent.PromiseTask.run(PromiseTask.java:106)
[2025-05-12T17:57:19.523+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.channel.DefaultEventLoop.run(DefaultEventLoop.java:54)
[2025-05-12T17:57:19.525+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
[2025-05-12T17:57:19.526+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
[2025-05-12T17:57:19.526+0000] {subprocess.py:93} INFO - 	at com.datastax.oss.driver.shaded.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
[2025-05-12T17:57:19.529+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.Thread.run(Unknown Source)
[2025-05-12T17:57:19.531+0000] {subprocess.py:93} INFO - Caused by: java.lang.ClassNotFoundException: jnr.posix.POSIXHandler
[2025-05-12T17:57:19.531+0000] {subprocess.py:93} INFO - 	at java.base/java.net.URLClassLoader.findClass(Unknown Source)
[2025-05-12T17:57:19.532+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.ClassLoader.loadClass(Unknown Source)
[2025-05-12T17:57:19.533+0000] {subprocess.py:93} INFO - 	at java.base/java.lang.ClassLoader.loadClass(Unknown Source)
[2025-05-12T17:57:19.533+0000] {subprocess.py:93} INFO - 	... 26 more
[2025-05-12T17:57:19.534+0000] {subprocess.py:93} INFO - 25/05/12 17:57:19 INFO Clock: Could not access native clock (see debug logs for details), falling back to Java system clock
[2025-05-12T17:57:20.282+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO CassandraConnector: Connected to Cassandra cluster.
[2025-05-12T17:57:20.634+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO CodeGenerator: Code generated in 37.200014 ms
[2025-05-12T17:57:20.663+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO AppendDataExec: Start processing data source write support: CassandraBulkWrite(org.apache.spark.sql.SparkSession@5ac8fd50,com.datastax.spark.connector.cql.CassandraConnector@28f74ebe,TableDef(gold_news,articles,ArrayBuffer(ColumnDef(id,PartitionKeyColumn,VarCharType)),ArrayBuffer(),Stream(ColumnDef(description,RegularColumn,VarCharType), ColumnDef(ingestion_time,RegularColumn,VarCharType), ColumnDef(published_at,RegularColumn,VarCharType), ColumnDef(recommendation,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(source,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType), ColumnDef(url,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(BytesInBatch(1024),1000,Partition,ONE,false,false,5,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(description,StringType,true),StructField(id,StringType,true),StructField(ingestion_time,StringType,true),StructField(published_at,StringType,true),StructField(recommendation,StringType,true),StructField(sentiment,StringType,true),StructField(source,StringType,true),StructField(title,StringType,true),StructField(url,StringType,true)),org.apache.spark.SparkConf@a52be8e). The input RDD has 8 partitions.
[2025-05-12T17:57:20.762+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO SparkContext: Starting job: save at <unknown>:0
[2025-05-12T17:57:20.770+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO DAGScheduler: Got job 2 (save at <unknown>:0) with 8 output partitions
[2025-05-12T17:57:20.771+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO DAGScheduler: Final stage: ResultStage 2 (save at <unknown>:0)
[2025-05-12T17:57:20.772+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO DAGScheduler: Parents of final stage: List()
[2025-05-12T17:57:20.773+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO DAGScheduler: Missing parents: List()
[2025-05-12T17:57:20.776+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at save at <unknown>:0), which has no missing parents
[2025-05-12T17:57:20.806+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 21.8 KiB, free 434.4 MiB)
[2025-05-12T17:57:20.848+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 434.4 MiB)
[2025-05-12T17:57:20.853+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on d4e9ca837c07:42539 (size: 10.7 KiB, free: 434.4 MiB)
[2025-05-12T17:57:20.854+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1585
[2025-05-12T17:57:20.855+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at save at <unknown>:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
[2025-05-12T17:57:20.856+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO TaskSchedulerImpl: Adding task set 2.0 with 8 tasks resource profile 0
[2025-05-12T17:57:20.872+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (d4e9ca837c07, executor driver, partition 0, PROCESS_LOCAL, 16873 bytes)
[2025-05-12T17:57:20.876+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3) (d4e9ca837c07, executor driver, partition 1, PROCESS_LOCAL, 16719 bytes)
[2025-05-12T17:57:20.895+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 4) (d4e9ca837c07, executor driver, partition 2, PROCESS_LOCAL, 16796 bytes)
[2025-05-12T17:57:20.908+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 5) (d4e9ca837c07, executor driver, partition 3, PROCESS_LOCAL, 16669 bytes)
[2025-05-12T17:57:20.911+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 6) (d4e9ca837c07, executor driver, partition 4, PROCESS_LOCAL, 16439 bytes)
[2025-05-12T17:57:20.916+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 7) (d4e9ca837c07, executor driver, partition 5, PROCESS_LOCAL, 16873 bytes)
[2025-05-12T17:57:20.923+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 8) (d4e9ca837c07, executor driver, partition 6, PROCESS_LOCAL, 16719 bytes)
[2025-05-12T17:57:20.935+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 9) (d4e9ca837c07, executor driver, partition 7, PROCESS_LOCAL, 19396 bytes)
[2025-05-12T17:57:20.936+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
[2025-05-12T17:57:20.982+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
[2025-05-12T17:57:20.987+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO Executor: Running task 2.0 in stage 2.0 (TID 4)
[2025-05-12T17:57:20.990+0000] {subprocess.py:93} INFO - 25/05/12 17:57:20 INFO Executor: Running task 3.0 in stage 2.0 (TID 5)
[2025-05-12T17:57:21.015+0000] {subprocess.py:93} INFO - 25/05/12 17:57:21 INFO Executor: Running task 4.0 in stage 2.0 (TID 6)
[2025-05-12T17:57:21.017+0000] {subprocess.py:93} INFO - 25/05/12 17:57:21 INFO Executor: Running task 5.0 in stage 2.0 (TID 7)
[2025-05-12T17:57:21.021+0000] {subprocess.py:93} INFO - 25/05/12 17:57:21 INFO Executor: Running task 6.0 in stage 2.0 (TID 8)
[2025-05-12T17:57:21.029+0000] {subprocess.py:93} INFO - 25/05/12 17:57:21 INFO Executor: Running task 7.0 in stage 2.0 (TID 9)
[2025-05-12T17:57:22.044+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO CodeGenerator: Code generated in 31.993628 ms
[2025-05-12T17:57:22.762+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO PythonRunner: Times: total = 856, boot = 799, init = 56, finish = 1
[2025-05-12T17:57:22.777+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO PythonRunner: Times: total = 882, boot = 824, init = 53, finish = 5
[2025-05-12T17:57:22.781+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO PythonRunner: Times: total = 871, boot = 784, init = 86, finish = 1
[2025-05-12T17:57:22.783+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO DataWritingSparkTask: Commit authorized for partition 3 (task 5, attempt 0, stage 2.0)
[2025-05-12T17:57:22.784+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO PythonRunner: Times: total = 866, boot = 807, init = 58, finish = 1
[2025-05-12T17:57:22.786+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO PythonRunner: Times: total = 856, boot = 794, init = 61, finish = 1
[2025-05-12T17:57:22.789+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO DataWritingSparkTask: Commit authorized for partition 2 (task 4, attempt 0, stage 2.0)
[2025-05-12T17:57:22.799+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO DataWritingSparkTask: Commit authorized for partition 4 (task 6, attempt 0, stage 2.0)
[2025-05-12T17:57:22.800+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO DataWritingSparkTask: Commit authorized for partition 6 (task 8, attempt 0, stage 2.0)
[2025-05-12T17:57:22.800+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO PythonRunner: Times: total = 866, boot = 817, init = 48, finish = 1
[2025-05-12T17:57:22.801+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO PythonRunner: Times: total = 889, boot = 829, init = 58, finish = 2
[2025-05-12T17:57:22.805+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO DataWritingSparkTask: Commit authorized for partition 5 (task 7, attempt 0, stage 2.0)
[2025-05-12T17:57:22.807+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO PythonRunner: Times: total = 871, boot = 788, init = 82, finish = 1
[2025-05-12T17:57:22.807+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO DataWritingSparkTask: Commit authorized for partition 1 (task 3, attempt 0, stage 2.0)
[2025-05-12T17:57:22.813+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO DataWritingSparkTask: Commit authorized for partition 0 (task 2, attempt 0, stage 2.0)
[2025-05-12T17:57:22.818+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO DataWritingSparkTask: Commit authorized for partition 7 (task 9, attempt 0, stage 2.0)
[2025-05-12T17:57:22.959+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO DataWritingSparkTask: Committed partition 2 (task 4, attempt 0, stage 2.0)
[2025-05-12T17:57:22.960+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO DataWritingSparkTask: Committed partition 0 (task 2, attempt 0, stage 2.0)
[2025-05-12T17:57:22.997+0000] {subprocess.py:93} INFO - 25/05/12 17:57:22 INFO DataWritingSparkTask: Committed partition 4 (task 6, attempt 0, stage 2.0)
[2025-05-12T17:57:23.004+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1939 bytes result sent to driver
[2025-05-12T17:57:23.005+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO Executor: Finished task 4.0 in stage 2.0 (TID 6). 1896 bytes result sent to driver
[2025-05-12T17:57:23.012+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO Executor: Finished task 2.0 in stage 2.0 (TID 4). 1896 bytes result sent to driver
[2025-05-12T17:57:23.013+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 2157 ms on d4e9ca837c07 (executor driver) (1/8)
[2025-05-12T17:57:23.014+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO DataWritingSparkTask: Committed partition 3 (task 5, attempt 0, stage 2.0)
[2025-05-12T17:57:23.016+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 58703
[2025-05-12T17:57:23.018+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO DataWritingSparkTask: Committed partition 6 (task 8, attempt 0, stage 2.0)
[2025-05-12T17:57:23.019+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 6) in 2110 ms on d4e9ca837c07 (executor driver) (2/8)
[2025-05-12T17:57:23.020+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 4) in 2147 ms on d4e9ca837c07 (executor driver) (3/8)
[2025-05-12T17:57:23.031+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO DataWritingSparkTask: Committed partition 1 (task 3, attempt 0, stage 2.0)
[2025-05-12T17:57:23.032+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO Executor: Finished task 6.0 in stage 2.0 (TID 8). 1939 bytes result sent to driver
[2025-05-12T17:57:23.033+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO Executor: Finished task 3.0 in stage 2.0 (TID 5). 1896 bytes result sent to driver
[2025-05-12T17:57:23.034+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 8) in 2116 ms on d4e9ca837c07 (executor driver) (4/8)
[2025-05-12T17:57:23.037+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO DataWritingSparkTask: Committed partition 5 (task 7, attempt 0, stage 2.0)
[2025-05-12T17:57:23.043+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 5) in 2136 ms on d4e9ca837c07 (executor driver) (5/8)
[2025-05-12T17:57:23.046+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 1896 bytes result sent to driver
[2025-05-12T17:57:23.051+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 2181 ms on d4e9ca837c07 (executor driver) (6/8)
[2025-05-12T17:57:23.056+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO DataWritingSparkTask: Committed partition 7 (task 9, attempt 0, stage 2.0)
[2025-05-12T17:57:23.058+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO Executor: Finished task 5.0 in stage 2.0 (TID 7). 1939 bytes result sent to driver
[2025-05-12T17:57:23.060+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 7) in 2146 ms on d4e9ca837c07 (executor driver) (7/8)
[2025-05-12T17:57:23.063+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO Executor: Finished task 7.0 in stage 2.0 (TID 9). 1896 bytes result sent to driver
[2025-05-12T17:57:23.072+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 9) in 2141 ms on d4e9ca837c07 (executor driver) (8/8)
[2025-05-12T17:57:23.073+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2025-05-12T17:57:23.076+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO DAGScheduler: ResultStage 2 (save at <unknown>:0) finished in 2.289 s
[2025-05-12T17:57:23.077+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-12T17:57:23.078+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2025-05-12T17:57:23.080+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO DAGScheduler: Job 2 finished: save at <unknown>:0, took 2.319980 s
[2025-05-12T17:57:23.082+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@5ac8fd50,com.datastax.spark.connector.cql.CassandraConnector@28f74ebe,TableDef(gold_news,articles,ArrayBuffer(ColumnDef(id,PartitionKeyColumn,VarCharType)),ArrayBuffer(),Stream(ColumnDef(description,RegularColumn,VarCharType), ColumnDef(ingestion_time,RegularColumn,VarCharType), ColumnDef(published_at,RegularColumn,VarCharType), ColumnDef(recommendation,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(source,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType), ColumnDef(url,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(BytesInBatch(1024),1000,Partition,ONE,false,false,5,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(description,StringType,true),StructField(id,StringType,true),StructField(ingestion_time,StringType,true),StructField(published_at,StringType,true),StructField(recommendation,StringType,true),StructField(sentiment,StringType,true),StructField(source,StringType,true),StructField(title,StringType,true),StructField(url,StringType,true)),org.apache.spark.SparkConf@a52be8e) is committing.
[2025-05-12T17:57:23.088+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO AppendDataExec: Data source write support CassandraBulkWrite(org.apache.spark.sql.SparkSession@5ac8fd50,com.datastax.spark.connector.cql.CassandraConnector@28f74ebe,TableDef(gold_news,articles,ArrayBuffer(ColumnDef(id,PartitionKeyColumn,VarCharType)),ArrayBuffer(),Stream(ColumnDef(description,RegularColumn,VarCharType), ColumnDef(ingestion_time,RegularColumn,VarCharType), ColumnDef(published_at,RegularColumn,VarCharType), ColumnDef(recommendation,RegularColumn,VarCharType), ColumnDef(sentiment,RegularColumn,VarCharType), ColumnDef(source,RegularColumn,VarCharType), ColumnDef(title,RegularColumn,VarCharType), ColumnDef(url,RegularColumn,VarCharType)),Stream(),false,false,Map()),WriteConf(BytesInBatch(1024),1000,Partition,ONE,false,false,5,None,TTLOption(DefaultValue),TimestampOption(DefaultValue),true,None),StructType(StructField(description,StringType,true),StructField(id,StringType,true),StructField(ingestion_time,StringType,true),StructField(published_at,StringType,true),StructField(recommendation,StringType,true),StructField(sentiment,StringType,true),StructField(source,StringType,true),StructField(title,StringType,true),StructField(url,StringType,true)),org.apache.spark.SparkConf@a52be8e) committed.
[2025-05-12T17:57:23.904+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO CodeGenerator: Code generated in 42.16347 ms
[2025-05-12T17:57:23.951+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO DAGScheduler: Registering RDD 16 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) as input to shuffle 0
[2025-05-12T17:57:23.963+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO DAGScheduler: Got map stage job 3 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 8 output partitions
[2025-05-12T17:57:23.965+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2025-05-12T17:57:23.965+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO DAGScheduler: Parents of final stage: List()
[2025-05-12T17:57:23.967+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO DAGScheduler: Missing parents: List()
[2025-05-12T17:57:23.973+0000] {subprocess.py:93} INFO - 25/05/12 17:57:23 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[16] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2025-05-12T17:57:24.035+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 25.9 KiB, free 434.3 MiB)
[2025-05-12T17:57:24.052+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.6 KiB, free 434.3 MiB)
[2025-05-12T17:57:24.056+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on d4e9ca837c07:42539 (size: 11.6 KiB, free: 434.4 MiB)
[2025-05-12T17:57:24.057+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1585
[2025-05-12T17:57:24.065+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[16] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
[2025-05-12T17:57:24.066+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSchedulerImpl: Adding task set 3.0 with 8 tasks resource profile 0
[2025-05-12T17:57:24.067+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 10) (d4e9ca837c07, executor driver, partition 0, PROCESS_LOCAL, 16862 bytes)
[2025-05-12T17:57:24.074+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 11) (d4e9ca837c07, executor driver, partition 1, PROCESS_LOCAL, 16708 bytes)
[2025-05-12T17:57:24.081+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 12) (d4e9ca837c07, executor driver, partition 2, PROCESS_LOCAL, 16785 bytes)
[2025-05-12T17:57:24.083+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 13) (d4e9ca837c07, executor driver, partition 3, PROCESS_LOCAL, 16658 bytes)
[2025-05-12T17:57:24.085+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 14) (d4e9ca837c07, executor driver, partition 4, PROCESS_LOCAL, 16428 bytes)
[2025-05-12T17:57:24.088+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 15) (d4e9ca837c07, executor driver, partition 5, PROCESS_LOCAL, 16862 bytes)
[2025-05-12T17:57:24.096+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 16) (d4e9ca837c07, executor driver, partition 6, PROCESS_LOCAL, 16708 bytes)
[2025-05-12T17:57:24.098+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 17) (d4e9ca837c07, executor driver, partition 7, PROCESS_LOCAL, 19385 bytes)
[2025-05-12T17:57:24.099+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Running task 0.0 in stage 3.0 (TID 10)
[2025-05-12T17:57:24.107+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Running task 1.0 in stage 3.0 (TID 11)
[2025-05-12T17:57:24.113+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Running task 6.0 in stage 3.0 (TID 16)
[2025-05-12T17:57:24.113+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Running task 5.0 in stage 3.0 (TID 15)
[2025-05-12T17:57:24.115+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Running task 4.0 in stage 3.0 (TID 14)
[2025-05-12T17:57:24.115+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Running task 3.0 in stage 3.0 (TID 13)
[2025-05-12T17:57:24.116+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Running task 2.0 in stage 3.0 (TID 12)
[2025-05-12T17:57:24.117+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Running task 7.0 in stage 3.0 (TID 17)
[2025-05-12T17:57:24.207+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO CodeGenerator: Code generated in 52.380702 ms
[2025-05-12T17:57:24.334+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO PythonRunner: Times: total = 77, boot = -1996, init = 2073, finish = 0
[2025-05-12T17:57:24.338+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO PythonRunner: Times: total = 89, boot = -2024, init = 2113, finish = 0
[2025-05-12T17:57:24.341+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO PythonRunner: Times: total = 47, boot = -2005, init = 2052, finish = 0
[2025-05-12T17:57:24.354+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO PythonRunner: Times: total = 90, boot = -2010, init = 2099, finish = 1
[2025-05-12T17:57:24.355+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO PythonRunner: Times: total = 74, boot = -2038, init = 2108, finish = 4
[2025-05-12T17:57:24.356+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO PythonRunner: Times: total = 71, boot = -2066, init = 2136, finish = 1
[2025-05-12T17:57:24.356+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO PythonRunner: Times: total = 50, boot = -2043, init = 2092, finish = 1
[2025-05-12T17:57:24.357+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO BlockManagerInfo: Removed broadcast_2_piece0 on d4e9ca837c07:42539 in memory (size: 10.7 KiB, free: 434.4 MiB)
[2025-05-12T17:57:24.358+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO PythonRunner: Times: total = 79, boot = -1998, init = 2077, finish = 0
[2025-05-12T17:57:24.438+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Finished task 4.0 in stage 3.0 (TID 14). 2362 bytes result sent to driver
[2025-05-12T17:57:24.439+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Finished task 3.0 in stage 3.0 (TID 13). 2362 bytes result sent to driver
[2025-05-12T17:57:24.440+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Finished task 1.0 in stage 3.0 (TID 11). 2319 bytes result sent to driver
[2025-05-12T17:57:24.452+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Finished task 6.0 in stage 3.0 (TID 16). 2362 bytes result sent to driver
[2025-05-12T17:57:24.454+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Finished task 5.0 in stage 3.0 (TID 15). 2362 bytes result sent to driver
[2025-05-12T17:57:24.455+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 13) in 371 ms on d4e9ca837c07 (executor driver) (1/8)
[2025-05-12T17:57:24.456+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Finished task 0.0 in stage 3.0 (TID 10). 2362 bytes result sent to driver
[2025-05-12T17:57:24.461+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Finished task 7.0 in stage 3.0 (TID 17). 2319 bytes result sent to driver
[2025-05-12T17:57:24.462+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 11) in 378 ms on d4e9ca837c07 (executor driver) (2/8)
[2025-05-12T17:57:24.463+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Finished task 2.0 in stage 3.0 (TID 12). 2362 bytes result sent to driver
[2025-05-12T17:57:24.465+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 14) in 373 ms on d4e9ca837c07 (executor driver) (3/8)
[2025-05-12T17:57:24.466+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 16) in 370 ms on d4e9ca837c07 (executor driver) (4/8)
[2025-05-12T17:57:24.466+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 15) in 375 ms on d4e9ca837c07 (executor driver) (5/8)
[2025-05-12T17:57:24.467+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 17) in 379 ms on d4e9ca837c07 (executor driver) (6/8)
[2025-05-12T17:57:24.467+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 12) in 394 ms on d4e9ca837c07 (executor driver) (7/8)
[2025-05-12T17:57:24.468+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 10) in 401 ms on d4e9ca837c07 (executor driver) (8/8)
[2025-05-12T17:57:24.468+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-05-12T17:57:24.471+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO DAGScheduler: ShuffleMapStage 3 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.484 s
[2025-05-12T17:57:24.477+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO DAGScheduler: looking for newly runnable stages
[2025-05-12T17:57:24.479+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO DAGScheduler: running: Set()
[2025-05-12T17:57:24.480+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO DAGScheduler: waiting: Set()
[2025-05-12T17:57:24.481+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO DAGScheduler: failed: Set()
[2025-05-12T17:57:24.661+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO CodeGenerator: Code generated in 53.291827 ms
[2025-05-12T17:57:24.692+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2025-05-12T17:57:24.696+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO DAGScheduler: Got job 4 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2025-05-12T17:57:24.698+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO DAGScheduler: Final stage: ResultStage 5 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2025-05-12T17:57:24.699+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2025-05-12T17:57:24.700+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO DAGScheduler: Missing parents: List()
[2025-05-12T17:57:24.700+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[19] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2025-05-12T17:57:24.717+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 18.1 KiB, free 434.3 MiB)
[2025-05-12T17:57:24.752+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.3 MiB)
[2025-05-12T17:57:24.758+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on d4e9ca837c07:42539 (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-12T17:57:24.759+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1585
[2025-05-12T17:57:24.767+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO BlockManagerInfo: Removed broadcast_3_piece0 on d4e9ca837c07:42539 in memory (size: 11.6 KiB, free: 434.4 MiB)
[2025-05-12T17:57:24.768+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[19] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2025-05-12T17:57:24.769+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2025-05-12T17:57:24.786+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 18) (d4e9ca837c07, executor driver, partition 0, NODE_LOCAL, 12874 bytes)
[2025-05-12T17:57:24.787+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Running task 0.0 in stage 5.0 (TID 18)
[2025-05-12T17:57:24.866+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO ShuffleBlockFetcherIterator: Getting 8 (688.0 B) non-empty blocks including 8 (688.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-12T17:57:24.871+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 38 ms
[2025-05-12T17:57:24.911+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO CodeGenerator: Code generated in 30.362421 ms
[2025-05-12T17:57:25.017+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO Executor: Finished task 0.0 in stage 5.0 (TID 18). 4056 bytes result sent to driver
[2025-05-12T17:57:25.025+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 18) in 214 ms on d4e9ca837c07 (executor driver) (1/1)
[2025-05-12T17:57:25.026+0000] {subprocess.py:93} INFO - 25/05/12 17:57:24 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2025-05-12T17:57:25.027+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO DAGScheduler: ResultStage 5 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.290 s
[2025-05-12T17:57:25.027+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-12T17:57:25.028+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2025-05-12T17:57:25.028+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO DAGScheduler: Job 4 finished: call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.327718 s
[2025-05-12T17:57:25.310+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO CodeGenerator: Code generated in 65.118132 ms
[2025-05-12T17:57:25.367+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO DAGScheduler: Registering RDD 21 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) as input to shuffle 1
[2025-05-12T17:57:25.368+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO DAGScheduler: Got map stage job 5 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 8 output partitions
[2025-05-12T17:57:25.369+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2025-05-12T17:57:25.370+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO DAGScheduler: Parents of final stage: List()
[2025-05-12T17:57:25.382+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO DAGScheduler: Missing parents: List()
[2025-05-12T17:57:25.389+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[21] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2025-05-12T17:57:25.398+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 38.3 KiB, free 434.3 MiB)
[2025-05-12T17:57:25.449+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 18.4 KiB, free 434.3 MiB)
[2025-05-12T17:57:25.456+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on d4e9ca837c07:42539 (size: 18.4 KiB, free: 434.4 MiB)
[2025-05-12T17:57:25.462+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1585
[2025-05-12T17:57:25.473+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[21] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
[2025-05-12T17:57:25.474+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO TaskSchedulerImpl: Adding task set 6.0 with 8 tasks resource profile 0
[2025-05-12T17:57:25.475+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 19) (d4e9ca837c07, executor driver, partition 0, PROCESS_LOCAL, 16862 bytes)
[2025-05-12T17:57:25.476+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 20) (d4e9ca837c07, executor driver, partition 1, PROCESS_LOCAL, 16708 bytes)
[2025-05-12T17:57:25.477+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 21) (d4e9ca837c07, executor driver, partition 2, PROCESS_LOCAL, 16785 bytes)
[2025-05-12T17:57:25.479+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 22) (d4e9ca837c07, executor driver, partition 3, PROCESS_LOCAL, 16658 bytes)
[2025-05-12T17:57:25.487+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 23) (d4e9ca837c07, executor driver, partition 4, PROCESS_LOCAL, 16428 bytes)
[2025-05-12T17:57:25.487+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO TaskSetManager: Starting task 5.0 in stage 6.0 (TID 24) (d4e9ca837c07, executor driver, partition 5, PROCESS_LOCAL, 16862 bytes)
[2025-05-12T17:57:25.492+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO TaskSetManager: Starting task 6.0 in stage 6.0 (TID 25) (d4e9ca837c07, executor driver, partition 6, PROCESS_LOCAL, 16708 bytes)
[2025-05-12T17:57:25.493+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO TaskSetManager: Starting task 7.0 in stage 6.0 (TID 26) (d4e9ca837c07, executor driver, partition 7, PROCESS_LOCAL, 19385 bytes)
[2025-05-12T17:57:25.494+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO Executor: Running task 0.0 in stage 6.0 (TID 19)
[2025-05-12T17:57:25.498+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO Executor: Running task 1.0 in stage 6.0 (TID 20)
[2025-05-12T17:57:25.500+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO Executor: Running task 2.0 in stage 6.0 (TID 21)
[2025-05-12T17:57:25.500+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO Executor: Running task 4.0 in stage 6.0 (TID 23)
[2025-05-12T17:57:25.501+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO Executor: Running task 5.0 in stage 6.0 (TID 24)
[2025-05-12T17:57:25.502+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO Executor: Running task 3.0 in stage 6.0 (TID 22)
[2025-05-12T17:57:25.502+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO Executor: Running task 6.0 in stage 6.0 (TID 25)
[2025-05-12T17:57:25.503+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO Executor: Running task 7.0 in stage 6.0 (TID 26)
[2025-05-12T17:57:25.532+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO BlockManagerInfo: Removed broadcast_4_piece0 on d4e9ca837c07:42539 in memory (size: 7.4 KiB, free: 434.4 MiB)
[2025-05-12T17:57:25.727+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO CodeGenerator: Code generated in 156.647946 ms
[2025-05-12T17:57:25.852+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO CodeGenerator: Code generated in 35.255679 ms
[2025-05-12T17:57:25.893+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO CodeGenerator: Code generated in 18.175476 ms
[2025-05-12T17:57:25.958+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO CodeGenerator: Code generated in 22.855505 ms
[2025-05-12T17:57:25.995+0000] {subprocess.py:93} INFO - 25/05/12 17:57:25 INFO CodeGenerator: Code generated in 17.06698 ms
[2025-05-12T17:57:26.019+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO PythonRunner: Times: total = 59, boot = -1322, init = 1380, finish = 1
[2025-05-12T17:57:26.028+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO PythonRunner: Times: total = 61, boot = -1314, init = 1374, finish = 1
[2025-05-12T17:57:26.043+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO PythonRunner: Times: total = 86, boot = -1328, init = 1414, finish = 0
[2025-05-12T17:57:26.049+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO PythonRunner: Times: total = 87, boot = -1290, init = 1377, finish = 0
[2025-05-12T17:57:26.053+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO PythonRunner: Times: total = 105, boot = -1317, init = 1422, finish = 0
[2025-05-12T17:57:26.054+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO PythonRunner: Times: total = 81, boot = -1340, init = 1419, finish = 2
[2025-05-12T17:57:26.055+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO PythonRunner: Times: total = 90, boot = -1301, init = 1391, finish = 0
[2025-05-12T17:57:26.056+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO PythonRunner: Times: total = 110, boot = -1290, init = 1400, finish = 0
[2025-05-12T17:57:26.344+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO Executor: Finished task 5.0 in stage 6.0 (TID 24). 2925 bytes result sent to driver
[2025-05-12T17:57:26.361+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO Executor: Finished task 7.0 in stage 6.0 (TID 26). 2882 bytes result sent to driver
[2025-05-12T17:57:26.362+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO Executor: Finished task 0.0 in stage 6.0 (TID 19). 2882 bytes result sent to driver
[2025-05-12T17:57:26.363+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO Executor: Finished task 4.0 in stage 6.0 (TID 23). 2882 bytes result sent to driver
[2025-05-12T17:57:26.364+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO Executor: Finished task 1.0 in stage 6.0 (TID 20). 2882 bytes result sent to driver
[2025-05-12T17:57:26.378+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO TaskSetManager: Finished task 7.0 in stage 6.0 (TID 26) in 901 ms on d4e9ca837c07 (executor driver) (1/8)
[2025-05-12T17:57:26.387+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 19) in 920 ms on d4e9ca837c07 (executor driver) (2/8)
[2025-05-12T17:57:26.388+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO TaskSetManager: Finished task 5.0 in stage 6.0 (TID 24) in 907 ms on d4e9ca837c07 (executor driver) (3/8)
[2025-05-12T17:57:26.402+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO Executor: Finished task 6.0 in stage 6.0 (TID 25). 2882 bytes result sent to driver
[2025-05-12T17:57:26.407+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO Executor: Finished task 3.0 in stage 6.0 (TID 22). 2882 bytes result sent to driver
[2025-05-12T17:57:26.408+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 23) in 938 ms on d4e9ca837c07 (executor driver) (4/8)
[2025-05-12T17:57:26.409+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO Executor: Finished task 2.0 in stage 6.0 (TID 21). 2882 bytes result sent to driver
[2025-05-12T17:57:26.410+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 20) in 950 ms on d4e9ca837c07 (executor driver) (5/8)
[2025-05-12T17:57:26.410+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO TaskSetManager: Finished task 6.0 in stage 6.0 (TID 25) in 935 ms on d4e9ca837c07 (executor driver) (6/8)
[2025-05-12T17:57:26.411+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 22) in 942 ms on d4e9ca837c07 (executor driver) (7/8)
[2025-05-12T17:57:26.416+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 21) in 953 ms on d4e9ca837c07 (executor driver) (8/8)
[2025-05-12T17:57:26.417+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-05-12T17:57:26.435+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO DAGScheduler: ShuffleMapStage 6 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 1.056 s
[2025-05-12T17:57:26.436+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO DAGScheduler: looking for newly runnable stages
[2025-05-12T17:57:26.437+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO DAGScheduler: running: Set()
[2025-05-12T17:57:26.437+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO DAGScheduler: waiting: Set()
[2025-05-12T17:57:26.437+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO DAGScheduler: failed: Set()
[2025-05-12T17:57:26.483+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-05-12T17:57:26.644+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2025-05-12T17:57:26.725+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO CodeGenerator: Code generated in 64.959441 ms
[2025-05-12T17:57:26.810+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO SparkContext: Starting job: call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617
[2025-05-12T17:57:26.829+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO DAGScheduler: Got job 6 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) with 1 output partitions
[2025-05-12T17:57:26.830+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO DAGScheduler: Final stage: ResultStage 8 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617)
[2025-05-12T17:57:26.831+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2025-05-12T17:57:26.832+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO DAGScheduler: Missing parents: List()
[2025-05-12T17:57:26.833+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[24] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617), which has no missing parents
[2025-05-12T17:57:26.848+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 40.5 KiB, free 434.3 MiB)
[2025-05-12T17:57:26.921+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 19.5 KiB, free 434.3 MiB)
[2025-05-12T17:57:26.923+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on d4e9ca837c07:42539 (size: 19.5 KiB, free: 434.4 MiB)
[2025-05-12T17:57:26.926+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1585
[2025-05-12T17:57:26.927+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[24] at call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) (first 15 tasks are for partitions Vector(0))
[2025-05-12T17:57:26.928+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2025-05-12T17:57:26.935+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 27) (d4e9ca837c07, executor driver, partition 0, NODE_LOCAL, 12874 bytes)
[2025-05-12T17:57:26.941+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO Executor: Running task 0.0 in stage 8.0 (TID 27)
[2025-05-12T17:57:26.966+0000] {subprocess.py:93} INFO - 25/05/12 17:57:26 INFO BlockManagerInfo: Removed broadcast_5_piece0 on d4e9ca837c07:42539 in memory (size: 18.4 KiB, free: 434.4 MiB)
[2025-05-12T17:57:27.074+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO ShuffleBlockFetcherIterator: Getting 8 (1152.0 B) non-empty blocks including 8 (1152.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-05-12T17:57:27.075+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 11 ms
[2025-05-12T17:57:27.143+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO CodeGenerator: Code generated in 67.023714 ms
[2025-05-12T17:57:27.230+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO Executor: Finished task 0.0 in stage 8.0 (TID 27). 5262 bytes result sent to driver
[2025-05-12T17:57:27.231+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 27) in 278 ms on d4e9ca837c07 (executor driver) (1/1)
[2025-05-12T17:57:27.234+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2025-05-12T17:57:27.244+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO DAGScheduler: ResultStage 8 (call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617) finished in 0.394 s
[2025-05-12T17:57:27.245+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-05-12T17:57:27.246+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2025-05-12T17:57:27.260+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO DAGScheduler: Job 6 finished: call at /opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:617, took 0.437208 s
[2025-05-12T17:57:27.311+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 ERROR MicroBatchExecution: Query [id = 5c17ed8c-6e3d-4e32-a5cf-66a76eb428c1, runId = ec79e0d6-348c-4b85-9665-b45e7836a80a] terminated with error
[2025-05-12T17:57:27.324+0000] {subprocess.py:93} INFO - py4j.Py4JException: An exception was raised by the Python Proxy. Return Message: Traceback (most recent call last):
[2025-05-12T17:57:27.325+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
[2025-05-12T17:57:27.326+0000] {subprocess.py:93} INFO -     return_value = getattr(self.pool[obj_id], method)(*params)
[2025-05-12T17:57:27.339+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 120, in call
[2025-05-12T17:57:27.340+0000] {subprocess.py:93} INFO -     raise e
[2025-05-12T17:57:27.340+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in call
[2025-05-12T17:57:27.341+0000] {subprocess.py:93} INFO -     self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
[2025-05-12T17:57:27.341+0000] {subprocess.py:93} INFO -   File "/scripts/spark_news.py", line 183, in process_batch
[2025-05-12T17:57:27.353+0000] {subprocess.py:93} INFO -     dominant_recommendation = max(recommendation_counts, key=lambda x: x["count"])["recommendation"]
[2025-05-12T17:57:27.354+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 174, in wrapped
[2025-05-12T17:57:27.355+0000] {subprocess.py:93} INFO -     return f(*args, **kwargs)
[2025-05-12T17:57:27.355+0000] {subprocess.py:93} INFO - TypeError: max() got an unexpected keyword argument 'key'
[2025-05-12T17:57:27.356+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:27.356+0000] {subprocess.py:93} INFO - 	at py4j.Protocol.getReturnValue(Protocol.java:476)
[2025-05-12T17:57:27.362+0000] {subprocess.py:93} INFO - 	at py4j.reflection.PythonProxyHandler.invoke(PythonProxyHandler.java:108)
[2025-05-12T17:57:27.363+0000] {subprocess.py:93} INFO - 	at com.sun.proxy.$Proxy30.call(Unknown Source)
[2025-05-12T17:57:27.363+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1(ForeachBatchSink.scala:53)
[2025-05-12T17:57:27.364+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.sources.PythonForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(ForeachBatchSink.scala:53)
[2025-05-12T17:57:27.364+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:34)
[2025-05-12T17:57:27.365+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)
[2025-05-12T17:57:27.365+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
[2025-05-12T17:57:27.365+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
[2025-05-12T17:57:27.366+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
[2025-05-12T17:57:27.366+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-05-12T17:57:27.366+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
[2025-05-12T17:57:27.370+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)
[2025-05-12T17:57:27.377+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
[2025-05-12T17:57:27.380+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
[2025-05-12T17:57:27.397+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
[2025-05-12T17:57:27.399+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)
[2025-05-12T17:57:27.400+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)
[2025-05-12T17:57:27.401+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-12T17:57:27.401+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)
[2025-05-12T17:57:27.402+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)
[2025-05-12T17:57:27.407+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)
[2025-05-12T17:57:27.409+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)
[2025-05-12T17:57:27.411+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.SingleBatchExecutor.execute(TriggerExecutor.scala:39)
[2025-05-12T17:57:27.411+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)
[2025-05-12T17:57:27.412+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)
[2025-05-12T17:57:27.412+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-12T17:57:27.413+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
[2025-05-12T17:57:27.413+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)
[2025-05-12T17:57:27.414+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)
[2025-05-12T17:57:27.414+0000] {subprocess.py:93} INFO - 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
[2025-05-12T17:57:27.415+0000] {subprocess.py:93} INFO - 	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)
[2025-05-12T17:57:27.415+0000] {subprocess.py:93} INFO - 	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)
[2025-05-12T17:57:27.421+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO AppInfoParser: App info kafka.admin.client for adminclient-1 unregistered
[2025-05-12T17:57:27.437+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO Metrics: Metrics scheduler closed
[2025-05-12T17:57:27.443+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-05-12T17:57:27.446+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO Metrics: Metrics reporters closed
[2025-05-12T17:57:27.449+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO MicroBatchExecution: Async log purge executor pool for query [id = 5c17ed8c-6e3d-4e32-a5cf-66a76eb428c1, runId = ec79e0d6-348c-4b85-9665-b45e7836a80a] has been shutdown
[2025-05-12T17:57:27.734+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2025-05-12T17:57:27.735+0000] {subprocess.py:93} INFO -   File "/scripts/spark_news.py", line 229, in <module>
[2025-05-12T17:57:27.743+0000] {subprocess.py:93} INFO -     analysis_query.awaitTermination()
[2025-05-12T17:57:27.744+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/streaming/query.py", line 221, in awaitTermination
[2025-05-12T17:57:27.746+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
[2025-05-12T17:57:27.747+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 185, in deco
[2025-05-12T17:57:27.765+0000] {subprocess.py:93} INFO - pyspark.errors.exceptions.captured.StreamingQueryException: [STREAM_FAILED] Query [id = 5c17ed8c-6e3d-4e32-a5cf-66a76eb428c1, runId = ec79e0d6-348c-4b85-9665-b45e7836a80a] terminated with exception: An exception was raised by the Python Proxy. Return Message: Traceback (most recent call last):
[2025-05-12T17:57:27.766+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py", line 617, in _call_proxy
[2025-05-12T17:57:27.767+0000] {subprocess.py:93} INFO -     return_value = getattr(self.pool[obj_id], method)(*params)
[2025-05-12T17:57:27.767+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 120, in call
[2025-05-12T17:57:27.768+0000] {subprocess.py:93} INFO -     raise e
[2025-05-12T17:57:27.768+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 117, in call
[2025-05-12T17:57:27.769+0000] {subprocess.py:93} INFO -     self.func(DataFrame(jdf, wrapped_session_jdf), batch_id)
[2025-05-12T17:57:27.770+0000] {subprocess.py:93} INFO -   File "/scripts/spark_news.py", line 183, in process_batch
[2025-05-12T17:57:27.772+0000] {subprocess.py:93} INFO -     dominant_recommendation = max(recommendation_counts, key=lambda x: x["count"])["recommendation"]
[2025-05-12T17:57:27.772+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 174, in wrapped
[2025-05-12T17:57:27.773+0000] {subprocess.py:93} INFO -     return f(*args, **kwargs)
[2025-05-12T17:57:27.774+0000] {subprocess.py:93} INFO - TypeError: max() got an unexpected keyword argument 'key'
[2025-05-12T17:57:27.774+0000] {subprocess.py:93} INFO - 
[2025-05-12T17:57:27.865+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1, groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor] Resetting generation and member id due to: consumer pro-actively leaving the group
[2025-05-12T17:57:27.868+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO ConsumerCoordinator: [Consumer clientId=consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1, groupId=spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor] Request joining group due to: consumer pro-actively leaving the group
[2025-05-12T17:57:27.880+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO Metrics: Metrics scheduler closed
[2025-05-12T17:57:27.881+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO Metrics: Closing reporter org.apache.kafka.common.metrics.JmxReporter
[2025-05-12T17:57:27.882+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO Metrics: Metrics reporters closed
[2025-05-12T17:57:27.887+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO AppInfoParser: App info kafka.consumer for consumer-spark-kafka-source-1680494c-54b6-4c50-a24f-ab976f24ba83--291767381-executor-1 unregistered
[2025-05-12T17:57:27.888+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO SparkContext: Invoking stop() from shutdown hook
[2025-05-12T17:57:27.889+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-05-12T17:57:27.978+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO CassandraConnector: Disconnected from Cassandra cluster.
[2025-05-12T17:57:27.979+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO SerialShutdownHooks: Successfully executed shutdown hook: Clearing session cache for C* connector
[2025-05-12T17:57:27.980+0000] {subprocess.py:93} INFO - 25/05/12 17:57:27 INFO SparkUI: Stopped Spark web UI at http://d4e9ca837c07:4040
[2025-05-12T17:57:28.079+0000] {subprocess.py:93} INFO - 25/05/12 17:57:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-05-12T17:57:28.127+0000] {subprocess.py:93} INFO - 25/05/12 17:57:28 INFO MemoryStore: MemoryStore cleared
[2025-05-12T17:57:28.128+0000] {subprocess.py:93} INFO - 25/05/12 17:57:28 INFO BlockManager: BlockManager stopped
[2025-05-12T17:57:28.139+0000] {subprocess.py:93} INFO - 25/05/12 17:57:28 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-05-12T17:57:28.145+0000] {subprocess.py:93} INFO - 25/05/12 17:57:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-05-12T17:57:28.165+0000] {subprocess.py:93} INFO - 25/05/12 17:57:28 INFO SparkContext: Successfully stopped SparkContext
[2025-05-12T17:57:28.166+0000] {subprocess.py:93} INFO - 25/05/12 17:57:28 INFO ShutdownHookManager: Shutdown hook called
[2025-05-12T17:57:28.167+0000] {subprocess.py:93} INFO - 25/05/12 17:57:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-2d0685cb-1d8f-4feb-96d4-0ad0c4c356d6
[2025-05-12T17:57:28.172+0000] {subprocess.py:93} INFO - 25/05/12 17:57:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223
[2025-05-12T17:57:28.176+0000] {subprocess.py:93} INFO - 25/05/12 17:57:28 INFO ShutdownHookManager: Deleting directory /tmp/spark-43a4ea8b-8b9a-43ce-8012-4a815b7f8223/pyspark-0179f450-defe-48fa-8153-0260b5b9814b
[2025-05-12T17:57:28.365+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2025-05-12T17:57:28.406+0000] {taskinstance.py:1935} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/bash.py", line 210, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2025-05-12T17:57:28.418+0000] {taskinstance.py:1398} INFO - Marking task as FAILED. dag_id=gold_news_pipeline, task_id=run_consumer, execution_date=20250512T175609, start_date=20250512T175616, end_date=20250512T175728
[2025-05-12T17:57:28.475+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 93 for task run_consumer (Bash command failed. The command returned a non-zero exit code 1.; 5972)
[2025-05-12T17:57:28.510+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2025-05-12T17:57:28.604+0000] {taskinstance.py:2776} INFO - 0 downstream tasks scheduled from follow-on schedule check
